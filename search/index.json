[{"content":"全部的内容均迁移至 https://axi404.top/\n","date":"2024-08-22T02:30:00+08:00","permalink":"https://axi404.github.io/Blog/p/%E5%8D%9A%E5%AE%A2%E5%B7%B2%E7%BB%8F%E8%BF%81%E7%A7%BB%E8%87%B3-https/axi404.top/","title":"博客已经迁移至 https://axi404.top/"},{"content":"读者们好，第一次见面是如此的仓促，以至于没有好好的准备一篇长篇大论，来讲述我来到这里之前走过多少的路，不过幸运的是，在将来的无数的日子里，我们还有很多机会来认识彼此。\n我是阿汐，不少人可能知道我在现实中的真名，不过在这里还是用网名示众吧，这样可以有一些安全感，虽然隐私这东西在网络上根本就不现实。\n还是按照简历的话来说一遍，这样读者可以更好的认识我，也知道我将来的目标什么的，或者说我会在这里更新什么内容，大家在这里可以看到什么内容。我开启了 giscus，这是一种使用 Github 的博客评论系统，于是你可以使用 Github 账号登录之后在下方评论，假如你有什么想要了解的，也欢迎告诉我！\n那么在这里重新介绍自己。\n大家好，我是阿汐，我是一名来自西安交通大学的人工智能专业的在读生，是 22 级。我当前在课内正在努力学习中，排名还算不错，保研是绰绰有余。至于课外，我对于人工智能领域十分感兴趣。具体来说，我正在本校（西安交通大学）人机所中进行科研实习，从事 Few Shot Learning（FSL）领域相关的内容，并且将来对 VLM 或者 Embodied AI 均有很大的兴趣。\n我的论文，PMT: Progressive Mean Teacher via Exploring Temporal Consistency for Semi-Supervised Medical Image Segmentation 已经被 ECCV 2024 接收。\n我目前在维护几个开源项目，我想这也是你为什么可以找到这里的原因，在这里都进行一个统一的介绍（你可能对其中的一些内容有所了解，但是另外的知之甚少）：\nAI Wiki：AI Wiki 是我主导的仿照 CS 自学指南 的相关项目，旨在帮助初学者更好的学习人工智能领域的内容，介绍人工智能领域的入门路线以及各类常识，并且介绍各个领域的推荐论文等。 西安交大生存指南：西安交大生存指南是我主导的仿照 上海交大生存指南 的相关项目，旨在帮助西安交大的新生与老生更好的在西安交大进行学习与生活，给予高效且实用的建议，并且提供一些有用的资源。 汐学组：汐学组是我主导并维护的学习小组，目前是基于西安交通大学（尤其是人工智能专业），提供课内相关内容的学习辅导资料，以及其他的技术类的分享。假如进行归类，AI Wiki同样是汐学组名下的产物。汐学组产出内容包括： 创作《西安交大生存指南》，旨在帮助西安交大新生与老生。 创作学科复习资料。 维护《人工智能自学指南》，旨在为人工智能初学者提供快速入门的途径。 更新《学点没用的》月刊，旨在为 CS/AI 领域学生/从业者提供可能不属于自己领域的优质教程，用于拓展知识面。 CSBAOYANDDL：CS BAOYAN DDL 是计算机专业保研相关的 ccfddl-like 的 ddl 网站，统计计算机专业保研的夏令营/预推免信息。本项目在 CS-BAOYAN 名下，即计算机保研交流群（绿群）名下。 其他：同时，我还活跃在 XiStudyGroup 以及 CS-BAOYAN 两个群组中，并作为 owner 维护其中的项目，更多的更新可以 follow 我的 Github 账号，或者相关组织。 本博客的创立，其实主要是想要放置一些杂物，例如日常的杂谈，以及部分的不成体系的技术分享。相关的教程一旦成体系之后，我也会在开源社区进行发布，具体的文档自然在本仓库的 Github 中同样是可见的，但是不会进行专门的发布工作。\n相信将来更多有意义的内容可以被放在博客上，一直以来博客创作都是属于极客的最为出色的创作载体之一，希望我也可以将其发扬光大。\n感谢大家的阅读，我们后会有期。\n","date":"2024-06-25T00:00:00Z","image":"https://axi404.github.io/Blog/p/hello-world/cover_hu17100407049240121877.jpg","permalink":"https://axi404.github.io/Blog/p/hello-world/","title":"关于我"},{"content":"前言 因为科研的需要，所以说需要安装一下仿真的环境，领域里面最通用的环境就是 Isaac Sim 了，但是据说也比较复杂，老师推荐了另一个 simulator（Sapien），说是比较轻量级，但是为了以后和其他工作更好地对接，以及之后估计半年多一年还是远程，有必要成为模拟器大师，于是挑战一下自己。\n这篇日记依然和 LLM Talk 系列一样，应该是无限期更新的，包括说正常的安装以及操作的一些记录（对于一些涉密的内容，不会涉及），一些模块的学习，以及一些报错的整理。一方面是给自己作为一个笔记，一方面也是假如说有将来的同学进组，可以有一些更加明确的指引。毕竟本人是英文苦手，看英文的速度完全做不到“扫过”，所以还是有必要记录一下的。\n一些你有必要知道的网址：\nIssac Sim 文档：https://docs.omniverse.nvidia.com/py/isaacsim/index.html Issac Sim 教程：https://docs.omniverse.nvidia.com/isaacsim/latest/core_api_tutorials/index.html mplib 文档：https://motion-planning-lib.readthedocs.io/latest/index.html Franka urdf：https://github.com/haosulab/ManiSkill/tree/v0.5.3/mani_skill2/assets/descriptions，需要使用其中的 panda_v2.urdf 并且下载 franka_description/meshes。 安装 Isaac Sim 首先先简单说一下什么是 Isaac Sim，这是一个在 Nvidia 的 omniverse 下的一个 App，可以完成各种的仿真，也支持 ROS 的接口（虽然我目前还不知道 Embodied 的这一套流程是否和 ROS 有接壤），所以说做机器人这方面，用这个的比较多。而且这个东西是可以生成 image（镜像）并且运行在服务器上的，所以说各种意义上的符合具身智能领域的各种需求。\n既然是 Nvidia 的产品，拥有一个 Nvidia 的账号也就是必须的事情了，一般来说还是推荐通过谷歌邮箱之类的 Mail 去注册，在这里不去赘述这个事情。\n环境概述 按照常规的教程来说，反正首先概述一下环境。本人的环境如下，作为参考，当然，这套环境貌似在一些性能上不是很可以，不知道能否坚持到最后：\n以下是 CPU 以及系统信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 root:~$ linuxlogo -a .-. .-\u0026#39;``(|||) ,`\\ \\ `-`. 88 88 / \\ \u0026#39;``-. ` 88 88 .-. , `___: 88 88 88,888, 88 88 ,88888, 88888 88 88 (:::) : ___ 88 88 88 88 88 88 88 88 88 88 88 `-` ` , : 88 88 88 88 88 88 88 88 88 88 88 \\ / ,..-` , 88 88 88 88 88 88 88 88 88 88 88 `./ / .-.` \u0026#39;88888\u0026#39; \u0026#39;88888\u0026#39; \u0026#39;88888\u0026#39; 88 88 \u0026#39;8888 \u0026#39;88888\u0026#39; `-..-( ) `-` Linux Version 5.15.0-117-generic, Compiled #127~20.04.1-Ubuntu 16 2.3GHz Intel i7 Processors, 128TB RAM, 73728 Bogomips Total 由于本人更换系统的意愿（见 Strange Bugs，Ubuntu 20.04 日常使用已经很不方便），在安装 Isaac Sim 之后的内容均在 Ubuntu 22.04 上进行，如存在其他版本的信息，会专门注明补充。此系统的信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 root:~$ linuxlogo -a .-. .-\u0026#39;``(|||) ,`\\ \\ `-`. 88 88 / \\ \u0026#39;``-. ` 88 88 .-. , `___: 88 88 88,888, 88 88 ,88888, 88888 88 88 (:::) : ___ 88 88 88 88 88 88 88 88 88 88 88 `-` ` , : 88 88 88 88 88 88 88 88 88 88 88 \\ / ,..-` , 88 88 88 88 88 88 88 88 88 88 88 `./ / .-.` \u0026#39;88888\u0026#39; \u0026#39;88888\u0026#39; \u0026#39;88888\u0026#39; 88 88 \u0026#39;8888 \u0026#39;88888\u0026#39; `-..-( ) `-` Linux Version 6.8.0-40-generic, Compiled #40~22.04.3-Ubuntu 16 4.6GHz Intel i7 Tigerlake Processors, 31.1GB RAM, 74k Bogomips 以下是显卡信息，因为是笔记本，我的显卡是 8GB 的 RTX 3070 Laptop：\n1 2 3 4 5 6 root:~$: nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2023 NVIDIA Corporation Built on Tue_Feb__7_19:32:13_PST_2023 Cuda compilation tools, release 12.1, V12.1.66 Build cuda_12.1.r12.1/compiler.32415258_0 我的电脑是 Dell 的 Alienware m15 R6。\n下载 omniverse-launcher 就像是之前说到的一样，Isaac 的 omniverse 下的一个 App，所以说在安装 Isaac 之前要先安装 omniverse-launcher，也是比较简单的，在官网 https://www.nvidia.com/en-us/omniverse/download/ 进行安装就好。进入下载页面之前会要求输入一些个人信息，随意写一下就好，理论来说 nvidia 账号中已经包含了这些内容，所以会自动填写。\n下载下来之后是一个 .AppImage 的文件，按照我的惯例，就直接运行了：\n1 2 3 4 cd ~/Downloads wget https://install.launcher.omniverse.nvidia.com/installers/omniverse-launcher-linux.AppImage sudo chmod +x omniverse-launcher-linux.AppImage ./omniverse-launcher-linux.AppImage 对于 Ubuntu 22.04，可能会报错 AppImages require FUSE to run.，按照提示信息，安装 sudo apt install libfuse2 即可。\n运行之后产生登录页面，本质上还是 nvidia 账号，点击 LOG IN 之后会跳转到网页，输入帐号密码登录即可。然后同意若干的协议，进入如下界面：\n这些路径按照默认配置即可。选择确认，进入主界面：\n其中比较重要的是 Library/Exchange/Nucleus，第一个是已经安装的内容的管理，第二个是安装内容的途径，第三个是一种中央数据库和协作引擎。\n安装并启动 Isaac Sim 进入 Exchange 进行安装，首先安装 cache，搜索之后下拉版本，选择 2023.1.0，并点击 install 即可。\n然后点击 Nucleus，选择 Add local Nucleus Service：\n会要求设置 path 以及 admin account，自行设置即可。\n最后在 Exchange 中安装 Isaac Sim，同样是搜索，版本选择 2023.1.0-hotfix.1，点击 install。\n本人目前选择安装 4.1.0 版本，且之后内容均在此版本下进行。\n在 Nucleus 下载完毕之后，可以找到两个本地的服务：\n其中选择 Settings，可以在网页中看到如下内容：\n值得注意的是，在第二次或者以后启动的时候，可能会出现进入其 Settings 链接 http://localhost:3080/ 之后为一片白色的情况，而 Cache 没有正确启动，导致后续的程序无法运行，解决方法之一是，可以进入其子窗口 http://localhost:3080/cache，再点击上方的 Apps，之后 Restart all 即可。\n假如出现问题，如显示 Stop 或者 Error，请检查之前说的版本问题。假如 cache 版本不对，重新卸载并且安装，然后点击 Launch 即可。\n选择文件夹图标的内容，可以在网页中看到如下的内容：\n均确认无误之后，可以在 Library 中选择 Isaac Sim 并且点击 Launch。\nStandalone Pick and Place 代码实现 此章节在 Ubuntu 22.04, CUDA 12.1, cudnn 9.3.0, Isaac Sim 4.1.0, cache 2023.1.0 下运行。\n接下来就是写代码的环节了，一般来说这个代码有两种实现的方式，一种是在 Isaac Sim 里面添加一个 User Example，另一种是直接使用一个脚本，也就是 standalone script，这里面推荐使用脚本。因为 User Example 的方法必须要使用 GUI 才可以启动，还是不太方便，后续我们肯定是希望这个程序可以摆脱 GUI，当然，必要的时候也可以唤出。\n第一次需要找到你的 Isaac Sim 的环境在哪里，因为 Isaac Sim 使用了自己的 python 环境，因此需要找到他的解释器，假如你是默认安装的路径，那么应该可以看到路径:\n1 echo /home/`whoami`/.local/share/ov/pkg/isaac-sim-4.1.0 但是假如不是，可以进入 Isaac Sim 软件，随便点击一个上方栏的 Isaac Examples，并且 Open Containing Folder 即可。\n例如 hello world 这个 example，这个文件夹应该在 isaac-sim-4.1.0/exts/omni.isaac.examples/omni/isaac/examples/hello_world 中，以下全部的操作视作在 isaac-sim-4.1.0 下进行。\n首先先安装一下 opencv-python，并且创建我们接下来的程序的文件夹：\n1 2 3 4 5 6 sudo apt install libgtk2.0-dev pkg-config ./python -m pip install opencv-python mkdir exts/omni.isaac.examples/omni/isaac/examples/Isaac_learning touch exts/omni.isaac.examples/omni/isaac/examples/Isaac_learning/script.py code . 然后打开这个新建的文件，在里面输入\n1 2 3 4 5 6 7 8 9 10 from isaacsim import SimulationApp simulation_app = SimulationApp({\u0026#34;headless\u0026#34;: False}) from omni.isaac.core import World world = World() while simulation_app.is_running(): world.step(render=True) simulation_app.close() 这是一个最简单的程序，可以创建出来一个正常的模拟器的界面，接下来需要做的事情就是在里面添加东西了。\n在这里简单介绍一下 Isaac Sim 的物体的基本组织结构，基本上可以说，Isaac Sim 里面的物体都是由 Prim 组成的，也就是所谓的 XFormPrim，一般来说，存在一个 world，一个 world 里面会存在 scene，scene 里面的绝大多数内容都是 prim，可以理解为 isaac sim 里面的 object，同时支持嵌套。\n不过对于最基础的内容，我们存在一些 api 可以使用，更多的内容都可以在文档中查询，所以让我们简单修改代码，在里面加入一个地面和一个方块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from isaacsim import SimulationApp simulation_app = SimulationApp({\u0026#34;headless\u0026#34;: False}) # we can also run as headless. from omni.isaac.core import World from omni.isaac.core.objects import DynamicCuboid world = World() world.scene.add_default_ground_plane() cube1 = world.scene.add( DynamicCuboid( prim_path=\u0026#34;/World/cube1\u0026#34;, name=\u0026#34;cube1\u0026#34;, position=np.array([0, 0, 1.0]), scale=np.array([0.5015, 0.5015, 0.5015]), color=np.array([0, 0, 1.0]), )) while simulation_app.is_running(): world.step(render=True) 运行一下，不难发现里面多出来了一个方块和一个地板，也就是这两行的效果。一个物体有两个经常使用的属性，一个是 Rigid Body，也就是物体是否会受到力的影响，一个是 Colliders Preset，也就是物体是否会有碰撞。DynamicCuboid 默认具有这两个属性，所以你会看到它掉在地板上，而地板是不受到重力影响的，所以你不会看到地板和物体一起掉下去。\n同时可以注意到的是 prim_path 以及 name，第一个描述了 cube 的 prim 的嵌套关系，因为 world 也是一个 prim，而这个物体的名字则叫做 cube1。\n同样的方法，我们可以在里面加入一个 Franka，这也不难：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 from isaacsim import SimulationApp simulation_app = SimulationApp({\u0026#34;headless\u0026#34;: False}) # we can also run as headless. from omni.isaac.core import World from omni.isaac.core.objects import DynamicCuboid world = World() world.scene.add_default_ground_plane() cube1 = world.scene.add( DynamicCuboid( prim_path=\u0026#34;/World/cube1\u0026#34;, name=\u0026#34;cube1\u0026#34;, position=np.array([0, 0, 1.0]), scale=np.array([0.5015, 0.5015, 0.5015]), color=np.array([0, 0, 1.0]), )) franka = world.scene.add(Franka(prim_path=\u0026#34;/World/Franka\u0026#34;, name=\u0026#34;franka\u0026#34;)) world.reset() franka.gripper.set_joint_positions(franka.gripper.joint_opened_positions) while simulation_app.is_running(): world.step(render=True) USD 是 Isaac Sim 保存数字资产的方式，想要使用 USD 也可以使用 Prim 来进行导入，这些内容我们都会在后续讲到，我在 Isaac Sim 里用五个长方体做了一个简陋的桌子，或许可供后续我的程序的例子中的使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 from isaacsim import SimulationApp simulation_app = SimulationApp({\u0026#34;headless\u0026#34;: False}) # we can also run as headless. from omni.isaac.core import World from omni.isaac.core.objects import DynamicCuboid import numpy as np world = World() world.scene.add_default_ground_plane() cube1 = world.scene.add( DynamicCuboid( prim_path=\u0026#34;/World/cube1\u0026#34;, name=\u0026#34;cube1\u0026#34;, position=np.array([0, 0, 1.0]), scale=np.array([0.5015, 0.5015, 0.5015]), color=np.array([0, 0, 1.0]), )) franka = world.scene.add(Franka(prim_path=\u0026#34;/World/Franka\u0026#34;, name=\u0026#34;franka\u0026#34;)) controller = PickPlaceController( name=\u0026#34;pick_place_controller\u0026#34;, gripper=franka.gripper, robot_articulation=franka, ) camera = Camera( prim_path=\u0026#34;/World/camera\u0026#34;, position=np.array([0.0, 0.0, 25.0]), frequency=20, resolution=(256, 256), orientation=rot_utils.euler_angles_to_quats(np.array([0, 90, 0]), degrees=True), ) world.reset() camera.initialize() camera.add_motion_vectors_to_frame() franka.gripper.set_joint_positions(franka.gripper.joint_opened_positions) while simulation_app.is_running(): position, orientation = fancy_cube.get_world_pose() goal_position = np.array([-0.3, -0.3, 0.0515 / 2.0]) current_joint_positions = franka.get_joint_positions() actions = controller.forward( picking_position=cube_position, placing_position=goal_position, current_joint_positions=current_joint_positions, ) franka.apply_action(actions) world.step(render=True) simulation_app.close() # close Isaac Sim ","date":"2024-08-19T09:20:00+08:00","image":"https://axi404.github.io/Blog/p/isaac-sim-%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/cover_hu14040113272813476576.png","permalink":"https://axi404.github.io/Blog/p/isaac-sim-%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/","title":"Isaac Sim 踩坑日记"},{"content":"前言 平时遇到一些奇怪的代码问题，记录并整理。\n博客渲染超时 在 Hugo 中，如果博客文章较多，渲染时间会非常长，导致渲染超时。具体考量可能是因为担心无限递归之类的，hugo 使用了粗暴的解决方法，超时就中断并且报错。所以解决方法也很简单，修改 config.toml 文件中的 timeout 配置项，增加渲染超时时间，单位貌似是毫秒。之前一直没有看 Github 详细报错，之前又出现过 Github Actions 瘫痪，我还以为又出现了，re-run 之后也就好了，估计是因为当初体量卡在临界点上，现在彻底超时了，也就发现了这个问题。\nCUDA \u0026amp; CUDNN \u0026amp; Pytorch 安装 因为之前的 Ubuntu 系统又因为我自己的不小心所以坏掉了，于是又一次尝试重装系统，但是出现了很多的问题。\n我的系统是 Ubuntu 20.04.6，在清华大学镜像站下载的最新版，电脑显卡是 NVIDIA GeForce RTX 3070 Laptop，可以支持 CUDA 12.2，在本段内容书写的时候，Torch 的官网使用的最标准的 pytorch 是 CUDA 12.1 的，所以安装这个版本，以及 9.3.0 的 CUDNN。\n首先给出下载 CUDA 和 CUDNN 的官网，其中 CUDA 12.1 为 https://developer.nvidia.com/cuda-12-1-0-download-archive，CUDNN 9.3.0 为 https://developer.nvidia.com/cudnn-downloads，之后依次选择自己的系统版本即可。其中 CUDA 的安装方法使用的是 runfile (local)，并且在此之前运行了 sudo ubuntu-drivers autoinstall 并重启以安装 driver。\n问题出现在，对于任何一个全新的最小安装的 Ubuntu 20.04 系统，在使用 runfile 的时候，均会报错，并说明在 /var/log/nvidia-installer.log 中可以看到详情，其最后为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -\u0026gt; Error. ERROR: An error occurred while performing the step: \u0026#34;Checking to see whether the nvidia kernel module was successfully built\u0026#34;. See /var/log/nvidia-installer.log for details. -\u0026gt; The command `cd ./kernel; /usr/bin/make -k -j16 NV_EXCLUDE_KERNEL_MODULES=\u0026#34;\u0026#34; SYSSRC=\u0026#34;/lib/modules/5.15.0-117-generic/build\u0026#34; SYSOUT=\u0026#34;/lib/modules/5.15.0-117-generic/build\u0026#34; NV_KERNEL_MODULES=\u0026#34;nvidia\u0026#34;` failed with the following output: make[1]: Entering directory \u0026#39;/usr/src/linux-headers-5.15.0-117-generic\u0026#39; warning: the compiler differs from the one used to build the kernel The kernel was built by: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0 You are using: cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0 MODPOST /tmp/selfgz3405/NVIDIA-Linux-x86_64-530.30.02/kernel/Module.symvers ERROR: modpost: GPL-incompatible module nvidia.ko uses GPL-only symbol \u0026#39;rcu_read_unlock_strict\u0026#39; make[2]: *** [scripts/Makefile.modpost:133: /tmp/selfgz3405/NVIDIA-Linux-x86_64-530.30.02/kernel/Module.symvers] Error 1 make[2]: *** Deleting file \u0026#39;/tmp/selfgz3405/NVIDIA-Linux-x86_64-530.30.02/kernel/Module.symvers\u0026#39; make[2]: Target \u0026#39;__modpost\u0026#39; not remade because of errors. make[1]: *** [Makefile:1830: modules] Error 2 make[1]: Leaving directory \u0026#39;/usr/src/linux-headers-5.15.0-117-generic\u0026#39; make: *** [Makefile:82: modules] Error 2 ERROR: The nvidia kernel module was not created. ERROR: Installation has failed. Please see the file \u0026#39;/var/log/nvidia-installer.log\u0026#39; for details. You may find suggestions on fixing installation problems in the README available on the Linux driver download page at www.nvidia.com. 经过检查，发现问题其实很简单，是因为 g++ 等版本为 9，太高了，设置为 7 即可。\n1 2 3 4 5 6 7 sudo apt-get install gcc-7 g++-7 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 9 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 1 sudo update-alternatives --display gcc sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-7 9 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 1 sudo update-alternatives --display g++ 之后再次运行，获得输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 =========== = Summary = =========== Driver: Not Selected Toolkit: Installed in /usr/local/cuda-12.1/ Please make sure that - PATH includes /usr/local/cuda-12.1/bin - LD_LIBRARY_PATH includes /usr/local/cuda-12.1/lib64, or, add /usr/local/cuda-12.1/lib64 to /etc/ld.so.conf and run ldconfig as root To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-12.1/bin ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 530.00 is required for CUDA 12.1 functionality to work. To install the driver using this installer, run the following command, replacing \u0026lt;CudaInstaller\u0026gt; with the name of this run file: sudo \u0026lt;CudaInstaller\u0026gt;.run --silent --driver Logfile is /var/log/cuda-installer.log 设置环境变量：\n1 sudo vim ~/.bashrc # or ~/.zshrc 之后在最后添加：\n1 2 3 export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64\\ ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} 之后再 source 一下：\n1 source ~/.bashrc # or ~/.zshrc 就可以正常的使用 CUDA 了：\n1 nvcc --version 输出为：\n1 2 3 4 5 nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2023 NVIDIA Corporation Built on Tue_Feb__7_19:32:13_PST_2023 Cuda compilation tools, release 12.1, V12.1.66 Build cuda_12.1.r12.1/compiler.32415258_0 之后的 CUDNN 以及 torch 的安装就是按照提供的正常流程进行，完结撒花。\n全部的指令包括以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 sudo apt update sudo apt upgrade sudo ubuntu-drivers autoinstall reboot sudo apt-get install gcc-7 g++-7 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 9 sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 1 sudo update-alternatives --display gcc sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-7 9 sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 1 sudo update-alternatives --display g++ wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run sudo sh cuda_12.1.0_530.30.02_linux.run sudo vim ~/.bashrc # or ~/.zshrc ### add following in .bashrc ### export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64\\ ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} ################################ source ~/.bashrc # or ~/.zshrc wget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-ubuntu2004-9.3.0_1.0-1_amd64.deb sudo dpkg -i cudnn-local-repo-ubuntu2004-9.3.0_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2004-9.3.0/cudnn-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cudnn wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh ./Miniconda3-latest-Linux-x86_64.sh conda create -n torch python=3.8 conda activate torch pip3 install torch torchvision torchaudio 之后在 python 中 torch.cuda.is_available() 返回为 true。\nUbuntu 22.04 三系统安装以及安装显卡驱动后无线网卡恢复 因为 Ubuntu 20.04 的若干的内容已经不再支持，使用起来最新的一些软件基本上全是报错，比较经典的就是 GLIBC 2.3.1 以及 libssl.so.3 等内容，而前者的安装十分的麻烦，所以干脆直接安装三系统。\n三系统的安装不是很困难，使用之前安装 Ubuntu 20.04 的 EFI 分区作为挂载点就好，之后在系统的 GRUB 界面就可以看到三个系统了。\nUbuntu 22.04 有一个比较经典的问题，就是安装显卡驱动之后，会导致无线网卡消失，按照正常的流程进行操作之后，运行 sudo ubuntu-drivers autoinstall 并且重启，再次进入默认的系统之后，就会发现网卡消失了。\n再次重启，进入 GRUB 之后选择 Advanced options for ubuntu，进去之后可以看到两个 Ubuntu 的版本以及对应的两个 recovery mode。两个版本里面比较新的一个是在安装显卡驱动之后新安装的版本，可以理解为显卡驱动对于较高版本的内核具有依赖，但是配套的无线没有一起安装，记下来两个版本的型号，然后选择较低版本的内核（不是 recovery mode）进入。\n进入这一内核之后，可以发现网卡是有的，但是使用 nvidia-smi，并没有正常的那个输出界面，因为这个系统中内核不满足显卡驱动的依赖，那么把这个系统的版本提上去就好了。\n使用 sudo dpkg --get-selection | grep linux 可以看到一些信息，其中一些项目包含版本号，有新版本的版本号，以及旧版本的，记下来这些旧版本的，并且使用 sudo apt install 安装使用新版本号覆盖旧版本号的这些内容。本人安装内容如下，作为参考：\n1 sudo apt install linux-headers-6.8.0-40-generic linux-image-6.8.0-40-generic linux-modules-6.8.0-40-generic linux-modules-extra-6.8.0-40-generic 再次重启，正常进入正常的系统，恢复。\n需要注意的是，越早设置这些内容，与本文档的对齐程度最高，本人的安装流程为，正常安装系统（将全部硬盘空间都挂在在 / 下）并设置语言为中文，进入系统之后更换语言为英文（因为不然的话输入法的安装比较麻烦），重启，将文件夹变为英文名，再重启，连接网络，sudo apt update 以及 sudo apt upgrade，最后就开始安装显卡驱动 sudo ubuntu-drivers autoinstall 并 reboot 重启。\n","date":"2024-08-17T17:30:00+08:00","image":"https://axi404.github.io/Blog/p/%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA%E7%9A%84-bug-%E9%9B%86%E6%95%A3%E5%9C%B0/cover_hu13695716010193172333.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA%E7%9A%84-bug-%E9%9B%86%E6%95%A3%E5%9C%B0/","title":"奇奇怪怪的 Bug 集散地"},{"content":"前言 简单来说，这是一篇成分复杂的文章，阅读到这篇文章的读者，多半并不符合这篇文章所属的条件。简单来说，需要是，你来自西安交大 + 你在校外出差 + 你在校内有跳板机 + 你需要使用校内服务器跑程序，不知道会不会对一些人有帮助。\n本人电脑小白一枚，所以使用的方法极有可能绕了远路，而且我没有 sftp 需求，也就懒得研究更加优雅的方式了，欢迎大家在下方评论进行补充。\n下载 Easy Connect 学校的 SSH 分为两种，一种是 WebVPN，只能活在浏览器里面，本质上是在一个浏览器里面套了个壳子，在里面访问校内网；另一种是 SSLVPN，通过 SSL/TLS 访问内部资源的方法。\n使用 SSLVPN，首先需要前往学校的官网，下载一种叫做 EasyConnect 的玩意，之后打开软件，会卡在一个获取登录配置的地方，在浏览器中进入 sslvpn 的官网，然后在学校账号认证界面登录，就可以成功进入某种内网了，此时可以连接跳板机了。\nSSH 之后就可以进行正常的 SSH 了，在这里因为是使用跳板机，对于 C:/Users/user_name/.ssh/config 进行修改：\n1 2 3 4 5 6 7 8 9 10 11 12 Host * ServerAliveInterval 60 Host jump_server HostName host_name User user_name Port port IdentityFile C:/Users/34064/.ssh/serect_key Host j67 HostName host_name User user_name Port port ProxyJump jump_server 其中前一个里面是类似组里的跳板机，于是使用组里面提供的地址以及端口和密钥来登录，之后的是正常的服务器，多了一个 ProxyJump 来表示使用跳板机。\n之后使用 ssh j67 就可以登录了。\n二次 SSH 由于跳板机只有特定端口的转发，而组里的跳板机连接的是一个 4*2080Ti 的服务器，我现在有一个能够用单卡 V100 的服务器，所以说要连接别的服务器。\n于是选择了比较愚蠢的方法，因为我当前这个服务器已经在校园网内，约等于我拥有了一个校园网内的终端，那么直接进行二次的 SSH 即可。在这里不得不提到 tmux，确实是十分实用的工具，不仅可以避免自己的程序被没有心跳信号杀死，也可以在一个 SSH 里面多开窗口，可以说十分的方便了。\n结语 感觉自己的这一套流程笨笨的，一套操作猛如虎，最后 SSH 确实很卡，毕竟套了好几层，不知道有没有更好的方法。\nUpdates 事实上发现自己可能确实笨完了，按照我们实验室的手册来说，确实是根据上述的流程才没问题的，但是事实上貌似只要开启了 sslvpn 之后就进入了内网。我使用的 4*2080Ti 的服务器是使用跳板机进行转发的（之前我应该也配置过，但是忘记了），然而假如说是正常的服务器，是不需要进入跳板机之后再二次 SSH 的，直接进行进行 SSH 连接即可，注意关闭自己的 VPN 程序即可。\n","date":"2024-08-16T20:51:00+08:00","image":"https://axi404.github.io/Blog/p/%E6%A0%A1%E5%9B%AD-vpn-%E8%BF%9E%E6%8E%A5%E5%AE%9E%E5%BD%95/cover_hu12825367815727053081.jpg","permalink":"https://axi404.github.io/Blog/p/%E6%A0%A1%E5%9B%AD-vpn-%E8%BF%9E%E6%8E%A5%E5%AE%9E%E5%BD%95/","title":"校园 VPN 连接实录"},{"content":"前言 在代表性工作之余，也有必要阅读一些其他的内容，这当然也需要总结，所以新开设一个章节，记录在这里。\nPointLLM PointLLM 可以是说十分标志的工作了，属于是中规中矩，但是效果确实很不错。就像是一般的 VLM 一样，但是只不过是将图像的模态输入换成了点云，然后使用 point encoder，总体来说改变并不算多。可以说这篇工作的诞生是符合直觉的，点云模态也可以作为一种语言进行建模。\nEmbodiedGPT EmbodiedGPT 也是一篇比较符合直觉的工作，但是不是那么的极简。本身是按照 BLIP2 的范式来的，用了一个 Embodied-Former（其实也就是 Q-former）来连接 ViT 和 LLaMA3，来做一个桥梁，之后输出一个 instance information，一个 CNN 处理图像输出一个 global information，两个 concat 一下作为 low-level policy 的输入。\n本身值得说的是，一方面这种设计，为什么不单独通过 embodied-former 直接输出的 instance information 呢？毕竟也是通过了 ViT 的信息编码的，之所以还需要一个 CNN，大概率是这样做了之后发现表征能力不强，所以需要更加显式的提供一些信息。\nRT-Trajectory RT-Trajectory 是一个输出 low-level policy 的模型，使用了 RT-1 的框架作为动作的输出，在此之前会输入之前和当前的帧以及一个工作轨迹，这里面动作轨迹通过 R 和 G 两个通道表征了时间顺序以及高度信息，和图像一起输入。因为从文字 prompt 改为了图像（轨迹），所以本质上具有更高的细粒度，性能更好也很正常。\nIm2Flow2Act Im2Flow2Act 算是一篇比较有意思的工作，本身应该是 ATM 的后续工作，不过因为糟糕的阅读顺序，我其实是先阅读的这一篇。\n因为确实需要的前置知识还是很多的，所以说先暂且形而上学的理解一下这个问题，后续估计需要详细的看一看相关的论文。Im2Flow2Act 的核心思想在于，首先根据任务生成对象流，对象流就具有很高的细粒度了，之后对象流通过模仿学习来获得动作规划。\n这篇工作使用了 Diffusion 里面的动作生成（视频生成）作为流生成的方法。首先先框出来一个物体，在物体上面可以采样若干的关键点，这些点就组成了一个 $H\\times W$ 的图片，但是这个图片不是正常的图片，和RT-Trajectory 里面的轨迹图片一样，是通过像素表征了别的信息，这里面就是图像系下的坐标和可见度。那么根据条件输入，就可以生成视频了，而这个视频本质上表征的是这个物体在不同时刻的空间信息。\n流生成了之后，基本上是直接使用模仿学习进行的运动规划，用了 Transformer 去编码当前帧的状态，再用 Transformer 去和任务流做融合，来生成剩余的流，最后交给 Diffusion Policy 去生成动作。\n粗浅的凑一下的话，创新性在于使用生成式的方法生成高细粒度的物体流，显然是优于 RT-Trajectory 的，同时第二阶段的时候使用当前的状态和任务流做融合，有一种 nav 中全局规划和局部规划的意味，但是并不完全。总的来说是一篇 based 轨迹的动作规划的很不错的工作，而且相较于 RT-Trajectory，更有细粒度，而且保证了公平性。\nLLARVA LLARVA 相较于之前的工作，可以说也是一个比较符合直觉的工作，使用指令调优（IT）的方法进行训练，也是处理了 OXE 这个数据集。从 Pipeline 也不难看出，LLARVA 是一个比较经典的架构，基本上也是 LLAVA 的框架，训练一个 projection layer 以及后面的 Transformer 做对齐以及模态的融合。\n其创新点其实有点 World Model 的意思，通过让模型预测将来的视觉轨迹这种更具细粒度的内容，之后输出 Action，这明显是一个更加困难而且包含了更多未来信息的任务，所以效果会更好也是显而易见的。当然，本身 IT 的方法，自然也可以让模型更好地完成任务就是了。\nATM 这篇论文可以说影响力还是很拉满的，对于后续的一些轨迹 based 的工作，比如 Im2Flow2Act，明显是有很大的影响的，本身也是拿了 RSS 的满分，不过因为理解了之前的这些论文，这一篇其实很好理解。\n本身的话，ATM 没有采取像是 Im2Flow2Act 一样的物体轨迹的预测，这也比较好理解，全局的点一方面或许可以具有全局的动作视野，而另一方面，全局的点也会比较好获取一些。本身的方法就是使用点跟踪的技术对图像里的点进行跟踪来生成数据集，然后让一个 track transformer 来预测点的轨迹。接下来就是一个正常的 Trajectory Conditional Policy，本身的实现，论文里也说了，也是使用 cls token 去做全局表征（ViT like），然后用了 track prediction 去作为额外的 condition 进行 fusion。\n从创新点来说，这篇算是开山之作之一了，引入了 Track 作为中间的表征以及条件，并且可以通过数据集的一些生成的技术进行标准的损失计算，因此在监督下训练提升的很好也是意料之中了。一方面增加了更具细粒度的输入，一方面这种细粒度也体现在任务的难度上（hard task），二者共同导致模型的简单易用。\nTrack2Act 老实说，我并没有感觉到 Track2Act 和 ATM 之间是否真的具有较大的差异，二者的方法实际上是近似的，也就是先预测轨迹，之后将轨迹作为动作生成的条件。首先还是进行点的预测，在这里使用的是 DiT，随机 sample 一些点和轨迹，然后就可以进行生成了，将当前状态、目标以及迭代次数都作为 adaptive conditioning 输入。\n有了这些点之后，就不难给出一个刚性变化了，然而刚性变化注定不太靠谱，于是乎加入了一个残差策略，再用另一个模型的预测来修正之前的结果。按照文章的表述，残差控制可以增加准确度并未首创，不过确实是一个纠正偏差的好方法，前面的轨迹生成并求刚性变化，获得一个变化之后加上残差，这本质上其实和 ATM 直接通过一个模型进行 action 的求解是等价的，毕竟刚性变化同样可以用模型来进行表征。\nExtreme Cross-Embodiment 这篇文章的感觉有点野心很大故事丰满但是后继乏力的感觉。基本的故事是说要实现一种跨不同机器人模态的表征学习，但是实际上只是视觉导航以及抓取这两种任务，甚至并不涉及灵巧手，这并不能算十分的跨模态。本身的想法就是说，移动和抓取的本质上都是让相机坐标系发生了坐标系变换，实际上是等价的（虽然其实并不等价，因为机械臂受到物理尺寸限制），所以说可以统一，然后就开始直接训练一个模型，输入是 state 和 goal，之后直接融合，获得两个目标，一个是机械臂的位姿（DiT），一个是距离的预测（MLP），也算是将这两个任务统一了一点。\n之前的任务，绝大多数都在处理单一的机器人下的任务，一般为机械臂，这篇的创新点也就止步于同时使用两种训练数据了。然而或许可以思考这样一个问题，假如说机器人的种类是可以穷尽的，或者说常见机器人的种类是可以穷尽的，一种 BEiTV3-like 的模型结构或许是可能的，直接在 Transformer 中引入 EMOE（Embodied MOE），然后同时使用这些全部的数据。\nECoT ECoT 这篇文章其实算是中规中矩，就是正常的 CoT，但是加入了 Embodied 的条件，能够 work 也是意料之中，或许其生成 CoT 数据的操作是可以借鉴的吧。\nVoxPoser VoxPoser 这一篇其实我不太理解，其本身是通过 LLM 以及 VLM 获取图像以及任务的表征，并且想要输出两张价值图，其中 VLM 是传统的 VLM，类似于开集检测器，可以获得物体的位置，之后 LLM 来去处理这些位置，获得两张价值图，这两张价值图进一步引导模型进行轨迹规划。疑点在于，整个的框架的表征被极大的压缩了，本来丰富的视觉特征被压缩到了必要的物体上，之后被 LLM 处理为了价值图，个人感觉这套体系并不稳定，任何一环出了差错，整体就崩掉了。然而使用价值图作为引导是值得参考的，这为模型的轨迹规划提供了更明确的提示。\nMOO MOO 的 pipeline 也很简单，本身甚至可以说设置了一个 hard task，而这都是为了设置一个通用的接口。因为 MOO 本身使用了 RT-1 的架构，所以可以理解为，其本身对于复杂的语言表征能力有限，而且不同的任务中，这些语言的格式可能也不相同。不过这个接口，我个人感觉就是本身就是 RT-1 已经具备的。\n大致的流程就像 pipeline 里面描述的一样，其可以将 Mask 作为一个通道融到图像里面，然后将动词提取出来。一个小的疑惑在于，比如说图中的任务，move 是一个向量，没有语序的话，模型如何理解这种顺序呢？然而这并非这篇论文核心探讨的问题，所以其实也无所谓。\nChatGPT for Robotics 本身可以理解为使用 ChatGPT 去做机器人的一个发散性的思考，同时提出了诸如 PromptCraft 之类的工具。\nPIVOT 这篇文章的思想还是比较有趣的，也算是充分利用的 MLLM 的 VLM 能力。本身的思路其实在于，让大模型在具身智能的任务中进行生成式不太靠谱，但是去做选择题还是可以的。于是可以先随机 sample 一些动作或者轨迹，之后将这些内容 annotate 到图片上（与 CoPa 同理解，VLM 的 V 更具有空间的表征能力），让模型选择，然后一次次的选择即可。\nCode As Policies 这篇文章的思路也很简答，就是可以使用代码来控制机器人，这等于可以让 LLM 与环境进行持续且合理的交互。大模型可以通过调用 API 来获取环境信息，比如说调用视觉 API 来获取物体位置，同时也支持了使用一些比如 for 之类的操作，毕竟代码肯定比一次次的生成式更加有条理。\nMOKA MOKA 的思路其实本质上和 CoPa 以及 PIVOT 是十分类似的，都是使用 Prompt-based 的 VLM，通过将不同的选择 annotate 到图像上，并且让模型进行选择，从而进行路径的规划。MOKA 等于说是希望通过若干的点标注，让模型学会如何去完成动作。所以流程上也是首先先找到需要操作的物体，然后再采样抓握点以及路径点之类的，最后结束。甚至说虽然 MOKA 里面没有明说，但是实际上其对于抓握点进行 filter，并且通过 filter 获得抓握姿态，这个流程实际上和 CoPa 可以说是一模一样，只是说 MOKA 希望通过路径点来完成动作，而 CoPa 则希望通过向量来完成动作。\n","date":"2024-08-16T10:00:00+08:00","image":"https://axi404.github.io/Blog/p/llm-talk-2/cover_hu777989237795605153.jpg","permalink":"https://axi404.github.io/Blog/p/llm-talk-2/","title":"LLM Talk 2"},{"content":"前言 上次培训虽然已经相隔许久，但是想必大家也还记得 Linux 系统的概念，这种开源内核的系统对于视觉组所需的程序的开发极其便利，而视觉组的全部代码也均部署在 Linux 系统中。\n本次培训，\n","date":"2024-08-13T16:12:00+08:00","image":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%B8%89%E6%AC%A1%E5%9F%B9%E8%AE%AD/cover_hu3262847341838353640.png","permalink":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%B8%89%E6%AC%A1%E5%9F%B9%E8%AE%AD/","title":"RoboMaster 视觉组第三次培训"},{"content":"尽管做过很多的期待，但是第六周的故事实际上确实枯燥无趣，几乎没什么可说的，不过为了记录生活，还是勉强记录一下吧。\n学业 RoboMaster RM 一直打到周六，最后也算是尘埃落定，虽然没有晋级八强，但是在十六强的时候也赢了一局，也算是破除了之前的魔咒了，姑且也算是队史的最好成绩了。\n可以说的是，这一周以来实际上我做的事情不算很多，一方面算法的稳定性确实很不错，另一方面英雄的主要任务确实也不是打前哨站。我在视觉组的组员兼同班同学 LXW 确实在自瞄方面做得很不错，无论是哨兵还是无人机，都是可以推掉前哨站的，而英雄又在吊射方面如此出色，前哨站的任务也就不主要交给英雄了。不过到了后面，自瞄体系的不稳定还是时常发生（指体系，如机械电控等问题导致视觉算法的效果不好，也很有可能），而且也伴随着战术的调整，英雄的反前哨站也就再次被提上日程了。\n姑且也算是一种释然吧，最后自己写的东西还算是派上了用场，虽然说最后输了，但是前一天晚上依然查出来电控那边的一个奇怪问题，也算是为后面做了一点技术积累。\n其实我也不是很确定自己是不是要继续打下去，但是既然自己已经是组长了，假如说没有人打算接任这个位置的话，大概率还是我继续顶上去。\n一些反思也会后续写在 RM 回忆录里面，但是在这里也姑且说一下。事实上今年的视觉组安排的不是特别好，一开始我的想法是，视觉组的任务太无聊了，我希望大家做一些更有意思的东西，甚至说讨论一下学术也是可以的，但是一方面确实任务还是很紧，而且在西交这样一个课内压力大的环境下，本科科研就已经很过分了，更别说在这样一个社团里面，大家聚在一起做一些讨论。\n本来我一直想的是，将自瞄这件事情基本上都由我负责，然后我拉进来的同学 LXW 负责协助，这样子两个人压力可以少很多。然而事实上因为上半年深度参与科研的原因，自瞄这部分很显然又出现了去年的情况，LXW 一个人做得太多，导致别人已经无法跟上他在做的东西了（这并不是指算法的困难，工程代码我从未要求过规范性，现在基本上还是以能跑通优先，所以每个人的风格不一样，也就很难看懂），这下压力就到了他那边，而我也就换到英雄反前哨站的工作了。\n但是说到底，这一年来我的工作其实还差不多，假如继续连任的话，一方面大三下确实磨不开时间，包括实习的一系列事情，会让我难以参加国赛，然而另一方面，我的重心可能会放在对于代码规范的整理以及文档的编辑中，之前的程序实在是太过于野蛮生长，急需一次收束。从这个赛季的结果上来看，可以说的是，视觉组的全部任务基本都完成了，后续的完善固然可以让这些老队员继续负责，然而我想将之转化为更加规范的工作。现在存在的一些缺陷，其中有部分，我依然有必要怀疑电控的水平（并非专业素养，而是代码中确实存在 corner case），这些都需要后面缓慢的对齐。\n如何如何，反正一年的劳作，终于也算是尘埃落定了，用心写的算法拿到了对应的结果，也算是给了那些新队员一个交代。\n签证 这个星期另一件在忙的事情就是签证，因为这个事情我确实没有自己做过，尽管现在是和两个师兄一起进行团体签，但是心里确实还是没底，截止到周日晚上，材料也算是准备好了，就是不知道后续具体是不是还会少东西，这里还是要打一个问号。\n假如一切顺利的话，我后续应该也会单独写一篇文章来记录一下，对于本校本专业的学生应该是有帮助的，毕竟给我的感触，难点之一固然是材料的繁琐，但是另一大难题，还是在于学院的老师踢皮球，让我无从下手。\n科研 这周的 offer 也算是正式发下来了，把一些资料填写了一下，之后也就进了浦江实验室的 oa 流程，车票订的是下个星期二，也就是签证的下一天，然后星期三到，计划是和绿群的群友晚上一起吃个饭（我在考虑是否要赠送女装照作为见面礼），然后第二天去入职。不过需要在这里提醒我自己的是，入职需要的材料最好别忘了，尽量在西安的时候处理完，学校里的打印机还算比较多，不然去了上海之后就麻烦了。\n因此，顺便加了老师的飞书，老师也给我分享了文档，让我去读一些文章，基本上来看，老师就是 Yilun Chen 了，老师本身的实力也很强，也算是希望能做一些有影响力的工作吧。不过老师竟然说要讨论一下，可能我还是要看完这些论文，我论文的积累量确实不多，现在还剩下八篇，但是基本上已经轻车熟路了，希望可以按时完成。\n在 Sanping Zhou 那边的课题来说，计划是投 ICLR，不过我目前发现了模型的一些问题，可能基础的代码还要再跑一跑，来看看最后的效果，希望没问题。\n","date":"2024-08-12T03:18:00+08:00","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week6/cover_hu13135602832655834378.png","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week6/","title":"周记 Week6"},{"content":"前言 本篇内容是因为本人在 LLM 的学习过程中，有学到不同的东西，所以需要一篇文档来总结一下，顺便也作为一个分享。本篇内容不会过多的讲解方法本身，相应的，会给出一些 insight 和思考。\nNoting 的是，全部的内容都是直接基于论文阅读的，参考资料中提及的内容指，这些内容或许能够帮助读者进一步理解论文里说的内容。大的基石还是论文。\n由于博客本身的特性，因为在标题中添加了论文链接，想要跳转请点击目录中的序号，不然会跳转到论文中。\nBOW BOW，也就是 Bag of Words，是一种十分简单的模型，简答来说就是将一句话使用词的形式进行分割，然后用键值对的形式进行储存。这样做的一个显然的结果就是，词袋模型并不能很好的建模语言的顺序，但是作为一种最为初级的 tokenizer 来说也已经很不错了。\n所以很显然，词袋模型的第一个通病，就是处在无法对于语序进行建模这个问题上，而且同时，可以理解为这个模型是使用一种表格来进行表示的，这种表格是 one-hot 且离散的，本质上也没有很好的建模语言。\n词袋模型的一个 trick 在于处理过大的词表，可以使用 hash 的方法，更好的利用空间。\n参考资料：\n词袋模型 - https://en.wikipedia.org/wiki/Bag-of-words_model Feature Hash - https://en.wikipedia.org/wiki/Feature_hashing TF-IDF TF-IDF 可以理解为是一种对于知识库中的文档中的词汇的重要性的建模方法。这个思想十分简单，也是由两个因素组成，TF 和 IDF，前者用来形容一个词汇在文档中出现的次数，后者则是使用了这个词汇的文档的次数。但事实上其中使用了 log 与乘法等内容进行数学形式的计算，不过这里只讨论 insight。\n这种方法很好地体现了一个真正的关键词汇，在文档中所需要包含的特征。首先，这个词汇一定会被反复提起，因此这个词汇与文档的关联性才高；同时，这个词汇不会被太多的文档所提及，假如被被提及太多，意味着这个词汇丧失了独特性，诸如人称代词等一系列内容，均符合 TF 的描述，因此需要 IDF 来进行 filter。\n参考资料：\nTF-IDF - https://www.cnblogs.com/L-shuai/p/13817978.html Word 2 Vec Word 2 Vec 是一种用于生成词向量的技术，它通过将词语映射到一个高维向量空间中，使得语义相似的词在向量空间中距离较近。其中比较常见的是 skip-gram 和 CBOW 两种模型，前者是使用词预测上下文，后者是使用上下文预测词。简单理解一下方法的话，CBOW 是输入一个词（one-hot 向量），然后经过编码，再解码为一个向量，最大化上下文的概率；CBOW 则是输入上下文，最大化词的概率。这两种方法显然都可以很好的训练编码器，也就使得词汇被编码到了一个连续的高维空间中。\nWord 2 Vec 的一个 insight 是，它将词映射到了一个高维空间中，而高维空间中，距离较近的词，语义上更相似。因此，这种思想可以拓展到其他领域，例如图像，声音等等，将不同模态的信息映射到同一个高维空间中，然后进行相似度的计算。\nCLIP CLIP 在某种程度上也可以说是一个开山之作，虽然说对多模态的探索早在它之前就已经开始了，然而不只是数据量很大，本身对于内容处理的范式也使得 CLIP 极具拓展性，可以在很多任务中泛化。\n简单理解一下 CLIP，也就是使用一个图像编码器和一个文本编码器，对于一组图像文本对进行编码，然后获得输出。接下来就是对比学习类型的工作了，需要清楚的是，相匹配的图像文本对一定是在编码之后相似度很高的，那么直接对大量输出之间的余弦相似度进行优化，是一个显然的答案。\n这里面激动人心的事情，一是在进行混合，或者说再进行多模态的相似度求解的时候，可以直接使用余弦相似度这种这种方法，这证明这些编码器在经过大量数据的训练之后，确实可以将不同模态的输入投射到一个通用的 high-level 空间中。事实上由于大多数的论文都是从故事说起，因此可能会忽略，尽管在人类的概念上图像和文本可以统一于一个高层的思维中的概念，然而这种表示，在使用数学或者计算机形式的信息时是否成立，这依然是一个问号。不过从目前的实验结果来看，答案是肯定的，而后续的一系列工作也证明了，不只是图像与文本，不同的模态之间确实可以具有一种数学意义上的高维空间中的统一。\n当然同时，CLIP 的 prompt template 进行 zero shot 分类的技巧也同样令人印象深刻，这本质上是对于 bert 范式在多模态领域对一种拓展。后续的工作中也涌现了一系列的对于 prompt 的应用，然而这是后话了。\n参考资料：\nCLIP - https://www.bilibili.com/video/BV1SL4y1s7LQ/ ViLT ViLT 也算是比较经典的多模态领域的工作了，这里面需要说的东西其实不多。首先需要先理清一些常规的内容，也就是 ViT 和 Transformer 在形式上究竟有什么区别。假如说我们不去关注这两个模型的输出，一个显而易见的事情是，他们的不同点仅仅在于模型的输入部分，当然对于输入的处理也有所不同。具体来说，在文本的部分使用了 tokenizer，还在图像的部分分 patch 变成 token 之后进行了一次简单的编码。借用一下后期的 insight，假如不去在意这种简单的编码的性能，已经可以理解为，视觉信息本身就是一种语言。\n这篇论文首先总结了之前的工作，然后给出了一个双塔的模型的对比。具体来说，双塔的多模态模型有三个组件组成，分别是文本编码器、图像编码器和多模态编码器，这其中，这三个编码器的大小也就成了一个问题。首先需要考虑的是，当我们有固定的算力的情况下，我们应该如何分配算力给三个模型。一种最为常见的做法，是把多一些的算力分配给图像，这是由于图像本身就具有更难的编码难度，然后将两个编码器在多模态上进行简单的融合 ；之后也就是 CLIP，属于是用了一个文本和图像都很大，之后在多模态进行一个简单的编码。但是一个直觉显然是，作为多模态的任务，我们需要将多模态的进行更好地处理，给足算力，因为真正的多模态的理解，不是像 CLIP 一样进行简单的高维表征的融合，而是直接从低维信息中直接获得高维的多模态理解。所以说显而易见的，可以直接将多模态的部分变成一个 Transformer，然后将不同模态的数据进行简单的 tokenize 之后就 concat 作为输入。\n在这里提供了几个 insight，其中之一是，尽管我们认为 ViLT 的这种做法比较符合直觉，但是很明显它缺乏一种泛化能力。在已经训练好的模型的基础上，假如新加入一种新模态，例如语音，ViLT 就需要重新进行一次训练，而 CLIP 将新的编码器 align 到之前的空间中即可，原来的编码器可以 frozen。虽然说这种方法并不优雅（因为三个模态同时进行训练，所获得的图像文本编码器的权重，肯定和他们两个进行训练的时候不一样，这也是因为对于三模态的输入来说，最后获得的那个高维空间，本身也会具有新模态的含义，但是尽管如此强行的对齐依然是可以的），但也能反映出来泛化能力上的不同。\n另一方面的几个小技巧，包括说对于图像使用数据增强（因为没有繁重的图像编码器，所以不同于之前的方法将编码后的特征储存起来使用，ViLT 作为端到端的模型，可以直接使用图像，那么图像增强就有必要了），同时避免使用 cut 以及 color 类型的增强。\n参考资料：\nViLT - https://www.bilibili.com/video/BV14r4y1j74y/ ALBEF 介绍一下 ALBEF，这份工作可以说也是很经典的内容了，基本来说，符合了前人工作的几个共识。首先就是，一般来说，图像编码器需要大于文本编码器，同时的话，多模态的编码器也要尽可能的大，于是使用了 12 层 Transformer 作为图像编码器，6 层文本以及 6 层多模态。同时也是用了 ITC/ITM/MLM，这几种经典的任务。\n其中一个创新点在于 hard negative，也就是从 ITC 中选择最相似的难样本作为 ITM 的 negative；同时还有一个，也可以理解为是自学习或者自蒸馏，反正就是加入了一个 MT 来获得稳定表征。这里面需要注意的是，事实上在训练的过程中，数据的噪声巨大无比，而且不一定准确，因此加入一个 MT，已经不是在单模态里面的那种简单平均了，而是甚至可以生成质量远高于当前 GT 的标签，这一点在后续的 BLIP 里面也有体现，也可以说是对于数据的处理。\n但是进行一个简单的拓展，之所以使用动量的方法，本质上还是因为它是 one- stage 的，假如说使用 noisy student 那种，每训练完一个模型再作为 Teacher，肯定也是没有问题的，在这里，BLIP 似乎更加出色，后续去说。\n参考资料：\n多模态串讲 - https://www.bilibili.com/video/BV1Vd4y1v77v/ VLMo VLMo 也可以说是一个比较经典的工作，其中提出的主要就是 MoME，但是这里面，MoE 的experts 是模型自己去选择的，而在这个里面则是手动的进行切换。\n大概的结构就是一个 L 层的 Transformer，但是其中的 FFN 都被换成了多个 FFN 的形式，然后在训练的过程中决定使用哪一个。\n这里面的一个 insight 在于无需使用多个 attention block，而是说确实一个 attention 就可以处理完全部内容了，而且不同的 FFN 也可以接收同样的输出，并根据自己的模态进行理解。\n那么对于这三个经典的 loss，ITC 可以分别激活图像和文本，最后算损失；ITM 先分别激活图像和文本若干层，之后再全交给多模态；MLM 同 ITM，从图上看起来还是十分优雅的。\n最后，这个预训练的策略也比较有意思，属于是采用了分阶段训练，首先用图像数据训练图像 FFN，之后是文本，在经过了一定量的预训练之后，才是多模态。在这个里面需要注意的是，图像和文本的顺序不能换，不知道具体是因为什么。\n参考资料：\n多模态串讲 - https://www.bilibili.com/video/BV1Vd4y1v77v/ BLIP BLIP 可以说是我比较喜欢的一篇工作了，当然，基础的模型结构并没有很大的创新，本身还是 VLMo 的框架，贡献了 attention block 的参数，但是把 MLM 换成了 LM，所以这里的参数不能共享，换成了一个 casual attention。\n这里面我非常喜欢的一个设计，就是它的 caption-filter 框架。这种设计其实在 ALBEF 里面已经体现出来了一些，也就是我前面说的使用 MT 的方法。但是事实上，这种方法并不完全的优雅，尽管是 one-stage，但是或许效果并不如 two-stage，更何况本身还是完全的套用之前的范式，属于是意识到了 noisy 和 pseudo label 的潜力，但是并没有完全发挥。\n那么，BLIP 的这个框架就不一样了。首先是一个 two-stage，这一点无伤大雅，正如我所说的，one 和 two 的区别并不是很大，甚至说 EMA 唯一的意义在于维护一个 bank，其他情况下完全可以想象，性能应该不如 two-stage。\nBLIP 的重点在于，ALBEF 只关注到了 MLM 生成的高质量，然后就直接融合进去了，这种粗糙的融合固然是可行的，但是效果不一定特别好，只能说是缓解了 noisy 的情况，因为 noisy 依然存在，只是因为 MT 的权重而被稀释了。那么一个更彻底的方案就是进行 filter，BLIP 巧妙的注意到了这种 filter 的需求和 ITM 的任务惊人的相似，于是使用 LM 进行 caption，把 caption 和 GT 一起交给 ITM 去二选一，这样最后的结果就会很好了。\n参考资料：\n多模态串讲 - https://www.bilibili.com/video/BV1fA411Z772/ CoCa CoCa 可以说和 ALBEF 十分的相似，基本上就是和 ALBEF 一模一样，但是 CoCa 的关注点在于，之前的工作，虽然看上去从 pipeline 里面都是同时进行的输入，但是实际上在一个 iteration 里面都是经过了很多次的 forward，而 CoCa 则是希望，在同一个 iteration 里面，所有的 forward 都只进行一次，也就是所谓的 one-pass。\n方法也十分简单，既然 one-pass 了，那么 scale 上去很多数据就会方便很多，毕竟计算快了很多，于是直接对文本输入直接采取 casual-attention，也不需要管数据的损失，算就完事了，于是任务也变成了一个 Co 和一个 Ca，也就是 contrast 和 caption。\n所以说白了其实带来的 insight 不算多，一方面 ITC 确实有效，一方面 LM 也是一个难任务，但是在诸多 trick 之上，CoCa 的 large model 以及 scale up 的 data 显然为其性能带来的更大的影响。\n参考资料：\n多模态串讲 - https://www.bilibili.com/video/BV1fA411Z772/ BEiT V3 可以说 BEiT V3 本质上和之前的 VLMo 是十分类似的，但是区别在于，其只采用了一种任务，也就是 LM 任务，这自然也增加了运算的效率。之后就是通过大量的数据，以及不同 FFN 的激活，来在不同的的任务里面训练，可以说是十分的简洁。\n这篇说白了也就是一个 insight，也就是阐述了 MoME 在 LM 任务下 scale up 之后确实很强，同时当然，这些 MoME 依然可以组合，再去 transfer 到不同的下游任务里。\n参考资料：\n多模态串讲 - https://www.bilibili.com/video/BV1fA411Z772/ BLIP2 虽然说名字叫做 BLIP2，但是实际上感觉模型的结构上区别还是很大的，只是说任务比较类似而已。\nBLIP2 的主要贡献，以及 motivation 在于，之前的模型，都是全部由自己训练的，无论是效率还是算力之类的，开销都很大，而目前领域内已经有了很多的性能很好的模型，于是直接 frozen 之后拿过来用就好。于是提出了一个 Q-former，可以对于 frozen 的图像 encoder 以及 LLM 起到桥梁的作用。\n训练还是一个 two-stage，这里面 stage-1 和 stage-2 的图画的其实很迷惑，因为 Q-former 里面本质上是有两个 Transformer 的，那么后面在 stage-2 的输出，是两个 Transformer 的 concat 还是什么，就很神秘。这里一篇 csdn 的博客 的图很不错，事实上拿的是 queries 输入的那个 transformer 的输出。\nStage-1 和正常的 ALBEF 区别不大，之后 stage-2 把输出过 MLP 送给 LLM，再进行训练。本质上假如没有 Stage-2，那么就是一个 ALBEF，而假如没有 stage-1，则是一种新的范式。那么能否抛开 stage-1 呢？毕竟 stage-2 也是一个完整的训练流程，而且也是多模态的，但是实验表明不行。一种理解是，在 Q-former 里面之所以要引入一个文本编码器，目的就是通过 stage-1 的各种任务，让图像端的 Q-former 和文本对齐，换句话说，这个 token 输入给后面的 LLM 的时候，模型说的是人话，而不是图像话，毕竟后面跟的 MLP 只是为了统一维度，本身与文本类似的语言表征，还是在 Q-former 里面进行建模的。比起来能够将两个模型拼起来，我觉得还是这个 align 的启发更大一些。\n参考资料：\nBLIP2 - https://blog.csdn.net/LoseInVain/article/details/136013909 LLava LLava 比较简单，主要是提出了一种只使用 GPT 的文字功能，就可以生成高质量 caption 的方法，简单来说，对于具有 captions 和 bounding boxes 的内容来说，其实际上具有更多的信息量可以挖掘，所以可以生成一些高质量的 hard task。\n模型的结构就是一个 image encoder 之后跟一个 MLP 来映射，然后一起输入到 LLM 里面。依然训练是 two-stage 的，首先只训练 MLP 来对齐，之后训练 MLP 和 LLM 来适应具体任务。\n本身的 insight 一方面对齐不需要很强的表征能力，MLP 已经足矣；另一方面高质量的数据很重要。同时 LLava 用的各种 prompt 自然也很有参考价值。\n参考资料：\nLLava - https://blog.csdn.net/qq_35812205/article/details/136586853 RT-1 RT-1 讲实话结构并不是很好，但是一是在于数据量大，二是在于在实体跑起来了，于是的话，参考价值也挺高。简单概述一下结构，是用卷积 + FiLM 来进行的文本和图像的融合，文本编码器的输出用来作为 FiLM 的参数，然后调制卷积。之后获得 Tokens 再过 TokenLearner，输入进一个 transformer 里面，获得最后的自由度。\n这种架构在当下貌似已经不流行了，所以说一下局限性，也就当作是 insight 了。一是在于，在数据量巨大的情况下，多模态基本就是撑死胆大的饿死胆小的，这种复杂的结构，本质上还是担心模型的表征能力不强，或者模型没有能力输出自由度这种级别的信息，但是显然从后面来看实在是多虑了，transformer 确实有大一统的潜力。二也是在于，这种设计其实封死了后面的拓展性。机器人的数据肯定是稀少的，遥想当初 VLMo 就是通过引入单一的视觉和文本数据来进行 scale，而 RT-1 则是完全不给除了自由度之外的数据留活路了，于是后面就很难再进行拓展了。\n参考资料：\nRT-1 - https://zhuanlan.zhihu.com/p/652897511 RT-2 RT-2 的结构就十分的合理了，使用一个大的 transformer（其实也就是 LLM）接收文本和图像的编码输入，之后获得特殊的 token 用来表示动作，就可以直接进行控制了。这种操作使得其可以同时使用多模态的数据以及机器人的数据，所以说 scale up 的效果非常不错，剩下的就不需要过多赘述了，就是正常的训练。\n参考资料：\nRT-2 - https://zhuanlan.zhihu.com/p/651670131 VIMA VIMA 也算是比较早期的工作了，没有使用 LLM，但是是有一定的可取之处的。首先是在于使用 object token，object token 的生成在使用 Mask R-CNN 之后包含图像信息即 ViT 编码之后的结果以及 bounding box，可以说同时包含了物体和位置信息，之后还储存了一些历史信息，可以进行长任务。虽然说 RT-2 也可以上下文理解，但是 VIMA 直接使用原本的信息，肯定表征更多一些。\n一个 insight 是 object token 肯定是一种很好的方式。以往的多模态输入都是先图像后文本，object token 将两个交叉在一起，肯定会有更好的效果，也更加将图像融入了文本的体系里面，是否有更加优雅的方式来进行 object token 的生成或许会是一个问题。\n参考资料：\nVIMA - https://zhuanlan.zhihu.com/p/659016759、 SayCan SayCan 可以说是在做这种规划任务里面比较早的了，但是也存在一些问题。首先大概的流程就是，先把需求提出来，这个时候模型本身存在一个动作空间，那么 LLM 就可以从这个动作空间里面给出不同的推荐，但是一个问题在于，由于 LLM 不清楚当前的情况，所以说可能无法很好地给出能够执行的结果，这个时候可以使用另一个模型，或者说是一个价值函数，来去评判在当前情况下这些动作的价值。那么这个价值函数是使用了环境信息的，价值大模型的推荐结合在一起，就生成了一个布置合理，而且可以完成的动作。\n这里面的 insight 其实不多，或者说显而易见，想要让 LLM 去参与到动作的生成，固然其本来就具有一定的规划能力，但是这种能力在没有现场情况的了解下是施展不开的，于是可以简单地使用价值函数来作为一种当前情况的引入，本身需要训练的东西也很少，可以说是十分的轻量化。\n参考资料：\nSayCan - https://zhuanlan.zhihu.com/p/655418399 Language Models as Zero-Shot Planners 这篇文章也是在 planning 领域的内容，某种程度上也可以说是 low fruit，甚至说不需要任何的训练，就是纯粹的 prompt，不过目测感觉还是要经过一些 finetune 的。\n大概的思路就是，先让一个模型给出一些计划，然后这些计划通过另一个模型翻译成在 action set 里面的最接近的内容，然后执行。唯一不多的 insight 在于 LLM 通过 high-level 的交互就可以进行近似输出。\n参考资料：\nLanguage Models as Zero-Shot Planners - https://zhuanlan.zhihu.com/p/656399047 PaLM-E PaLM-E 可以说就是就是对于上述种种猜想的一个实际的体现，也就是说一方面仅仅通过多模态的 prompt 进行输入，这里面的输入包括文字/环境/图片，也就是全部的模态，之后输出的是 high-level 的 planning，再由其他的执行器去完成 low-level policy。\n参考资料：\nPaLM-E - https://zhuanlan.zhihu.com/p/662935514 ViLA 讲实话，我不是很理解 prompt 类型的工具，不过确实一些这种类型的工作可以有非常好的性能。总体来说，ViLA 输出的也是 high-level 的 policy。大概的流程就是输入当前的图像以及任务，还有历史上已经完成的任务，然后交给 gpt-4v，使用 CoT 分析一下当前的场面，然后结合分析给出动作，再交给执行器。\n个人感觉 prompt 类型的工作实际上还是解决任务，而没有带来比较振奋人心的 insight（当然，CoT 这种属于出色的 prompt 工作），这毫无疑问是令人沮丧的，但是确实也刷新了性能，并且有效利用了那些已经性能很好的工作。\nCoPa CoPa 的工程感更足，把大量的模型结合在一起。总的来说首先是一个物体抓取，接下来是路径规划。对物体抓取，CoPa 给出了一个从粗到细的分割流程，具体还是使用 SAM 和 gpt 配合，最后筛选出来一个抓取的细节部位，然后用抓取姿势的生成器生成姿势。就有点类似于把锅拿起来，需要握住的是锅把一样。接下来是一个路径的规划，这里面也是先识别了各种物体的位姿，然后将这些内容画在图上，估计这种选择是因为不信任大模型的数学能力，反而是图像比较直观，容易理解。之后通过这种细粒度的指示，大模型就可以给出更加合理的建议，类似于之前是将锤子放在钉子上，现在可以是将锤子和钉子对齐，而且根据识别的位姿，或许可以精确到距离。然后交给执行器。\n一个 insight 是对于细粒度信息的追求，很多时候直接的训练不能获得到这么细粒的信息，而 VLM 也不具有这种表征能力，所以说这种用其他模型的表征方式或许确实无法替代。\n总结 在阅读了诸多的内容之后，我发现了几件事情是大的趋势以及必要的。\n首先是多模态输入的必然性，这里指交叉输入的多模态，将图像或者物体也作为 token 进行编码；其次是对齐的必要性，多模态具有不同的编码器，在这里，无论是直接训练 encoder 还是训练一个 projection，都是有必要将语言之外的模态映射一次的，也就导致大多数训练都是 two-stage 的。\n","date":"2024-08-08T22:34:00+08:00","image":"https://axi404.github.io/Blog/p/llm-talk-1/cover_hu14717558460103327451.jpg","permalink":"https://axi404.github.io/Blog/p/llm-talk-1/","title":"LLM Talk 1"},{"content":"跟着队伍去深圳打 RoboMaster，本来是想好好静下心来读读论文，奈何着天气太燥热潮湿，让我心头也浮躁，总想写点什么东西，于是想起来之前说的，正好现在时间也合适，不如写一篇 RoboMaster 回忆录，记录一下，这贯穿我人生五年的比赛。\n高中概况 说起来是比较抽象的，大多数人参加 RoboMaster，还是只有一年或者两年，自然也不难理解，大一或者大二加入，打到大三大四，最近可能会有四年的，但本身大一的梯队留下来的就不多，而直接成为正式队员又太难，所以还是以两三年为主。\n那假如说广义的 RoboMaster，那么我已经从高一就开始接触了，大概是由于什么北京的所谓素质教育，而且高中里面就存在着一些科技向的社团，有着很优秀的老师，也让我有了接触这些机器人比赛的途径。不过说到头，这些比赛真的是素质教育吗？我看也未必。\n感觉到了最后，就算我拿了省冠军，倒也没有什么作用，毕竟确实技术难度很低，远远远远低于奥赛一类的竞赛，而又需要投入成本，大多数学校也负担不起，不够亲民。\n所以说到底，机器人比赛还是一些富裕地区的富裕学校小打小闹的产物，让学生们体验一下一些创造感，虽然貌似这些技能在大学中的同样类型的比赛中还能起到作用，然而个人的感觉是，相较于大学中的那些专业竞赛，此类比赛依然算是小打小闹。\n高中的时候我还觉得我自己多少有些天赋，自认为是要裸分上清北的，平时和那一帮学霸一类有说有笑，虽然成绩不是最顶尖那一批，但是课余时间的松弛感还是和他们对齐了。我和我的胞弟是同等岁数，在大学期间加入的社团也并非机器人社，而是自己出钱捣鼓一些桌游，创办了一个桌游社。说起来这个社团现在应该依然存在，我们当初留下来的桌游估摸着价格也有大几百元，对于一个月生活费只有五十元的高中生来说，可以说是一笔慷慨捐赠了。\n我所在的高中有一种实验班，叫做项目实验班，其实有点类似于培养学生的科创能力那种感觉，而是事实上，聚集的就是那一帮想考理科实验班，但没进去的学生。\n我记忆里面真正有项目能力的同学，可能不超过五个，其他的人基本还是经典的做题家，到了毕业，说不定也不会工程制图，代码也写不出几行，当时还没有 GPT，那大伙的水平还要再降一等。\n项目实验班有一系列的创客课程，类似于物化生信，选择一个感兴趣的方向，几个同学弄一个小的发明创造，当然也不全是创造，基本就是在网上已经有的东西，大家用一个学期跑一遍流程。\n别的不说，我从小应该还算对电脑接触得很多，不是那种单纯的手机用户。在这里并没有鄙视的意思，然而个人感觉，在同时具有使用电脑和手机的条件下，基本只使用手机，而从未接触过电脑，这种人到了大学里面，能力都很差。不少人是本来电脑接触的就不多，开始接触了之后也就了解了其中魅力，更是变成了很厉害的水平，这种自然不在上述范围之内。\n虽然我之前使用电脑，最最主要的可能还是以玩游戏为主，然而为了玩游戏（我的父母均是北邮研究生毕业，那时候北邮的分数和北大可能都差不多，毕业可以去 Oracle/Microsoft/IBM 这种国际大厂，在互联网行业从业三十多年），和父母斗智斗勇，可不只是删掉浏览记录，并且让电脑凉下来这么简单，还是触类旁通过不少的技术，代码也会写上几行，姑且在同学们里面也算是有基础的了。\n我之前也对电脑感兴趣，加上网瘾少年的游戏制作梦想，所以说就选择了机器人的项目，然后用 Arduino 写写东西。基本的 Arduino 确实没什么好说的，就是很基础的技术，随便来个 GPT 都能写出来比我当时好的程序，然而正是那时候，认识了机器人社团里的两位老师，Q 老师和 S 老师。\nQ 老师貌似是北大计算机毕业，很是厉害，管理机器人社和天文社两个社团，平时自己还搞搞书籍翻译，感觉有点像那种已经精神富足了的计算机大佬，而且符合那种搞计算机的刻板印象，幽默风趣，有的时候偏好发滑稽，和学生们打成一片。S 老师我接触的更多，本人非常好说话，非常的和蔼可亲，不过关于老师的其他细节，我倒是不是很清楚，大多数时候和老师聊天，要不然是日常，要不然是比赛相关，聊老师自己几乎没有。\n尤其我这个人比较脸盲，而且其实大多数时候比较内向。我非常乐于助人，而且可以和很多人打成一片，然而事实上，我并不愿意结识新的朋友，或者说这令我恐惧且疲惫。可能只有在新环境中，我才会尝试扩展自己的社交圈，而在此之后，这个圈子多半不会有很大的变动。值得一提的是线上并非如此，线上我还是十分积极的。\n初识 RM 其实本质上，高一的时候我并没有接触 RM，然而和机器人社还有很多的往来，尤其是用机器人社的电脑偷着打游戏，这件事我乐此不疲，而且老师虽然嘴上严厉教育，但实际上管得不严。\n到了高二的时候，有一次我去机器人社，碰到了我的好朋友 CX，CX 是机器人社的主力之类的。我们学校对于那些类似提前批进入学校实验班的同学，会有一个类似于夏令营的东西，他在里面已经提前做了一些机器人相关的内容了，然后在后续，也一直在里面打比赛。\nCX 当时说自己在写 RM 的循线程序，在之前的时候，我就已经知道机器人社搞来了几台 RoboMaster S1，麦轮的机器人可以平移，看上去确实现代感十足。我当时说要一起去看看，所以去了我们的另一个场地，看他写这个程序。\n高中的 RM，只有工程机器人需要自己写程序，而且写的也不算多，其他的机器人基本上就是图形化编程，我看那些说明也不算难，提供的接口都很简单，所以就干脆写了写，出现了第一版的跑图程序。\n随后我就开始了我的 RM 生涯，有点像是说之前的一些同学似乎不打了，反正我可以写步兵的程序，同时作为步兵的操作手。\n像是之前说的一样，RM 的程序不算很难，但是图形化接口也意味着很难去使用自己的一些算法，包括说像是 OpenCV 一类的程序更是别谈。现在回忆起来，当初有一位 ZQ 同学在项目班的另一个项目里，貌似学了 OpenCV，当时我问能不能写一个装甲板检测出来，他展示的那个效果很不错，我还问能不能放到我们的机器上，现在来看，好像只是一个单纯的 threshold，甚至没有 findContours，难以评价。\n甚至说当时 Dji 没有开放装甲板识别的接口，只有数字识别，所以我们也没指望自瞄。当时的任务是击打能量机关和基地，能量机关是从小到大打一到五的数字，Dji 会提供数字识别的借口，返回数字以及图像坐标系坐标；基地的击打则是需要跑图到对面半场，然后自瞄。\n这里面有必要解释一下，RM 高中组的赛制，和大学有一些区别，加上读者可能也不了解 RM，干脆从头解释。\nRM 本质上是一个类 DOTA 游戏，其实说角色变成了纯物理世界的机器人，可以用键鼠控制。高中组有限制对机器人的改装幅度，不像大学组是自己做机器人，我们都是用大疆的 S1 机器人。\n既然是类 DOTA，肯定是涉及击杀以及血量等等的，RM 具有一套所谓的皮肤系统，说白了就是几个装甲板，或者说传感器，有人说是压力传感器，也有人说是声音传感器，具体也不得而知。高中组的机器人分为步兵/工程/无人机，步兵可以发射子弹，是那种水弹，所以打在装甲板上就可以造成伤害；工程有机械臂或者其他的机构，可以获得弹药瓶，步兵机器人的发弹量是被系统限制的，用完了之后只能等待系统发放的低保，或者用相机模块扫描弹药瓶上的标志获得补充，弹药瓶的获得自然有不同难度，区分度在于高度或者位置，其扫描后可以获得的发弹量也自然不同，最多的貌似是三百，可以爽打一局；无人机也是一个大疆提供的无人机，只需要控制它飞到对面基地的特定位置，让对面的摄像头扫到，基地就会破甲。比赛有补给区，补给区里面有一个标志，扫到就可以回血。\n比赛主要分为两个阶段，一阶段是自动的，二阶段是手动的，现在貌似划分更多了，但我只说我当时经历的。基地的护甲默认是五十，假如对面机器人阵亡了就会扣二十，最低是零，但是无人机可以给它扣到负的，一发子弹的伤害是十，护甲与伤害有一种计算关系，假如满护甲，那打一下好像才扣两点血。\n另一个机制是能量机关，可以理解为是一个在场地中心的机构，有五个可击打的传感器，显示数字一到五，需要按顺序打，就可以获得攻击增益 ATK。自动阶段激活是一个永久的 1.5，手动阶段激活是暂时的，但貌似是 2。能量机关有冷却。\n所以说，不难理解的是，自动阶段需要步兵先激活能量机关，再去打基地；工程拿弹药瓶，而且要跑得快一些；无人机不需要做什么。到了手动阶段，大家就开始 FPS，然后攻打对面的基地。\n冠军之路 我加入了 RM 队伍之后，和大家一起努力，程序可以说完成的差不多，不过需要说的是，确实还是接口好用，技术含量不高。\n甚至说因为曝光问题，我们在坡上无法识别对面的基地，所以需要循线准确一些，然后再撞墙矫正位置，之后手动抬到一定高度，完全是开环。\n工程机器人确实十分给力，我们的速度很快，所以说不至于打低保，弹药脸足够的情况下，基本上是稳赢的。\n高中的队伍其实就是打打闹闹，大伙都没什么含金量，不过确实有的学校，本身教育水平可能差点意思，所以打算把这个作为宣传招牌，也是我们当时的劲敌，民大附，不过到最后这个队伍有一些唐，到时候再说。\n当时我其实发现了一个问题，这些队伍普遍操作能力不太强，RM 的机器人，毕竟是物理控制，操作有一些粘滞感，一般人很难适应，基本上不能跑打，打移动的目标也不太行，尤其是在没有自瞄的时候（我们当时没人有自瞄）。而我可能说恰好有一些天赋，当时队伍里面的训练，和两个高一的同学加上一个老师打，我可以一个人打三个，而且地图不大，我可以倒着跑全图，一边逃跑一边还手。另一位操作手是 CX 同学，也很厉害，我们属于是强强联合。\n当时我们发现了一个简单清晰的盲点，大家貌似都很笨，在基地护甲没有到 0 的时候就在打基地，两点两点的扣，根本无济于事（基地貌似三千还是多少血量，反正很多），而对战欲望很低，让我一度怀疑我在打 RM 单机版。\n战术的前置是，我们有比较充足的弹量，两个厉害的步兵操作手，这些恰好我们都符合，于是理论如下：我们在自动阶段获得充足弹药，并且获得永久 ATK，基地的击打其实无所谓，在比赛的前期专注 PVP 而非打基地，杀掉对面三辆车，同时无人机破甲，激活临时能量机关。这时候我们一发子弹对基地可以造成 50 点伤害，两辆车一起不到十秒钟就可以结束比赛。\n靠着这套战术，我们很轻易的就在比赛里面披荆斩棘，当然，写的一些程序可能也是有帮助的。\n正像是前面所说的，大多数的队伍的操作手都没有灵性，基本上在站桩，所以就一路杀出重围，到了决赛。决赛的队伍就是之前说的民大附，在这里不得不好好诋毁一下，相关问题也无需抵赖，只要是当时那一届参赛的队员都会有印象。\n民大附这支队伍，我个人感觉是没有什么含金量的，貌似是请了外援还是什么的，写了些程序，我是不知道这些程序有啥必要找外援，然后还找了赞助之类的，最后实际上比赛没什么意思，基本上轻松取胜，主要说一些小插曲。\n当时印象很深刻的是，他们的无限火力机关枪。在 RoboMaster 中对于发射的限制主要分为弹量限制和热量限制。弹量限制很好理解，你只能发射那些你赚到的子弹，更多的不能发；热量则是说，你每段时间只能发一定数量的子弹，这被量化为热量，热量会不断下降，同时开火会热量上升，热量满了就不能开火了。抛开没有明确证据的，在和他们对战的过程中，他们貌似就已经开了无限火力模式一样，就算三百的弹药瓶不在他们这边，依然可以全场一直在打，甚至没有热量的感觉；民大附的战队在比赛的自动阶段打出过 1700 伤害，按照理论计算，最高伤害也不到 1500，所以就有点匪夷所思了；之后还有过民大附机器人失控实录，在自动阶段演都不演，直接启动无限火力，无论是射速还是弹量，都比正常的高无数倍，获得“机关枪”美誉，最后紧急暂停。他们自然也有解释，认为是 BUG 之类的，但是这种现象频繁出现在他们身上，而其他队伍从来没出现过，是不是他们自己动的手脚，自然也就不言而喻了。\n同时还有一位仁兄，胖胖的，感觉凶神恶煞。上文说道他们队伍有赞助商，这个赞助并非用来建设队伍，而是打钱之后大家平分，当然，也有一个前提，那就是获得冠军。一共一万多块钱的赞助，每个队员都能分到小几千块，自然是对高中生来说的一笔巨款。然而我们队伍的强势打破了他们这一幻想，基本上我们夺冠是势在必得的，这位仁兄就守在我们队伍旁边聆听我们的战术，不知道是想要帮我们指点一二还是什么。在别的队伍的备赛区逗留本身就是违规，我们尝试驱逐无果，他依然硬着脖子说要站在这里，然后又开始打电话，装作放狠话的样子。不知道是不是民大附就是这种职高氛围，还是怎样，反正一股子小混混的味道。随后更是忽然暴起，把我们备场区的一张木头的桌子用手砸裂了。我不太理解这个行为是什么意思，是类似于混混在街头打架斗殴前，先把玻璃瓶子在自己脑袋上砸一下，显得自己一脸血很勇敢吗？有一种脑子不好使的感觉，最后搞得满手是血，还溅到我们同学的衣服上了，最后是骨折了还是怎样，他们就弃权比赛，把这位仁兄送到医院了。\n综合来看，几场比赛都没什么悬念，我们就拿下了北京市和华北赛区的双冠军，也没啥难度和压力。之前比赛之前设想过很多的情况，高手如云等，但是事实上到了比赛才发现，原来我们才是那个唯一的高手。\n随后就是备赛国赛，准备了半天，最后因为疫情也成为了线上评分。我们队伍的一大优势在于操作手，最后纸面实力排了一个国家二等奖，倒也说得过去。\n基本上 RM 比赛可以算得上高中最后的疯狂了，紧接着的暑假里面还可以有一些新生培训，算是夏令营，事实上新生的素质也有一些堪忧，机器人队成为了打游戏的地方，后面也就禁止游戏了。\n事实上我们几个老队员也有打游戏，也可以说这种行为，或者说不好的表率是我们先开始的，但是老队员们一是早已经完成了测试，任务都做完了，二是当下确实没什么要紧的事；新的这些同学，倒是觉得机器人社是玩游戏的避风港了，实在是令我头疼不堪，更是有人说出了“要不是因为可以玩游戏，谁来机器人社”这种荒谬的言论。\n事到如今，我也就在玩碧蓝航线一款二游，之前我是经典的单机玩家，游戏时长几千小时，联机游戏也是暴雪那套，可以说半个婆罗门，现在倒是没什么游戏有吸引力了，也就渐渐不玩了。身边还是有不少同学玩游戏，玩 MC 的不少是 CS 领域高手，其他的玩游戏的人大多数表现正常，但是表现有点唐的几个人多半都是游戏玩家，我不知道这种必要不充分是否有什么隐藏其中的道理，但是也开始慢慢认同游戏害人不浅这件事情了。游戏在我的生活中给我带来的不愉快很多，主要是作用在一些我认识的人身上，有时间以后再说。\n第二年 RM，我基本上也就是有时间回来看看，算不上深度参与，因为高考所以也没有时间和他们一起去比赛。据说这一年民大附他们又有技术的提升之类的，我们输了，但是具体我也没有了解太多。\n高中的 RM 就在这种不知不觉之间结束了，唯一留给我的只有两个冠军奖杯，数不尽的回忆，以及当初的热血沸腾。\n在这里再补充一些内容，以免将来忘记，由于我的记录是以事件为主的，所以说对于人的记录其实甚少，甚至说在前面提到的 Q 老师和 S 老师在后面也没有提及，当然很大程度也是因为大多数事情我已经记不清了。\n我们队伍的主力一共有四个人，都是和我一个年级的同学，除了我，CX 同学，还有 HY 同学和 TR 同学，这两位同学共同负责的工程机器人。\n后来加入了大学的 RoboMaster 比赛，有一定原因就是因为 HY 同学是 RMUC 的忠实粉丝，在高中期间就不断地说比赛里的一些情况，也让我对大学组的比赛有了了解，否则我可能连大学组的比赛都不知道。\n除此之外，还有几个高一的同学，名字我也都记着，但是就缩写而言，和后面的一些人产生了冲突，所以就不一一写了，然而依然有必要说的是，这些高一的梯队同学在比赛中也做出了卓越的贡献。因为疫情原因，全国赛改为了线上比赛，此时我们这些主力队员都已经高三了，需要准备高考，而线上比赛又需要录制视频，这些都是他们做出来的。\n大学概况 不少读者应该知道我在大学的情况，但是为了回忆的完整性，还是重新说明一次，把内容进行完全记录。\n大学的时候，我进入了人工智能专业，老实说我之前是想选数学的，可以理解为某些对于自己数学天赋的自信，虽然这种天赋近期貌似遗失了。然后进了人工智能专业之后，我也就开始想要了解这个专业里的东西了，当时我能想到的，无论是和编程还是人工智能，唯一能擦上边的就是 RoboMaster。\n于是我就在专业群里面发问，当时我在专业群里还算活跃，所以大家的回复也很有效，大概的意思就是说，我们专业里面有 RM 视觉组的组长，也是我的学长，比我大两年。\n于是后来我就联系了这位学长，即 JH 学长，然后他带我进了 RM 招新群。\n在大学一开始的时候，事实上我对一些学习之类的事情不是很上心，我的目标就是保研而已，而且是保研本校。我刚开始的时候做过很多心理建设，类似于既来之则安之，因此没有去想再追赶上我那帮高中的同学，当然后来的前进的理由，也已经不是追赶。\n尽管我现在在一些新生指南中说，大家可以在假期把高数/线代/概率论全学完，然而这并非我当初做到的事情，准确的说，我没学概率论。在此基础上更加糟糕的是，我对于编程的学习知之甚少。\n尽管我之前说过我有一定的编程基础，但是事实上，也只是在一些算法竞赛中做过最粗浅的学习，使用的也是 Dev C++，同时做过项目和写过算法题的同学，应该自然有所了解，基本可以说除了他们的语言相同之外，很少可以见到共同点，包括一些 C++的特性，设法中更是没有涉及。老实说，算法竞赛用 C++，只是因为快而已。\n视觉梯队 我当时基本上也没有做什么准备，因为之前和 JH 学长说的也是，对于大一同学基本上没什么要求，但是可能也无法成为正式队员。当时我没有做过多的了解，记得当时面试的时候，是一个非常简单的问题，如何在一串数组里面找到最大的元素，需要手写代码，可以说十分的水。\n当时在视觉组里面的有四位学长，分别是人工智能专业的 JH/MD/JXY 以及电气的 YZ，都是很厉害的人。\nRM 拥有一套属于自己的培训与筛选的体系，这套体系的根本目的并非培训，而是进行筛选。之前的队伍其实倒也还好，然而最近随着内卷的风气越发严重，而最近我们的成绩很不错，有了一个加智育分的招牌，也就吸引得不少学生呼啸而来。\n老实说我非常痛恨这些人，因为 RM 本来就并非像是腾飞杯一样的水赛，不是说来几个人拿一个实验室里的项目，自己包装包装，就可以混一个奖项加分的。倒也不是说这类为了分数来的人没有水平，只是说他们确实很难坚持下去，可以说混这个字已经刻在了一些人的骨子里。一开始在队伍里的培训的时候，大家也都是知道轻重缓急的，都是一副很卷的样子，后面一旦发现自己进入了梯队，也就全都兴致全无了，又或者呆在主力队员的位置上，但不太做事。\n我大一时候的培训更加偏向于压力，培训的内容和考核的内容基本上关联不大，当时可能说培训的是计算机视觉的理论，但是考核是让你写 C++ 的 OpenCV。\nOpenCV 的本体其实是 C++为主，然而因为 Python 的易用性，导致网上的教程基本都是和 Python 相关，当时 ChatGPT 也还没有横空出世，所以代码基本上都是在没有人教的情况下慢慢摸索。\n其中当时教学中的几个很大的坑，包括说 OpenCV 和 C++的一些配置，以及 ROS 等等，在后面我也都有慢慢去自己学习，当时的任务也算基本完成了，然而由于组长告知大一同学只能是梯队，完成最后的任务没有什么意义，我在简单看出了思路之后也就没有再继续写代码。\n当时的那段时间是疫情期间，基本上也都是网课，所以说对于点名之类的问题，要求也不算很高，加上我更加倾向于自学，那段时间的作息可以说全乱套了。当时我基本上一个循环是六个小时，可能学习四到五个小时，然后剩下的时间睡觉，之后又醒来，接着学习，尽管从那段时间对我后来的提升很明显，包括说对于编程的一些基础/思维方面/计算机视觉的理解。\n大概也就是在国庆结束之后，我们刚刚结束了培训，准备公布正式队员的名额，此时 JH 学长和 MD 学长忽然就离队了。由于本人并不是非常热衷于社交，而且也并不是十分八卦，这其中一大部分的原因来自于本人的脸盲，剩余的可能是懒惰。因此假如读者想在本篇回忆中，找到一些关于队伍历史上的秘密，那么可能就失望了。事实上关于这两位学长离队的原因，我也没有太多打听，有人说是因为加分，有人说是因为压力，具体我也不得而知。\n正式队员 由于两位学长的离队，我也从之前的只能成为梯队，变成了一名正式队员，所以接下来理论来说就是完成剩余的任务，这里面我首先负责的是相机取流的任务。\n我从头去阅读海康相机的 sdk，然后去写取流程序，当时的疫情已经越来越严重，基本上能够开展工作的时间不算很多，大多数时候我就呆在地下室（也就是我们社团的活动场地），然后看一些代码，顺便学习一些课内知识。\n后来因为更多的疫情，期末考试也取消了，基本上整个学校全部封禁，本来我们说 RM 要办冬训，这也算是一个传统，为了下半年的正式比赛打一下基础，把大多数的事情都做好，但是也被迫转到线上了。\n现在还有印象的是，当时听说了地下室也要封，我们的能量机关被放在另一个地方，当时我和视觉组的组长 YZ 学长骑车去一个挺远的楼里面，用相机拍视频，这样用来到时候在家里进行调试。虽然貌似最后，因为能量机关的改版，以及楼道里的反光太过于严重，所以说这些视频并没有很派上用场。\n之前我的任务是负责相机的取流，直到后来，在冬训的时候，开始和 YT 一起负责能量机关的识别和预测，我负责识别，预测则由 YT 负责。YT 适合我同年加入队伍的大二学长，比我大一个年级，预测当时主要就是通过拟合，然后弹道模型算出来飞行时间，去求出来云台需要转动的角度。比较朴素的预测是通过迭代法进行的，我们当时建立了一个模型，发现这个最终的角度虽然是超越的，但是是存在一个方程的，所以后面直接可以用牛顿法进行解决，然后求出来 pitch 和 yaw。\n寒假的时候我主要在读之前的能量机关代码，之前的代码主要使用了 ROS 框架，但是讲实话并不好评价，因为这套框架对于 ROS 的运用仅限于把串口通信和运算分成了两个线程，我们后面觉得在这里使用 ROS 是完全浪费的，而且也会被迫要求新人也重新学习 ROS，这是巨大的教学开销，也没什么必要。\n大多数的代码有很多的嵌套，而且有一些算法，如今来看，可能确实十分的精妙，但是有的耗时太多，有的效果不太明显，而且并非 clean code。\n当时我把能量机关识别的流程完整的写了出来，然后一个一个梳理，写了一套新的比较简单的流程，跑起来也没有什么问题，可以说十分的流畅，而且也没有误识别的现象；在培训的时候也有这个识别任务，当时我用了漫水处理，这并非一个主流的写法，但我也把它作为一个方法封装进去了。\n当时我们商量的是，因为自瞄还在老代码的框架里面，但是我已经新写了一套取流+能量机关的框架，把两个融合在一起并不简单，而且我当时也不是很会 ROS，所以说留一辆车给新代码，其他的都是老代码的。\n自瞄当时还处于需要检测装甲板的这个阶段，最大的难度其实是灯条匹配，车辆的每一块装甲板都有两个灯条，怎么确定这两个灯条是属于同一块板子还是两块，这是一个难题。通过几何上的特征，可以保证大多数情况不出错，然而这并非全部，后面有不少的队伍出了一些异形车，使得这种朴素方法的误识别率更高了。\n当时已经把能量机关做的差不多了，所以想着做一下自瞄，一开始是 yolo 识别一个 bbox，然后加一个灯条匹配，后面看到了沈航的开源，他们做了一个四点回归，直接求了装甲板的四个顶点，我的手比较快，直接把这套流程缝合到了新框架里面。\n记忆中比较深刻的是当时的一次交流赛，是西安联盟里面的几个学校一起打，当时队长的意思是需要稳定性，所以说不允许换新代码，我偷偷在一个车上面放了新代码，可以说是效果拔群，事后队长来找我说，这个代码效果确实好，把每个车上都放上这个代码吧。\n还有其他的事情是，能量机关也换了样子，所以说老的传统视觉不好用了，当时已经有了训练神经网络的技术，其实说是训练，主要是包括标注在内的一套框架，以及最后部署的代码，所以说我们对能量机关也做了一个神经网络去识别，同时我也写了一套新的视觉逻辑，也没什么问题。\n后面就是联盟赛，联盟赛办在本校，肯定是要打出气势的。当时队伍里面除了组长 YZ，还有我、YT、同样是新人的 SY 以及 JXY 学长。JXY 学长招来了 ZH，他们两个人一起做了这个赛季的另一个重大项目，哨兵的 SLAM 和导航。\n我们在联盟赛打的还算不错，最后拿了冠军，其中很大一部分原因就是哨兵出力了，同时当时的操作手也很有水平。那时候我的课余精力还很充沛，所以也报名了操作手选拔，当时说的是大家一起打一打，然后看看水平，具体叫谁去打会在群里说，结果我就被叫了两次，一共才打了两局，其他人貌似就已经十多局了，后面操作手出来了，我甚至都没有第一时间知道。再之后有人说，压根就不打算让视觉组当操作手，这句话是不是真的我就不得而知了。\n再之后，组长 YZ 和其他的学长们，因为都已经大四了，所以开始要准备毕设，我是其他人里面代码写的最多的，所以说隐隐约约间有一种要成为组长的架势，也开始负责一些东西。\n值得一提的是，当时的视觉圈子里面出了一个很厉害的开源，忘了是哪个大学了，作者叫陈君，所以大家称之为君瞄，用的也是 ROS 框架。我们的代码后面把他们的一些程序解耦了，然后做了修改，放进了自己的框架里面，我这个人特别手快，对这种解耦的事情非常擅长，后续调了调也就没啥大问题，现在我们的程序基本上沿用的还是这一套框架。\n虽然说君瞄确实很不错，但是整体的氛围却让我感到非常反感，有点造神的感觉，当时陈君把他们录制的视频放到网上，大家都很吹捧，但是好像也没什么人在实战中打出来这个效果。\n后来作者说是因为和人吵架，被人嘲讽了，所以把自己的程序删库跑路了，但是据传说，在此之前他用这个几百个 star 的 repo 拿到了大疆的 offer，所以是懒得搭理开源社区，还是真的恼羞成怒，还是要画一个问号的。\n当时分区赛，陈君还和我聊过，拿着他们那个库的贴纸，问我要不要，然后就像是在推销一样，我说不用了，他依然说个不停。令我印象很深刻的是道具训练，这个环节大概就是每一个队伍调试一下能量机关以及飞坡之类的，他们队伍能量机关不行，就在场地里面调自瞄。这种行为其实有点行为艺术，因为自瞄完全在任何地方都可以，这个地方光线也不一定正确，完全就有种秀肌肉的感觉，事实上我印象里命中率也不高，车离的还很近。\n有读者可能好奇，我们既然拿了他们很多程序，为什么我还对他如此诋毁，岂不是吃饱了骂厨子，这还要从比赛本身开始说起。\n事实上，就像是我之前说的一样，我对于陈君的反感主要来自于造神以及饭圈的氛围。我们小组赛和他们分散了一个组，当时我们在他的算法上做了不少改进，自然要碰一碰，当时我们打他们，打到了一比零，我们落后，因为裁判系统的故障，比赛暂时暂停。那时候没什么人看好我们，毕竟君瞄威名远扬，这倒也可以理解，更何况他们已经先下一城。然而陈君在视觉群里面直接说，假如他把西交打败了，他就去无偿给每一个队伍调车，群里立刻席卷了一片西交必输的恶毒言论。当时我印象很深刻的深圳大学依然支持我们，我们现在和深圳大学关系也很不错，在分区赛也是和他们一个场地。这个事情也就导致我们之间确实结下了梁子，不过因为抽签的运气好（说起来，当时还是队长和我两个人去抽的签），我们在一比一平了之后，小组第二出线，反而战胜了劲敌晋级八强以及四强，遇到的都是状态不太好的队伍，而陈君则止步十六强，去打复活赛了。\n另一件印象深刻的事情是哨兵，当时两位学长都来不了现场，而队长在申请建图的时候，因为疏忽没有通过申请，我当时负责哨兵的维护，也是出了不少的状况，最后基本上哨兵是通过在家里的巡逻获得了一点点的贡献。\n后面到了国赛的时候，视觉组这边一直负责雷达的 LXY 接管了哨兵的工作，但令我印象深刻的是他把工控机一拿到手之后就让我做了格式化，出于谨慎，我对工控机中的内容进行了备份，不然估计程序都要消失了。\n事实上，在第一个赛季的时候，视觉组主要起到作用的还是能量机关的激活，而且因为各种各样的原因，最后激活的效果其实不尽如人意，自瞄因为只能识别不能预测，或者说没有调过预测，所以说不能打高速旋转的小陀螺，在实际的赛场中作用不是很大，主要是一个辅助。\n当然，我们做的工作还是很多的，我们完全地重新写了一套框架，包括说串口的通信/相机取流/识别和预测/能量机关，在这里面值得一提的是串口的一个奇怪的 bug。\n很久以前，我们的通信就已经可以使用了，但是事实上还有不小的问题。因为 Linux 系统的特性，串口的通信本质上就是对文件的读和写，然而在细节上来说，还有不少的内容需要设置，我们使用了网上的开源程序，封装之后放到了我们自己的框架里面，但是出现了一个很奇怪的问题。我们的通信协议的长度是 64，也就是说，只有在我们接到一段长度是 64 的内容之后，我们才会对其进行解码，然而事实上我们经常收到长度为 63 的内容。这个问题我们想过很多方法解决，包括说是串口线的问题/串口的问题，甚至到了最后，我们感觉将线稍微弯曲一下，就会持续地发出 63，而将其恢复，通信就正常了。这种感觉就好像我们将那一个字节捏在了手里一样，让我们百思不得其解。最后是视觉组的 YT 发现了问题所在，在看了几篇博客之后，修改了代码，这时候我们才知道，原来是因为串口的收发会将回车不认为是字符而是真回车，导致这个字符不会被记录，从而少了一个字节。\n到了国赛的时候是去深圳，在这里顺便说一下两个城市的住宿条件。我们出去比赛主要是学校出钱，或者使用社团的经费，当然我们每个人也都垫付了一些，其中甚至有的没要回来，这是后话。为了省钱，我们每次出行肯定都不是那种豪华酒店，往返一般是硬卧，酒店也很难安排到每人一张单人床，可能要很多人挤在一起。\n长沙的条件一直都很好，我们住的是 LOFT，在市区里面，旁边也有吃饭的地方，车辆调试一般在晚上进行，我们会租一个篮球场，也在住的地方不远处；深圳在当时则是一个酒店，因为长沙的时候我已经实在无法忍受住宿，所以干脆特立独行，让家里人给我单开了一间房，酒店的条件也很舒适，市区里面，旁边还有商场。去深圳之后，我们是在一个羽毛球馆里进行调试，当时我负责反前哨站，基本可以做到百发百中，但是有些玄学，而且因为机械装配的问题，在离得比较远的时候，会出现怪异的情况：我发给电控一个坐标，希望他瞄准，瞄准的时候会抬高枪管，我就看不到目标了，导致在离的很远的时候不能正常的自瞄，这个问题在下一个赛季通过修改机械结构解决了。\n国赛的时候，在调试的时候，视觉能做的事情已经不多了，能量机关差不多的打，自瞄的识别很稳，反前哨站则因为机械结构而爱莫能助。除了哨兵，由于上述的问题，导致本来还算能用的框架又出了不少问题，LXY 需要通宵调车。其他的我们几个视觉组的，前半夜把已经没问题的程序跑上几遍，然后就在一边聊天，等夜宵，我经常去场地边上的便利店里买几包酒鬼花生，很是好吃。\n国赛倒是没什么好记录的，我们的水平，老实说，在当时并不配得上群魔乱舞的国赛，但是运气好，分在的小组竞争并不算很激烈。我们第一赛季的全部比赛，可以说能够胜出，都是因为有运气在里面，而这一点在国赛体现的尤为明显。小组赛的三个对手，要不然机器人出了常规问题，要不然哨兵出去了没有回来，导致我们几个在观赛席的反应是：“Nice，他们哨兵出去了，这下应该回不来了”或者“果然没回来，基地已经展开了，该去偷家了吧”，因为相较于今年，去年的对手普遍没有击杀哨兵或者上环高打基地的能力，或者是因为被我们主动的盯防而阻止的。\n在这样的情况下，我们开始了两场比赛全部胜利，然后莫名其妙的，就出线小组赛了。从观赛席回到备厂区的时候，我们几个人问彼此，这就国一了？显然是有点不太相信这件事情的发生。\n国赛的后续碰到的真高手，自然也就赢不下去了，我们的名次也就止步十六强了，但是好歹是在很多年后再次追平了队史。\n组长之路 事实上，在第一个赛季结束之前，我们就已经基本确定了视觉组组长的人选，也就是我，抛开别的不谈，我可能确实做的工作比较多。\n然而在国赛之后，LXY 也对组长的位置起了觊觎之心。大概是因为加分的缺乏之类的，他在国赛负责的是哨兵，可能认为加上了组长的身份，就可以获得不止两分的加分，于是便开始和我竞争。\n我因为有事情，比赛结束之后就回了西安，大多数的队员还留在深圳，因为有大疆举办的青工会。据说是因为当时，之前定好的队长去打别的比赛，耽误了这边的进度，老队员对一大堆定好管理层都有一些意见，所以打算大洗牌。当时是队长和老组长找到我，我也记不清先后顺序了，包括 YT 也问我，视觉组组长是不是要换人。我心里倒觉得奇怪，我的培训教程都已经写得差不多了，为什么忽然有人提换人的事情？\n后来大概了解了一下才知道，估计是视觉组在深圳期间没做什么事情（开始的时候需求就是那么多，我们都做完了，我之前还说过要不要调试一下防陀螺，队长也不让，我们还能做什么呢），估计是看 LXY 做的事情多（毕竟工控机都格式化了），所以打算把组长的位置换人。\nLXY 其人，倒也不坏，但是干活的积极性确实不好说，当时我们几个其实关系都不错，但是这件事情确实把我气得不轻。之前他做的是雷达，来队里的次数就不算很多，雷达是老代码，相较于之前据说是需要删，都不需要写什么。后面接手了哨兵，也就需要经常来一段时间了。\n我们当时拉了一个群，讨论组长人选的事情，现在来看，我其实对于组长是谁没什么所谓，只是说对于莫名有人说我贡献度什么的，心里确实不满。包括说后面有一段让我气愤的话：\n唉，其实我说一下就是我看其他组的同学每天通宵熬夜调车感觉很心疼，感觉视觉组就这样走了很对不住其他组，所以我一般选择了陪伴”\n视觉组工作做完了，留一个人守夜，其他人走，不也很正常吗？难道说让大家在这里空耗才是正确的吗？再说陪伴，怎么不见你分区赛陪伴了，我因为 RM，这一年来少说也熬夜了五六十天，估计上百，那时候你怎么不心疼了，不陪伴了？\n这是我第一次隐约对 RM 产生了一丝失望。我高中就是打 RM 的，给我留下的都是快乐的回忆，但是大学的 RM 显然并非如此，越往后，越不是一个安心搞技术的地方。人情世故，责任推诿，勾心斗角，层出不穷。只是说我打了一年，一是舍不得一些朋友们，二是对得起一些人的期望，三是确实还抱有改变一些事情的念头，所以打算留下来。在今天来看，我还是不知道自己做的是否是对的，我不需要加分，第一赛季的分数早就够了，更多的分数也没有任何价值；科研的性价比远高于 RM，要我操心的事情也没有那么多，但是我还是留下来了，虽然可能没人因此感动。为什么呢，我会问自己，有太多人给了我太多的期待，我想，至少不要辜负太多。\n考虑了许久，YT 打圆场，说暂时就先考察我，假如没问题，我继续当组长，我也和前队长保证，好，那就没问题，我就正式成为组长了，虽然说事实上我履行这个职责已经将近半年之久。\n比赛也结束了，下一任管理层也都定下来了，那这个赛季基本上也就告一段落了，收拾收拾再出发，要准备下一个赛季了。\n我们的招新工作其实有点混乱，早在暑假开始的时候，我们办理过一个综能课，当时就是说培训之类的，但是最后讲了一点点就不了了之，后面就要进行训练了，综能课快速完结。到了比赛结束，已经八月十多号，也已经到了需要开始下一轮招新的时候了。\n我一向认为自己是有一些新人亲和力的，在招新的环节也比较下功夫，一方面我大二的时候确实更多时间会投身于科研，当初写了一些程序，可能还是需要新队员来继续开发，另一方面，我也确实认为，新鲜血液才是个队伍的未来所在。\n之前的招新工作其实一个重点在于压力培训，我们培训的内容和讲的内容并不是很相关，而最后做的事情和培训的内容关系也不是很大，只能说确实是作为筛选所设计。而今年培训的难点，另一方面则在于人工智能的兴起，不像我当初的情况，大多数的代码都需要我顺着其他人的博客去查，而且质量也参差不齐，如今只需要和模型说上几句话，大多数问题就迎刃而解。\n因此一方面，视觉组的培训应该更着重于帮助大家快速掌握一些基础技能，这些事情是人工智能也不能真正速成的，所以我在家的时候，大概录制了八期课程，去讲解视觉所需要用到的 C++知识，本身长度也不长，这样可以在线上就完成这最费时间的一步。在之后的培训，我也是主要从计算机视觉的基础说起，讲了一些通俗易懂的概念，然后就带大家上手代码。\n事后来看，这种选择不一定是正确的，培训的效果确实很好，对于任务，大家也可以比较出色的完成，但是事实上视觉组的主要工作在于后期的长期调试，代码上的一些东西，一是没有必要再去找轮子，二是那些需要写出来的难度都不算很高，导致任务缺乏区分度。\n一些同学确实是三分钟热度，很快就离开了，剩下的不少人都可以完整的跟下来整个培训。然而一方面出于一些交情，因为培训和新人走得太近，不太好意思通过打卡时间将他们开除；另一方面，大家的实力确实尚可，导致之后选拔不出来可以坚持下来的人，按照现在来看，当时选拔下来估计七八个人，现在只留下来了三个人。\n要是将来还是由我来办培训，双盲的打分是肯定要存在的，而且估计任务的难度还要进一步提升。\n当了视觉组组长之后，确实有参与一些行政相关的事情，然而到了赛季的后半程，这些事情又莫名其妙的消失了。我们队伍本来打算使用飞书，然而从结果上来看，除了项管还在坚持，大多数人其实用的不多，这种特别小型的团队，确实没有必要使用飞书进行管理的地步。同时也是因为熟人，物资管理到最后做的也不是很好，尽管我三令五申过，视觉组的物资，在使用之前要和我说一下，但从结果上来看，不只是我的键盘和设备丢的差不多，像是相机之类的东西，其他组拿走之后，我也要花不少时间才能溯源，还好最后没丢什么。\n第二年的技术发展也算是日益完善，之前没有的视觉兑矿，以及更好的反陀螺自瞄，更好的能量机关算法，更好的 SLAM（最后是交给了电控组的同学，LXY 因为到勤时间不够被移出队伍了），也都陆陆续续地出来了，总体上发展还算平稳。我把去年我做的一些开发，陆陆续续的都交出去了，分配给其他同学，他们在我的基础上也有做很多的调整，或者独立做了很多的开发。\n成为组长之后的一个明显的体验是，没必要再去亲力亲为的进行调试了，虽然说因为我还负责反前哨站的工作，所以和实际工作还有一些接轨，但是绝大多数时候，我只需要了解大家大致的情况就已经可以了。\n这个赛季之中还有一些人员变化，但是因为我也不太了解具体情况，可能也就不会过多的介绍了，万一说错了，可能反而还要被其他人说。不过可以说的是，从体感来讲，我身边的队员普遍对于管理层都不太满意，而且一些进度上确实也有太过于 push 的嫌疑，现在比赛还没有结束，所以说换届还不会开始，事后怎么清算我自然也就不太清楚了。不过事实上我倒是观感不是很大，一方面现在的这些人基本都和我同届，而且我也都已经有了加分之类的，也可以说是死猪不怕开水烫，反正我事先定的什么目标，我就按照这个目标去执行，也不管别人催什么的，定的 ddl 之前肯定也可以完成。\n一开始因为本身的自瞄，对于远距离的目标的识别和建模也都不太准确，所以说我的调试也不是很顺利，但是后面考虑到前哨站的特性，使用了更加 simple yet effective 的策略，总体来说就还算准确了。之前说的是命中率百分之七八十，后面我基本可以做到百分之百，但是因为发射之类的原因，有的时候可能卡一下，就会有一定偏差，但是这种问题也不是某一方的责任，确实是长期需要改进的。现在另外的问题是通讯，我发出去的信息在另一边不能很好的接受，似乎是因为电控的总线上挂了太多电机导致的，现在随着头越来越重，控制的死区也开始增大，这一点我暂时也没有想到很好的解决方法。\n这些策略在学校的时候，还算很不错，一开始用的是大疆的 Gen1 弹丸，基本上可以说很稳，到了后面用 Gen2，事实上弹道就和电控的弹道模型有了很大的差距，这个事情在视觉这边可以用算法比较方便的解决。在电控端重新标定一个弹道模型，玄学成分太大，我也没有指望。后续的基本全部操作，都是为了弥补弹道上的问题，对弹道做了一阶多点的标定，不过显然的是，在没有解决本质问题之前，视觉的方案终究只是治标不治本。\n这个赛季依然选择的是去长沙参加分区赛，然后再晋级国赛。相较于去年来说，一些视觉的方案确实已经被落地了，加上我们也派上了一些如平衡以及吊射英雄的一些比较前沿的兵种，所以说最后打出来的效果很是不错。\n去年如此来看，确实运气不错，最后还拿了一个分区赛四强，今年就不是那么顺利了，但是还是打出了自己的水平，晋级国赛。\n结语 一开始打算写回忆录，还是比较激情澎湃的，想着自己至少也打了这么多年，一定也有很多有意义的东西可以记录，然后我到后面却发现，好多事情早已无法让我兴奋起来。一些内容我记不清了，一些内容我也不太确定，太多的琐事太多无趣的瞬间，让我开不了口，也落不下笔，记叙也从顺叙变成的插叙，索性将故事收拾一下，等将来想写了，再做一些补充。\n大学的 RM，一开始做技术的时候是很有趣的，不断自我提升的感觉也很棒，然而出一些自尊或者其他的情结，想要接任组长之后，我是反而慢慢地对这个比赛失去了一开始的激情，而回忆路越往后写，反而越觉得没什么事情好写。一些事情我已经记不清了，时间也仿佛飞快的流逝，那些古老的回忆，反而在我的印象十分深刻。两年的 RM 大学生涯，我好像做了很多，但是对一切又似乎没什么改变。机械依然是比赛的焦点，视觉组从重构到各项技术都达到新标准，我确实也或多或少都有参与，然而组员们的功劳，我倒也不能全都一个人拿下。\n我忽然间想起来，在第一年去国赛的时候，YZ 学长和我说的话。他说自己虽然是组长，但是好像这一个赛季也没有帮上什么忙，我一个人向前做得太快了，大家都没有追上很多。YZ 学长的技术能力是我至今见过最顶级的一批人，一开始的很多探索也都是他牵的头，那时的他想的会不会和如今的我想的一样呢？\n我或许给一切开了个头，然后每名组员就向前冲刺了，而我还呆在原地，缠身于生活中的琐事，回过神来的时候，自己却已经帮不上忙了。\n好在结果不差，也算是没有辜负大家一路以来的努力，尽管我的参与也不算很多，但或许也还值得厚着脸皮说上一句，没有辜负当时大家的嘱托。\n未来的比赛我还会不会打，我想了很久，假如没有人赶我走的话，大概还是会再厚着脸皮待上一段时间，不过未来还是属于新人的，我嘛，暂且日拱一卒吧。\n","date":"2024-08-03T22:17:00+08:00","image":"https://axi404.github.io/Blog/p/robomaster-%E5%9B%9E%E5%BF%86%E5%BD%95/cover_hu17786166531967832253.PNG","permalink":"https://axi404.github.io/Blog/p/robomaster-%E5%9B%9E%E5%BF%86%E5%BD%95/","title":"RoboMaster 回忆录"},{"content":"前言 算是写在一切之前，在开始我的 LLM 以及 embodied 之前，自然还是下过不少的基本功的，在这里算是记录一下，后续的内容也会陆陆续续的更新。\n我写的大多数的 insight 分享，都是某一天想起来再写的。我估计我读过的论文，估计少说也有两百多，一篇一篇写是不太可能了，只能说慢慢读，慢慢写，想起来写，纯凭兴趣。\n正常的基本功内容以及之前的一些文章，可以说也有很多了，要是说写完，倒也不太可能，姑且作为一个长期的工作吧，希望能够有写完的一天。\n机器学习 一开始是学习机器学习，在这里，大多数的知识点就是算法本身，更加偏向于数理之类的内容，不存在太多的 insight。要是真说是有的，估计是对于诸如熵/分布/采样等内容的理解与重视。中间看过几本书，推荐李航老师的《统计学习方法》以及周志华老师的《机器学习》。统计学习方法有简博士的讲解，在我写这篇博客的时候，依然还在连载，不过事实上到了后面，一些内容很容易就看进去了，倒是不太需要视频。\n深度学习 ","date":"2024-08-01T19:41:00+08:00","image":"https://axi404.github.io/Blog/p/llm-talk-0/cover_hu8759730391849262067.jpg","permalink":"https://axi404.github.io/Blog/p/llm-talk-0/","title":"LLM Talk 0"},{"content":"由于迟到的第四周周记，许多在第五周发生的事情，在第四周里没有来得及表达，因此也就给了我的表达欲更多的动力，在匆匆忙忙写上几个第四周的周记之后，也就开始了这周的内容。\n学业 科研 首先是跟进一下之前的实习申请，在大老板面试之后，又是小老板的面试，大老板那里只能说确实压迫感很强，虽然老板本身和蔼可亲，但总体看上去，是对于我的工作比较不在意的。可能说投稿只是一个必备项，能证明我是优秀一些的学生，但本身考虑更多的还是我对于将来的领域的理解，以及一些基础技能的掌握。这确实也是一点，事实上我的这篇论文确实是是在一个小领域中的小贡献，对那些大型的工作来说，可以说只是我有科研的经历而已，剩下的其实也不能证明什么。\n小老板的面试倒是细节了不少，但是也没有拷打的意味，这说起来我的感受也不清楚，假如说是一个非一作的同学来回答，会不会对他的一些问题回答不上来呢？但是至少我来说，感受并不明显。\n大概是很舒适的和小老板一起过了一遍我的工作，然后我又聊了一下关于 embodied ai 的一些看法。这其中自然也有一些提问，多半是关于一些，无论是多模态也好，还是具身智能相关的一些论文的内容。只能说确实是一分耕耘一分收获，一方面我展示一些之前的博客内容，老板也知道了我的积累量，而且后续的一些解释和理解，也基本在我的了解范围之内，因此没有太多的问题，观感应该也很不错。\n面试结束的时候，小老板说我对于领域的理解在同龄人里面应该是比较多的，实在是令我受宠若惊，然而，好吧，先虚心接受，再继续努力吧。\n之后 HR 很快给了反馈，两次专业面试都通过了，之后和 HR 打了一个电话，了解了一下将来的一些情况，之后就说开始跑 HR 流程了，估计一周左右就可以有 offer，希望顺利。\n焦虑 我已经走了很多的路，走了很远很远，但是回头看向身后，总感觉那些被我拉开距离的人不一会便会追赶上，而向前望去，在我前面的人又是距离我那么远。\n加入了一个小群，里面应该也算是一批目前全国非常厉害的科研高手，只能说还是人外有人天外有天，可笑我之前嘴里还说着无所谓，但是依然在心里是有一点沾沾自喜的。\n年纪轻轻就已经有了一篇顶会，貌似这在人工智能学院是前所未有，是不是也可以说是天才了呢？然而我的成绩不算好，别的内容也不算突出。女朋友总问我，有一篇不就够了吗，为什么还要继续努力？我也想问自己，是不是贪得无厌了。\n我总是能在一些人里面混到中游偏上，然而总是做不到顶尖。\n小学的时候，我是数学课代表，初中的时候，我是数学最顶尖的几个人，高中的时候，几乎大半个我们年级的数学组老师都认识我。高中的时候年级组长也是数学老师，我们模拟考试，数学卷子有的时候我提前一小时就可以做完，然后就借口说上厕所，就出来闲逛。年级组长语重心长地和我说，你是咱们年级最聪明的学生，当然，还有经典的：“需要更多的努力”。这句话后来几乎成了梗，像是差学生专属的 pua，但是我大概能确认我并非此类，因为老师也跟别的不少老师提过。高一的时候我还参加过数学竞赛，拿了省一的末尾，不过后面学校里面竞赛训练聊胜于无，又赶上了疫情，最后也就不了了之。\n不过考得好我是一向不擅长，语文作文有的时候能拿个范文，但是整体上大多数科目属于看着都会做着都错的情况。不少问题我看到红叉子之后立刻就能反应过来，然而有什么用呢？老师也总是说我粗心，但是我已经尽力检查了。\n我能在那帮学霸里面混的开，但是一到考试就和大家拉开差距了。小学的时候有推优，能去更好的学校，我没去成，在初中里面也成了很厉害的人；中考去了不错的学校，又是新的环境，更厉害的人，我还是混到了靠前的位置；高考发挥失利，来了西交，人工智能专业（如今来看，这或许是很好的结果，本来我一直是对数学感兴趣），又是年级前列，但也不是最顶尖。\n有人说，你这是不擅长考试，所以去的地方人都不如你，你自然就到中游偏上了，我却倒也觉得自己是有几分天赋的：我是北京考生。\n我其实有一套歪理，辩解一下，北京考试卷子简单但是考验心细云云，在这里就不说了。从现实来看，我虽然排名不高，也算是年级前列了，论文发表也是自己老老实实做。所以要不然我是有混到中游偏上的天赋的，要不然北京考试就真是地道了，还是能整出来两个像我这样的做题家的。\n天赋的话题就到此为止，那么现在呢？我已经到了前列了吗？插入了太多的回忆，现在暂且回到之前的内容，焦虑。\n我是总很容易安于现状的，一千米考试的时候，到了快结束，会想着跑慢些，反正分数差不多得了，中考高考考完之后，说是沮丧，倒也没有很多情绪在里面。然而科研岂是中游偏上即可？要是安于现状，有怎么有安稳的生活？\n我的理想不算远大，我喜欢学习喜欢技术，学习本身的开销不大，一张桌子一台电脑足矣；女朋友喜欢裙子，倒也不是名牌，jk 或者 lolita 足矣；我们经常出去一起吃饭，也不是豪华饭店，一顿饭贵则一百多足矣，否则小几十块钱也能将就；住房不用太大，不逼仄就好，能晒晒太阳。虽然这种生活已经难得，然对于我当下来说，不算很困难。\n可是我总会多走一步，免得遇到意外，但多走了这一步，又是新的风景，又有新的高手，又要我更加多走一步了。\n于是乎焦虑油然而生，越往上，越是高手如林，越是觉得后怕，高手如此之多，假如我没往前这一步，那当初那个层面的厉害人士岂不是更多？只是我不了解罢了。\n唯有学习，继续努力，日拱一卒吧。\n生活 火车上 由于在火车上，陷入了极度的人生的不平静之中，周围都是小孩的声音，偏偏自己的事情又一团乱麻，让人心烦。\n坐火车去深圳，队伍里只能报销硬卧，这劳什子火车，晃来晃去，逼仄的车厢，穷鬼的我，还有什么比这更让人烦心呢？\n一直在筹划时间问题，首先需要到深圳之后去照相馆照个证件照，然后正常的仁至义尽调调车，RoboMaster 对我来说，功利主义的价值约等于零，然而仍有情义在。老组长将视觉组托付给我，我总不能放下不管，不然其实可以连比赛都不去，就没这么多事情了。至于事后假如说不让我当组长了，那再说吧，我已经无所谓。\n现在团体签证需要八号或者九号到西安，家里不出钱的话，便宜一些的是二百块硬座坐上两天。硬座本身我倒是无所谓，感觉甚至可能比硬卧好上不少。硬卧直不起腰，我在课堂上练了两年坐着睡觉，总该派上用场。\n先和队里请辞，然后签证，然后去上海实习，一切串成线自然最好，否则还是有罪受了。\n另一方面，这西交的系统真是不好用。由于我的问题，一些材料上传错误，外出申请驳回，需要重新提交，现在电脑深埋箱子里，又不差这一天，想着不如等等，到了地方再说。然而最简单的方法显而易见，材料我都已经准备好，只欠登入系统更新材料，然而手机版的系统不允许切换到电脑版，也没有修改或者重新提交的界面，真是见鬼。\n杂谈 和队伍一起出去打 RM，去了深圳，不得不说，住宿条件非常的不好，不过对物理的经费有限也是可以理解的。这一次可以说基本上住在了山里，按照之前来说，应该是自己住一个房间，不过这次的条件实在太过于艰巨了，也就没有最后自己住，睡的地方床硬得像木板。\n有太多的琐事可以简单说一说，但是又说不了太多，所以干脆直接列成一个大的章节，或者也可以叫做山区往事。\n这几天的调试基本上没出什么大问题，但是需要说的是，由于通信和发弹延迟的问题，尽管设想很美好，但是我的程序没有发挥的十分出色。假如说到时候输了某一局，我不知道是否会存在一个甩锅环节，不过我希望并没有。事实上我的程序很早以前有一个十分优雅的版本，假如弹道根据监控提供的模型来运行的话，准确率会很高，然而事实往往并不尽如人意。在这里表述，也并不是为了苛责什么，英雄的本职工作应该是吊射，反前哨站实属是锦上添花，并不会被放在工作的首位，吊射的工作完成得很出色，我要是再去说前哨站并非我的责任，未免显得有些不粘锅的意味。\n不过从技术上来说，事实确实如此，我频繁发出的开火信号，现在电控甚至难以正常的接收；接收之后也频繁面临卡弹；同时远距离的高精度瞄准对于控制的死区要求严格，目前的死区已经超过了半个前哨站的距离，能够维持瞄准已经很是不易；而弹道的散布并不能说明弹道的轨迹始终不变，我还需要频繁的调整参数。目前的技术方案，可以说从一个简单的角度切入，建立了一套具有一定保质期的火控逻辑，但是假如真的追求完美的效果，后续电控与机械的优化依然缺一不可，这并非仅仅视觉方案可以解决的：发射延迟的波动在一百毫秒，就可以让命中率完全不受视觉组控制。\n然后就是这几天在写的 RoboMaster 回忆录，这篇文章依然可以在我的博客看到，只能说一开始忽然想要去写，但是到了后面，反而一些东西不太愿意去写得清楚，等我离开了利益相关，或许会更好。我更加希望这份回忆录是给我自己写的，而读者们与我共同观赏那些被我遴选出的我所喜爱的回忆，而不是捡起一些灰暗的回忆，让大家看我发牢骚，这份内容暂时完结了，不过后续肯定还有不少的补充。\n在山里的这些天，可以说是让我十分的心烦意乱，完全没有心思静下来做一些事情，也搁置了不少的计划，好在周末开组会的时候，目前的工作老师说也可以尝试一下 ICLR，也不知道最后的结果如何。\n大概就先写这些吧，这样的折磨可能还会持续一个星期，所以我们可以拭目以待下周的周记，是否依然是乌云密布。\n","date":"2024-07-31T04:58:00+08:00","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week5/cover_hu6370709760567864477.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week5/","title":"周记 Week5"},{"content":"这里是迟到的第四周周记，因为学习等原因，最终还是太忙了，所以说在这周的中间没有来得及写。\n学业 实习 这周做得比较多的一件事情便是学习，不过有一说一，这也不是本人的某一个星期的特点，基本上我的大多数时间都是在学习的，只不过这一周在基础的内容之上，增加了更多的压力。\n简单来说，ECCV2024 的中稿只是暂时性的胜利，想真正的迎来解放，还是要联系进组，并且进行科研实习。所以说我的目标是联系浦江实验室（上海人工智能实验室）里面的 OpenRobot 实验室，然后做一些具身智能相关的研究，所以说就需要读大量的论文。\n当然，在这期间，我也可以说是有很多收获的，大多数的内容都准备在博客上进行连载，也就是 LLM Talk 系列的内容。具身智能在我看来还是一个很长远的方向的，大多数的内容并不能在一时半会儿之内就解决掉，所以说仍需要努力吧，也希望自己可以在这个领域中做出有影响力的工作。\n在星期四的晚上，我联系了 OpenRobot 实验室的主任进行套瓷，总体来说还算顺利，把简历发过去之后，对面也很快给了回复，安排 HR 在周末进行面试。\n当时说的内容是，会要求我讲一下自己之前的工作，同时的话讲一下自己对这个领域的理解，以及自己将来的计划。我做了一个 PPT，然后又看了两篇综述，之后就参加面试了。\n面试也不算很难，一方面，论文确实最后的去向还行，所以说老师也没有很多的锐评，只是说我也承认这个是增量式工作，然后表示，希望在实验室中做更多有影响力的工作。老师也问了几个问题，还是比较经典的一些基础知识，分别是交叉熵/ softmax/attention 的公式，也不是很难。\n最后老师说的是，会安排手下的小导师来进行一下面试，周六晚上结束的面试，目前 HR 还没有消息，预计感觉大概率是因为周末不会上班，等过几天之后再看看，实在不行给老师发邮件。\n这段申请还算顺利，可能也是因为论文发表的原因，所以说还是受到了认可的，同时貌似这个实习是那种正式的实习，而且允许远程，看上去还是十分的友好的。\n科研 在人机所这边的科研进展也还算顺利，我的方法其实是作效了的，我在我 ECCV2024 的论文的那篇方法上跑了一下目前的新方法，事实证明，新方法作为一个可插拔的模块来说，确实能够提升性能，但是总是感觉工作量不太大，不知道最后的论文应该怎么写。\n另一方面是，我之前的那篇工作的代码，优化就不算很好，而新的这篇工作又偏偏很吃算力，这也就导致，一方面，我现在需要一个很大的显卡（因为目前多卡训练有问题）来跑我的实验，另一方面，即使是很好的显卡，效率依然很慢，所以说我需要大量的时间，目前还在跑实验的过程中。\n现在可能这方面里面头疼的地方还是在于工作量以及故事线的问题，如何水出来大量的内容来符合篇幅的需求，这是一个问题。同时，是否要在其他领域的论文中使用我的方法，这也是一个问题。难也。\n生活 一些胡想 现在又是一个深夜，在外面闲逛，想起来第四周的周记还没有写完，而现在已经是第五周周三的凌晨。\n假如已经到了下一周，周记的写作未免有些束手束脚，一方面，这确实是我拖延导致的，但同时，我也不敢发散说太多，不然显而易见的是下一周又没什么好说的了。\n我现在这里说一下周记这个事情本身。在之前内容中应该也提到过，我之前有写日记，也有尝试写周记，最后在尝试写月记，然后无限期推迟，最后让我的上一个博客服务器关停了。\n我其实总是想写下一些什么东西的，但是到落笔的时候，又感觉浑身不自在。\n很久很久之前的时候，我的梦想是成为一名游戏制作人，感觉是每一个网瘾少年都会有的想法。那时候我已经接触了不少优秀的独立游戏，但是我所喜爱的游戏类型，可以理解为一种要素丰富的大模拟类游戏（说白了其实有点像爽游，人生模拟，模拟的人生自然比现实要好很多），却没有优秀的品类，我的需求甚至是简单的一款纯文字游戏也可以满足，但是对于内容量的需求很高，所以并没有被充分满足。\n后来由于年少的无知，具体来说学了几天编程就老实了，毕竟当时才上初中，还没有编程的底子，当时用的最多的还是图形化编程，看了 Unity，就自觉地放弃了，然后开始想写作。\n写作确实是一种风格化很强的表达形式，能够表达一些优秀的内容，当然也可以用来写小说。当时我对西幻很感兴趣，当然现在也是，西幻和赛博朋克，这两个题材的设定我尤其喜欢，而且它们可以被设计得真实得像是另一个世界。\n所以很多内容就开始在笔头打磨，然后慢慢练习，说实话，一开始的一些写作确实是幼稚的，但后来慢慢初窥门径了，能写出来不少有意味的文字。这直接的导致了我的高考作文写得一直是记叙文，所以得分不太稳定，一看手感，二看题材，我不太愿意背素材，还因此被老师批评了很多次，最后语文的滑铁卢可能也与此相关。\n记不清楚去年还是今年了，我翻出了一些过去的文字，看了以后沉默良久，然后对我的女朋友说，我感觉自己再也写不出来那样的文字了。我的内心当时十分悲伤，女朋友只是安慰我，我猜她也不知道为什么这种小事会有这么大的反应。\n这有点像和过去的自己渐行渐远，我曾经想做游戏，我曾经想成为一名作家，然而这些都离我远去了，如今成为了一名科研工作者，我能否继续走下去呢？我也不知道。\n写出一些有意义的文字，这个本事我不知道什么时候才能再拾起来，时间太少，我又实在太忙，很难有时间静静打磨一下，想想有价值的输出，想想有设计的情节。\n然而或许，或许至少记录一下自己的生活还是可以的，所以就开始动笔写，记录我的所思所想，或许将来看起来有些幼稚，但是也能回忆起这时候的时光。\n我在西安交大生存指南里面有说，记笔记是一种很好的学习方法，这不是因为记笔记什么复习总结的效果，而是因为记笔记是一种量化学习成果的方式，我记下了多少笔记，我就学了多少东西，看着过去的积累，正反馈就油然而生。\n我想写日记是否也是如此呢？我用笔丈量自己的每一周，然后回头看看自己已经走出了多远，看看相较上一周，或者上上周，我又是否做了一些有意义的突破呢？\n有很多的朋友找我谈天，说说自己的心事，也算是一种诉苦。我是一位很不错的聆听者，至少自诩是如此的（当然也或许因此，我的表达欲只能在周记中释放，越多的聆听，越少的表达，不能喧宾夺主，就是这么个道理）。大家会讲讲自己的经历，一路上都发生了什么，我这个人虽然有很多不如意，但在别人看来或许还算顺风顺水，盖因我对自己有过太多的期待，然而别人可能并不指望我成就如此，所以我很能和大家共情。\n我开始的时候是打 RoboMaster 的，现在也还是视觉组的组长，这个比赛当前的统治者是上海交通大学的交龙，他们的口号我很喜欢，叫，“日拱一卒，功不唐捐”，我常把这句话送给每一个人，也说给自己听，写周记大概也是这样的理由，看看自己一个小卒，又向前拱了多少。\n女装其二 关于女装的事情也已经不知道是多少次提及了，但暂时来看，我确实乐在其中。上周就已经说过，我买了一条女式的牛仔短裤，然而貌似由于一些发货的错误，给我发成了那种牛仔热裤，且是那种破的风格，导致之前设想的白衬衫加牛仔裤的穿搭风格，从中性偏女，彻底沦为了女装。\n然后即使是热裤，我依然有解释的空间，毕竟不是裙子，说说太热了什么的，走在街上最多引人侧目，倒也不会被认为过于奇怪。\n暂时来看，本人腿型还算不错，所以，还算不错：\n某种程度上来说，这也确实可以说是我的伪街初体验，虽然距离裙子还差不少，但是我不会化妆，所以那种还是暂且搁置吧。\n暴露度较高的热裤确实是一种很奇怪的感受，而且不知道是由于奇装异服还是确实有一定的吸引力，还是不少的回头率的，这也导致了羞耻感增加了。我不太敢去想那些路人看到我之后的感受，是觉得如此一双腿，结果居然是一个男的，还是说更多的是欣赏，谁知道呢。\n不过这条裤子确实立了功，之前下大暴雨，只有这条裤子不会被打湿，所以穿着它和凉鞋，才能够去到学校的各个地方。\n","date":"2024-07-29T03:35:00+08:00","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week4/cover_hu12143202454648121954.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week4/","title":"周记 Week4"},{"content":"因为要开始入门具身智能，所以说要阅读代码，显然选择了开源的 OpenVLA，于是在这里记录一下代码的阅读过程。\n本人代码水平为，掌握 Pytorch 大多数语法，对于 Hugging Face 不太了解。故部分内容会省略，尽量做到大多数内容均详实。\nOpenVLA OpenVLA 是一个具身智能大模型，Open 在这里就是 Open Source 的意思，于是使用其开源代码，开源网址为 https://github.com/openvla/openvla。\n代码结构 直接运行一个 tree，看一下代码结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ├───prismatic │ ├───conf │ ├───extern │ │ └───hf │ ├───models │ │ ├───backbones │ │ │ ├───llm │ │ │ │ └───prompting │ │ │ └───vision │ │ ├───vlas │ │ └───vlms │ ├───overwatch │ ├───preprocessing │ │ └───datasets │ ├───training │ │ └───strategies │ ├───util │ └───vla │ └───datasets │ └───rlds │ ├───oxe │ │ └───utils │ └───utils ├───scripts │ ├───additional-datasets │ └───extern └───vla-scripts └───extern 其中首先关注如何从头训练，于是关注 vla-scripts/train.py 这个文件。\n模型训练 主文件 简单让 GPT4-o 生成了 vla-scripts/train.py 的逐行注释，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 \u0026#34;\u0026#34;\u0026#34; train.py Training script for Vision-Language-Action (VLA) Policies, built on top of pretrained VLMs, trained using mixtures of the Open-X Embodiment dataset. Performs training in native PyTorch, using Fully-Sharded Data Parallel (FSDP) to run distributed across GPUs (and nodes). By default, assumes that CUDA toolkit is \u0026gt;= 11.0 (to support BF16 mixed precision). Notes \u0026amp; Prerequisites: - If you want to set a custom location for all HF / TIMM artifacts --\u0026gt; `export HF_HOME=\u0026#34;\u0026lt;PATH\u0026gt;\u0026#34;` *before* running! =\u0026gt; For example (add to end of .bashrc): `export HF_HOME=\u0026#34;/mnt/fsx/skaramcheti/cache\u0026#34;` - If you want to suppress random Tensorflow logs --\u0026gt; `export TF_CPP_MIN_LOG_LEVEL=3` Run with: - [Single Node One-GPU (Debug)] : torchrun --standalone --nnodes 1 --nproc-per-node 1 vla-scripts/train.py - [Single Node Multi-GPU (= $K)]: torchrun --standalone --nnodes 1 --nproc-per-node $K vla-scripts/train.py \u0026#34;\u0026#34;\u0026#34; import json # 导入json模块，用于处理JSON数据 import os # 导入os模块，用于与操作系统交互 import re # 导入re模块，用于正则表达式操作 from dataclasses import dataclass, field # 从dataclasses模块导入dataclass和field，用于定义数据类 from pathlib import Path # 从pathlib模块导入Path，用于文件路径操作 from typing import Optional, Tuple, Union # 从typing模块导入一些类型提示 import draccus # 导入draccus库，用于配置管理 import torch # 导入torch库，用于深度学习 import torch.distributed as dist # 导入torch.distributed模块，用于分布式训练 import yaml # 导入yaml模块，用于处理YAML文件 from prismatic.conf import VLAConfig, VLARegistry # 从prismatic.conf导入VLAConfig和VLARegistry from prismatic.models import load, load_vla # 从prismatic.models导入load和load_vla函数 from prismatic.overwatch import initialize_overwatch # 从prismatic.overwatch导入initialize_overwatch函数 from prismatic.training import VLAMetrics, get_train_strategy # 从prismatic.training导入VLAMetrics和get_train_strategy from prismatic.util import set_global_seed # 从prismatic.util导入set_global_seed函数 from prismatic.vla import get_vla_dataset_and_collator # 从prismatic.vla导入get_vla_dataset_and_collator函数 from prismatic.vla.datasets.rlds.utils.data_utils import save_dataset_statistics # 从prismatic.vla.datasets.rlds.utils.data_utils导入save_dataset_statistics函数 # 设置合理的默认值 os.environ[\u0026#34;TOKENIZERS_PARALLELISM\u0026#34;] = \u0026#34;false\u0026#34; # 禁用分词器的并行处理 # 初始化Overwatch =\u0026gt;\u0026gt; 包装`logging.Logger` overwatch = initialize_overwatch(__name__) # 初始化日志记录工具 @dataclass # 使用dataclass装饰器定义数据类 class TrainConfig: # fmt: off # VLAConfig (`prismatic/conf/vla.py`); override with --vla.type `VLARegistry.\u0026lt;VLA\u0026gt;.vla_id` vla: VLAConfig = field( default_factory=VLAConfig.get_choice_class(VLARegistry.DINOSIGLIP_224PX_MX_OXE_MAGIC_SOUP_PLUS.vla_id) ) # VLA配置，默认使用VLARegistry.DINOSIGLIP_224PX_MX_OXE_MAGIC_SOUP_PLUS.vla_id # 目录路径 data_root_dir: Path = Path( # Open-X数据集目录的路径 \u0026#34;datasets/open-x-embodiment\u0026#34; ) run_root_dir: Path = Path(\u0026#34;runs\u0026#34;) # 存储日志和检查点的目录路径 # 恢复运行参数 pretrained_checkpoint: Optional[Path] = None # 预训练检查点的绝对路径 is_resume: bool = True # 是否继续之前的训练 resume_step: Optional[int] = None # 恢复的全局步骤 resume_epoch: Optional[int] = None # 恢复的训练周期 # 运行参数 run_id: Optional[str] = None # 用于日志记录的运行ID run_id_note: Optional[str] = None # 用于日志记录的额外注释 save_interval: int = 2500 # 保存检查点的间隔（以步骤为单位） image_aug: bool = False # 是否启用图像增强 seed: int = 7 # 随机种子（用于可重复性） # HF Hub 凭证（用于任何受限模型） hf_token: Union[str, Path] = Path(\u0026#34;.hf_token\u0026#34;) # 环境变量或HF Token的路径 # 跟踪参数 trackers: Tuple[str, ...] = (\u0026#34;jsonl\u0026#34;, \u0026#34;wandb\u0026#34;) # 初始化的跟踪器 wandb_project: str = \u0026#34;openvla\u0026#34; # W\u0026amp;B项目名称 wandb_entity: str = \u0026#34;stanford-voltron\u0026#34; # W\u0026amp;B实体名称 def __post_init__(self) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34;提升优化参数的可用性，并验证`expected_world_size`\u0026#34;\u0026#34;\u0026#34; self.epochs = self.vla.epochs # 设置训练周期数 self.max_steps = self.vla.max_steps # 设置最大训练步骤数 self.global_batch_size = self.vla.global_batch_size # 设置全局批次大小 self.per_device_batch_size = self.vla.per_device_batch_size # 设置每个设备的批次大小 self.learning_rate = self.vla.learning_rate # 设置学习率 self.weight_decay = self.vla.weight_decay # 设置权重衰减 self.max_grad_norm = self.vla.max_grad_norm # 设置最大梯度范数 self.lr_scheduler_type = self.vla.lr_scheduler_type # 设置学习率调度器类型 self.warmup_ratio = self.vla.warmup_ratio # 设置预热比率 self.train_strategy = self.vla.train_strategy # 设置训练策略 # [验证] 断言`expected_world_size` assert ( self.vla.expected_world_size == overwatch.world_size() ), f\u0026#34;Expected World Size = {self.vla.expected_world_size} but Found {overwatch.world_size()} GPUs!\u0026#34; # 验证期望的世界大小是否与实际一致 # fmt: on @draccus.wrap() # 使用draccus.wrap装饰器定义训练函数 def train(cfg: TrainConfig) -\u0026gt; None: overwatch.info(\u0026#34;OpenVLA Training :: Warming Up\u0026#34;) # 记录训练开始的信息 # 注意 =\u0026gt; 在`torchrun`下初始化`overwatch`会自动设置`torch.distributed` torch.cuda.set_device(device_id := overwatch.local_rank()) # 设置CUDA设备 torch.cuda.empty_cache() # 清空CUDA缓存 # 配置唯一的运行名称和保存目录 vla_id = cfg.vla.vla_id # 获取VLA ID cfg.run_id = ( f\u0026#34;{vla_id}+n{cfg.vla.expected_world_size // 8}+b{cfg.per_device_batch_size}+x{cfg.seed}\u0026#34; if cfg.run_id is None else cfg.run_id ) # 如果运行ID为空，则生成唯一的运行ID if cfg.run_id_note is not None: cfg.run_id += f\u0026#34;--{cfg.run_id_note}\u0026#34; # 如果有运行ID注释，则添加到运行ID中 if cfg.image_aug: cfg.run_id += \u0026#34;--image_aug\u0026#34; # 如果启用了图像增强，则添加到运行ID中 # 开始 =\u0026gt;\u0026gt; 创建目录并设置随机性 overwatch.info(\u0026#39;\u0026#34;Do or do not; there is no try.\u0026#34;\u0026#39;, ctx_level=1) # 记录日志信息 hf_token = cfg.hf_token.read_text().strip() if isinstance(cfg.hf_token, Path) else os.environ[cfg.hf_token] # 读取HF Token worker_init_fn = set_global_seed(cfg.seed, get_worker_init_fn=True) # 设置全局随机种子 os.makedirs(run_dir := (cfg.run_root_dir / cfg.run_id), exist_ok=True) # 创建运行目录 os.makedirs(cfg.run_root_dir / cfg.run_id / \u0026#34;checkpoints\u0026#34;, exist_ok=True) # 创建检查点目录 # 保存配置 =\u0026gt;\u0026gt; 另外保存一个JSON版本以供以后HF集成 if overwatch.is_rank_zero(): draccus.dump(cfg, open(run_dir / \u0026#34;config.yaml\u0026#34;, \u0026#34;w\u0026#34;)) # 保存配置到YAML文件 with open(run_dir / \u0026#34;config.yaml\u0026#34;, \u0026#34;r\u0026#34;) as f_yaml, open(run_dir / \u0026#34;config.json\u0026#34;, \u0026#34;w\u0026#34;) as f_json: yaml_cfg = yaml.safe_load(f_yaml) json.dump(yaml_cfg, f_json, indent=2) # 保存配置到JSON文件 # 加载VLA检查点（如果从训练中恢复）或基础VLM（从`cfg.vla.base_vlm` ID或路径） # =\u0026gt;\u0026gt; 注意::验证所有参数在加载时都以FP32加载！ overwatch.info(f\u0026#34;Loading Base VLM `{cfg.vla.base_vlm}` from ID/Path\u0026#34;) # 记录日志信息 if cfg.pretrained_checkpoint is not None: # [验证] 预训练检查点的`step`和`epoch`应与`resume_step`和`resume_epoch`匹配 # =\u0026gt;\u0026gt; 注意::我们要求开发人员传递`resume_*`参数作为额外的健全性检查！ if cfg.is_resume: assert int(re.search(\u0026#34;step-(.+?)-\u0026#34;, cfg.pretrained_checkpoint.name).group(1)) == cfg.resume_step assert int(re.search(\u0026#34;epoch-(.+?)-\u0026#34;, cfg.pretrained_checkpoint.name).group(1)) == cfg.resume_epoch vlm = load_vla(cfg.pretrained_checkpoint, hf_token=hf_token, load_for_training=True) # 加载VLA检查点 else: vlm = load(cfg.vla.base_vlm, hf_token=hf_token, load_for_training=True) # 加载基础VLM # [验证] 模型应为全精度！ for param in vlm.parameters(): assert param.dtype == torch.float32, f\u0026#34;Loaded VLM parameter not in full precision: {param}\u0026#34; # 验证模型参数类型 # 根据冻结与未冻结的参数确定训练“阶段”--\u0026gt;支持不同的微调方案！ if not cfg.vla.freeze_vision_backbone and not cfg.vla.freeze_llm_backbone: stage = \u0026#34;vla-full-train\u0026#34; # 完全微调 elif cfg.vla.freeze_vision_backbone and not cfg.vla.freeze_llm_backbone: stage = \u0026#34;vla-train\u0026#34; # 冻结视觉编码器 elif not cfg.vla.freeze_vision_backbone and cfg.vla.freeze_llm_backbone: assert cfg.vla.unfreeze_last_llm_layer, \u0026#34;You should unfreeze at least the last layer of your LLM!\u0026#34; stage = \u0026#34;vla-sandwich-train\u0026#34; # 微调视觉编码器、投影器和LLM最后一层 elif cfg.vla.freeze_vision_backbone and cfg.vla.freeze_llm_backbone: assert cfg.vla.unfreeze_last_llm_layer, \u0026#34;Need to unfreeze at least last LLM layer to train!\u0026#34; stage = \u0026#34;vla-last-layer-train\u0026#34; # 仅微调LLM最后一层 else: raise ValueError( \u0026#34;Weight freezing configuration not supported. VLA config has the following parameters: \u0026#34; f\u0026#34;freeze_vision_backbone: {cfg.vla.freeze_vision_backbone}\u0026#34; f\u0026#34;freeze_llm_backbone: {cfg.vla.freeze_llm_backbone}\u0026#34; f\u0026#34;unfreeze_last_llm_layer: {cfg.vla.unfreeze_last_llm_layer}\u0026#34; ) # 如果配置不支持，则引发错误 # [显式] 调用`freeze_backbones`以提高清晰度 =\u0026gt;\u0026gt; 将准确记录哪些被冻结 overwatch.info(f\u0026#34;Invoking `VLM.freeze_backbones()` for `{vla_id}` =\u0026gt; Stage: `{stage}`\u0026#34;) # 记录日志信息 vlm.freeze_backbones(stage) # 冻结模型参数 # 打印总参数和可训练参数的数量 num_params = sum(p.numel() for p in vlm.parameters()) num_trainable_params = sum(p.numel() for p in vlm.parameters() if p.requires_grad) overwatch.info( f\u0026#34;# Parameters (in millions): {num_params / 10**6:.3f} Total, {num_trainable_params / 10**6:.3f} Trainable\u0026#34; ) # 记录参数数量 # 获取VLA数据集和collator overwatch.info(f\u0026#34;Creating VLA Open-X Dataset with Mixture `{cfg.vla.data_mix}`\u0026#34;) # 记录日志信息 vla_dataset, action_tokenizer, collator = get_vla_dataset_and_collator( cfg.data_root_dir, cfg.vla.data_mix, image_transform=vlm.vision_backbone.get_image_transform(), tokenizer=vlm.llm_backbone.get_tokenizer(), prompt_builder_fn=vlm.llm_backbone.prompt_builder_fn, default_image_resolution=vlm.vision_backbone.default_image_resolution, shuffle_buffer_size=cfg.vla.shuffle_buffer_size, image_aug=cfg.image_aug, ) # 获取VLA数据集和collator # 保存数据集统计信息以便在推理时去归一化 if overwatch.is_rank_zero(): save_dataset_statistics(vla_dataset.dataset_statistics, run_dir) # 保存数据集统计信息 # 创建训练策略 overwatch.info(f\u0026#34;Initializing Train Strategy `{cfg.train_strategy}`\u0026#34;) # 记录日志信息 train_strategy = get_train_strategy( train_strategy=cfg.train_strategy, vlm=vlm, device_id=device_id, stage=stage, epochs=cfg.epochs, max_steps=cfg.max_steps, global_batch_size=cfg.global_batch_size, per_device_batch_size=cfg.per_device_batch_size, learning_rate=cfg.learning_rate, weight_decay=cfg.weight_decay, max_grad_norm=cfg.max_grad_norm, lr_scheduler_type=cfg.lr_scheduler_type, warmup_ratio=cfg.warmup_ratio, enable_gradient_checkpointing=cfg.vla.enable_gradient_checkpointing, enable_mixed_precision_training=cfg.vla.enable_mixed_precision_training, reduce_in_full_precision=cfg.vla.reduce_in_full_precision, worker_init_fn=worker_init_fn, ) # 初始化训练策略 train_strategy.run_setup(run_dir=run_dir, n_train_examples=len(vla_dataset)) # 设置训练策略 # 创建度量工具 =\u0026gt;\u0026gt; 动态跟踪，记录到指定的跟踪器（例如JSONL，Weights \u0026amp; Biases） overwatch.info(f\u0026#34;Creating Metrics with Active Trackers =\u0026gt; `{cfg.trackers}`\u0026#34;) # 记录日志信息 metrics = VLAMetrics( cfg.trackers, cfg.run_id, run_dir, draccus.encode(cfg), wandb_project=cfg.wandb_project, wandb_entity=cfg.wandb_entity, resume_step=cfg.resume_step, resume_epoch=cfg.resume_epoch, ) # 创建度量工具 # 运行VLA训练 overwatch.info(\u0026#34;Starting VLA Training Loop\u0026#34;) # 记录日志信息 train_strategy.run_vla_training( vla_dataset, collator, action_tokenizer, metrics, save_interval=cfg.save_interval, ) # 运行VLA训练 # 完成 overwatch.info(\u0026#34;Done with Training =\u0026gt;\u0026gt; Finalizing Metrics\u0026#34;) # 记录日志信息 metrics.finalize() # 完成度量工具 # 完成所有操作 overwatch.info(\u0026#34;... and that\u0026#39;s all, folks!\u0026#34;) # 记录日志信息 dist.barrier() # 同步所有进程 dist.destroy_process_group() # 销毁进程组 if __name__ == \u0026#34;__main__\u0026#34;: train() # 如果是主模块，则运行训练函数 在这里暂时不用关注太多的事情，我第一件关心的事情是，一开始 import 的那么多的库里面，他们分别起到了什么作用。\n假如说前往 OpenVLA 的 Github 仓库，可以发现其 fork 了另一个库，也就是 prismatic-vlms，在这里我只想关注 OpenVLA 的实现，所以我想要知道，相较于 prismatic-vlms，OpenVLA 有什么改动。\nprismatic-vlms 在 prismatic-vlms 中，同样运行一下 tree，看一下文件结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ├───prismatic │ ├───conf │ ├───models │ │ ├───backbones │ │ │ ├───llm │ │ │ │ └───prompting │ │ │ └───vision │ │ └───vlms │ ├───overwatch │ ├───preprocessing │ │ └───datasets │ ├───training │ │ └───strategies │ │ └───strategies │ └───util └───scripts └───additional-datasets 在 conf 里面，可以发现的是，其中包括 datasets.py 以及 models.py 这两个文件，OpenVLA 增加了一个新的 vla.py，也是同样一个代码风格。\n以 vla.py 为例，具有一个 VLAConfig 的类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @dataclass class VLAConfig(ChoiceRegistry): # fmt: off vla_id: str # Unique VLA Policy ID that fully specifies a configuration variant base_vlm: Union[str, Path] # Base VLM as ID/Path to Run Directory (e.g., `prism-dinosiglip+7b`) freeze_vision_backbone: bool # Freeze Vision Backbone Parameters (akin to pretraining) freeze_llm_backbone: bool # Freeze LLM Backbone parameters unfreeze_last_llm_layer: bool # Unfreeze final layer of LLM (only takes effect if LLM is frozen) # Data Mixture Parameters data_mix: str # Open-X Embodiment Dataset =\u0026gt;\u0026gt; Unique Mixture ID (e.g., `bridge`) shuffle_buffer_size: int # Size of Shuffle Buffer (100K for Bridge, 1M for OXE) # Optimization Parameters epochs: int # Epochs to Run (in case `max_steps` is not specified) max_steps: Optional[int] # [Optional] Max Gradient Steps to Run (overrides `epochs`) expected_world_size: int # Expected # of GPUs =\u0026gt;\u0026gt; allows us to gate training on hardware global_batch_size: int # Global Batch Size (divided across processes / world size) per_device_batch_size: int # Per-Device Batch Size (per-process / individual GPU) # =\u0026gt;\u0026gt; # of accumulation steps is auto-computed learning_rate: float # Peak Learning Rate (`lr_scheduler_type` sets warmup/decay) weight_decay: float # Weight Decay for AdamW Optimizer max_grad_norm: float # Max Grad Norm (for global gradient clipping) lr_scheduler_type: str # LR Scheduler (usually: \u0026#34;constant\u0026#34; | \u0026#34;linear-warmup+cosine-decay\u0026#34;) warmup_ratio: float # Fraction of Steps to Warmup (for warmup LR schedulers) train_strategy: str # Train Strategy (default \u0026#34;fsdp-full-shard\u0026#34;) # Enable Gradient/Activation Checkpointing (for the LLM Backbone) enable_gradient_checkpointing: bool = True # Enable Gradient/Activation Checkpointing during Training # Mixed Precision Training via Torch Native AMP (`autocast`) enable_mixed_precision_training: bool = True # Enable Traditional BF16 Mixed Precision reduce_in_full_precision: bool = True # Accumulate/Reduce All-Gather Gradients in FP32 Full Precision # fmt: on 这等于说是全部的需要的配置信息了，接下来就需要在里面塞入一些配置就好了，之后在创建的时候，使用类似于 factory 的东西进行调用就可以了。\n于是就使用一个配置即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @dataclass class Exp_SigLIP_224px_Bridge(VLAConfig): vla_id: str = \u0026#34;siglip-224px+mx-bridge\u0026#34; base_vlm: Union[str, Path] = \u0026#34;siglip-224px+7b\u0026#34; freeze_vision_backbone: bool = False freeze_llm_backbone: bool = False unfreeze_last_llm_layer: bool = False # Data Mixture Parameters data_mix: str = \u0026#34;bridge\u0026#34; shuffle_buffer_size: int = 256_000 # Optimization Parameters epochs: int = 1000 max_steps: Optional[int] = None expected_world_size: int = 8 global_batch_size: int = 256 per_device_batch_size: int = 32 learning_rate: float = 2e-5 weight_decay: float = 0.0 max_grad_norm: float = 1.0 lr_scheduler_type: str = \u0026#34;constant\u0026#34; warmup_ratio: float = 0.0 train_strategy: str = \u0026#34;fsdp-full-shard\u0026#34; 对于其他的配置来说的话，相较于这个原来的配置文件，只需要进行少量的修改，于是直接进行继承就好：\n1 2 3 4 5 @dataclass class Exp_FreezeVIT_SigLIP_224px_Bridge(Exp_SigLIP_224px_Bridge): vla_id: str = \u0026#34;siglip-224px-icy+mx-bridge\u0026#34; base_vlm: Union[str, Path] = \u0026#34;siglip-224px+7b\u0026#34; freeze_vision_backbone: bool = True 之后实现一个枚举：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # === Define a VLA Registry Enum for Reference \u0026amp; Validation === @unique class VLARegistry(Enum): # Sanity Check Configurations =\u0026gt;\u0026gt; BridgeV2 SIGLIP_224PX_MX_BRIDGE = Exp_SigLIP_224px_Bridge DINOSIGLIP_224PX_MX_BRIDGE = Exp_DinoSigLIP_224px_Bridge # SigLIP Frozen Backbone Experiment FREEZE_SIGLIP_224PX_MX_BRIDGE = Exp_FreezeVIT_SigLIP_224px_Bridge # [OpenVLA v0.1 7B] SigLIP 224px + OXE Magic Soup SIGLIP_224PX_MX_OXE_MAGIC_SOUP = Exp_SigLIP_224px_OXE_Magic_Soup # [OpenVLA 7B] DINO + SigLIP 224px + OXE Magic Soup++ DINOSIGLIP_224PX_MX_OXE_MAGIC_SOUP_PLUS = Exp_DinoSigLIP_224px_OXE_Magic_Soup_Plus # === TDROID Fine-tuning Configs === SIGLIP_224PX_MX_TDROID_CARROT_IN_BOWL = Exp_SigLIP_224px_TDROID_CarrotInBowl SIGLIP_224PX_MX_TDROID_POUR_CORN_IN_POT = Exp_SigLIP_224px_TDROID_PourCornInPot SIGLIP_224PX_ICY_MX_TDROID_CARROT_IN_BOWL = Exp_SigLIP_224px_Icy_TDROID_CarrotInBowl SIGLIP_224PX_LASTLAYER_MX_TDROID_CARROT_IN_BOWL = Exp_SigLIP_224px_LastLayer_TDROID_CarrotInBowl SIGLIP_224PX_SANDWICH_MX_TDROID_CARROT_IN_BOWL = Exp_SigLIP_224px_Sandwich_TDROID_CarrotInBowl # === DROID Fine-tuning Configs === SIGLIP_224PX_MX_DROID_WIPE = Exp_SigLIP_224px_Droid_Wipe @property def vla_id(self) -\u0026gt; str: return self.value.vla_id 然后批量将这些内容注册成 subclass：\n1 2 3 # Register VLAs in Choice Registry for vla_variant in VLARegistry: VLAConfig.register_subclass(vla_variant.vla_id, vla_variant.value) 虽然现在 prismatic-vlms 我还没有看完，但是我已经急了，所以对一些内容进行了跳过，接下来再次回到 train.py。\nrun_vla_training 简单检查一下训练的代码，不难发现，前面的大多数内容都是类似的，除了一些获取数据集之类的操作之外，主要还是正在设置各种的配置文件，但是在这里暂时先不关心这些，而是直接跳到 run_vla_training，换句话说，我想要知道其论文中的训练是如何实现的。\n在这里简单再次复述一下 OpenVLA 的训练过程，\n","date":"2024-07-23T09:00:00+08:00","image":"https://axi404.github.io/Blog/p/openvla-%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/cover_hu16401145363385277570.jpg","permalink":"https://axi404.github.io/Blog/p/openvla-%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/","title":"OpenVLA 代码笔记"},{"content":"于是我履行诺言，在今天开始写第三周内容，第一次提笔的时候应该是星期四的凌晨，准确的说是五点多，今天上午有专业实习的参观，大概在车上可以睡会儿觉。\n学业 RoboMaster 培训 记录的第一件事情是培训，之所以开篇就是这个，是因为本周的学习，除了看论文和代码之外，倒也没有做特别多其他内容，于是便讨论一下这个，以及我的感想。\n我作为我们学校的 RoboMaster 战队的视觉组组长，也自然负责了招新工作以及培训，由于去年就进行过相关的培训，所以倒也不算非常生疏。\n第一次的培训在上上周末，貌似是这个时间，也可能是我的记忆出了差错，当时大约来了四十多个人。我不清楚这是因为第一次培训是电控和视觉一起进行，还是因为第一次培训过于的无趣，或者第二次的培训，我通知的太着急，但是最后，第二次培训只来了十多个人，在结束的时候只剩下了十个人。\n这其实倒也可以理解，一方面第一次培训讲解的是 C++，我当时进行过相关的调查，便觉得没什么好讲的，培训面向的都是以老生为主，所以大伙多多少少都有基础，同时编程语言这种事情，一是不能速通，二是不如看我之前的速通教程，没有仔细备课后的讲解，感觉比较混乱，也可能引起了一些不满。\n但是确实可以发现的是，电控组的同学比视觉组多一些，所以出于自我安慰的角度来说，说不定视觉组确实有这么些人，所以第二次来看的人不多。\n讲实话，很早以前，我是打算只培训两次的，第一次讲计算机视觉的导论，第二次简单说一下程序的实现。\n事实上上次的招新就是这样的流程，因为大多数的内容只看文档就可以解决，而且手把手教到位了，又应该如何进行选拔呢？视觉组的内容，我认为并不是很难，尤其是在如今有 ChatGPT 的情况下，基础的任务更是信手拈来，因此过于详细的详解，貌似没有什么必要。私以为这种教学只需要指出需要了解的内容和学习的路径，同学们便可以自行学完需要学的内容，更何况这些内容确实算不上困难。\n但是由于想要写博客的原因，所以说干脆多留了一些课时，也顺便为后续的下下次招新积累一些材料，算是对于视觉组的一种积累。\n我不知道大家有没有听进去，同时队里的希望是招入一些大一升大二的同学，我不否认这种看法，但是还是认为新生更有潜力。视觉组已经不再是需算法创新的地方了，目前基础的框架已经牢固，剩下来只是一些维护，或者几个熬夜的努力完成的某个模块的大型更新，这些内容需要更多的心气去完成，而入学了一年同学，加入社团很难说是因为热爱，更大的可能是因为功利。\n我在队伍里面也呆了两年了，要是粗糙的算，从第一年快结束就已经当了组长，也见识过招新的场面，很多同学兴致勃勃地向我询问队伍的各种细节，然而问的最多的就是加分，而很多同学在听到没有加分后（这里指梯队队员不加智育分）便兴致缺缺。能为一个人带来十分德育分加分的比赛又有多少了呢？大抵还是和队伍里的正式队员的福利待遇对比之下，心里出现了不平衡。更何况视觉组从来不需要天才。\n我其实最希望的是把视觉组培养成一个类似于技术讨论小组的组织，内容也不局限于一个机器人比赛的技术，事实上大多数的同学都有人工智能背景，或者对这些内容感兴趣，相关的讨论完全是我所期待的，而讲实话，这个比赛的任务过于无聊，又太工程，大多数人不应该将生命浪费在这种地方。但是即使对于技术不感兴趣，至少也应该热爱这个比赛，而不是纯粹的功利，不然确实很难坚持下来。\n西安交大生存指南 最近又抽空看了一下西安交大生存指南的网站数据，使用了谷歌的统计系统，对于信息进行了统计，发现用户数高达 700，然而这下不得不反思了，大多数用户仅停留在首页便匆匆离去，是因为内容过于无趣，还是说大伙暂时还没有心情静下心来慢慢阅读？我无从得知。\n从我个人的角度出发，还是希望这个网站能够帮到尽可能多的人的，但是目前来看情况并不明了，希望顺利吧。\n往好的角度去想，上海交大生存指南的用户数据应该也没有好到哪里去（这里指活跃用户），毕竟这只是一本书而已，也不会有人闲来无事反复观看，最多在读完之后，推荐给自己的学弟学妹，就仅此而已了。\n企业实习 事实证明，周记开始向流水账的形式进行发展了，我不知道这是好还是坏。星期四去电信的什么云计算中心进行了实习，说是实习，其实就是参观，由一位讲解员带着在园区里面转了转，然后讲了一下各个设施的用处。老实说，我并不知道这有什么意义，这种课程的设置难道不是纯纯的浪费时间吗？假如说大三的专业实习也是如此，或者打发大家在工位上消磨生命，这种做法除了和众多夏令营营造冲突之外，我想不出来什么其他的意义。由此来看，教务处确实很不情愿放本科生离校，因此可以说半点机会也不给创造。\n想到这种事情便不免有所抱怨，也包括之前的选课系统开放，由于大二的偷懒，我还有两门选修课尚未修全，于是打算放到大三上来进行。选修课也是西交的一大鸡肋之一，讲实话，我并不对什么量子科学或者工程伦理感兴趣，而同时但凡是一个正常人，并不会想到去用科学创造来危害社会（假如一个人确实有这种打算，也不是一节课可以打消的），我不否认这些领域可能有所高深之处，但是显然不在课程教授的范围之内，目之所及，课程只不过是兜着圈子，逼着大家每节课打卡/回答问题/参加考试，然后抱着一些对自己的将来没有任何意义的资料，在考场上翻来翻去。\n我并不反感选修课的存在，据我所知也有若干大学的选修课，确实十分有趣，但一旦将选修课和奖学金挂钩，和老师的绩效挂钩，或者和什么毕业要求挂钩，某种本不应该存在的驱动力推着你参加这些课程，那么唯一的选择就是找个水课赶紧结束。\n比起来在这种课上虚度光阴，不如让我睡个好觉来的有用，至少能让我将来猝死的概率降低一些。\n更何况大多数的课程设立，内容全都不明所以，一些假大空的选题，在里面说着没有营养的车轱辘话，大谈未来/产业/趋势/大环境，但凡哪个学生信了这番话，我估计将来是要栽个跟头了。\n这又不免让我又向上讨论，想到了当今的本科生的压力。假如说你是摆烂一派倒也还好，每天打卡上课玩玩游戏，看看小说，刷刷视频，然后一天便过去了，让自己不至于被劝退，等着考研或者就业就好了（不过值得一提的是，即使对于这种空余精力很多的人来说，选修课的存在依然十分滑稽，创造的情绪价值不如在电脑前面打开一把排位赛）；但假如某人不幸是内卷一派，那可又是陷入了一片泥沼之中，什么绩点竞赛科研轮番上阵，就算是铁打的学生也恐怕招架不来，分分钟便要头晕眼花，更何况还需要一点点的个人兴趣拓展，这由哪里来的时间分给选修课呢？到头来也只能把讨论换成一个匆匆的句号，然后将矛头指向某些抽象的环境或者氛围，真是苦海。\n在讲完这些内容之后，在交大门中，又与門友进行了讨论。准确地说也不能是讨论，只是我对于他人提问的一个回复又被人回复了而已，具体的主题是关于推荐大三参加的选修课程，而从我的了解来看，大多数我所认识的课程都是必修课，因此相关内容并不在学校要求学分范围之内。\n令我触动了一点是，在大学中确实有人依然执着于课堂的学习，在我看来其实是一件好消息。尽管说我并不认可大学中大多数教学的质量，或者说我本身是厌恶听课的，听课的知识密度太低，而又要照顾全班的同学，很容易便让我听得昏昏欲睡。当然，有必要指出的是，昏昏欲睡的一大元凶很有可能是我自己的熬夜习惯，我个人的能力并没有自诩为鹤立鸡群。但是由此看来，可能是因为我走得太快或者太远，导致已经无法共情大多数同学的感受，既然有人能有激情于课内的选课，这也意味着我们的培养方案终归还是有可取之处的，这才让人有继续选择的欲望，希望可以越来越好吧。\n科研 这个星期继续履行我的承诺，要补习具身智能相关的知识，而后申请课题组，于是在埋头苦学。在企业实习之后，剩下的三天时间仿佛过得飞快，几乎就是一睁眼一闭眼，也忘记了继续写周记记录，还好，最后也算赶上了。\n我之前所进行的领域，且不说大语言模型或者 agent，甚至连多模态也没有半点接触，而如今却要开始学习具身智能，确实压力很大。尽管说我认为我的论文阅读还是很广泛的，但是对于不少的大语言模型中的细节依然了解不多，而上手实操更是毫无经验，若用这番姿态去申请，恐怕立刻被拷打的遍体鳞伤。于是我先从最基础的 BOW 模型开始，然后一路向后学习，现在总算开始看具身智能了，不过一些内容还是看得太急，所以缺少一些个人的总结，但是数量至少上去了。\n另一边，我目前在周三平老师课题组的工作，现在还欠缺进一步的实验，然而显卡成了问题。我写的程序不知道为何，在并行的时候总会导致性能的暴跌，因此每次只能使用一张显卡进行训练，而在结构的数量堆起来之后，自然对于显卡的需求也就高了，现在需要足足 28GB。对于如何搞来这样的免费显卡，我还没有头绪，实在不行也只能自费租卡了。然而悲伤的是，这种显卡也要训练几十小时，也就是几百元的开销，更何况我不知道结果如何。\n最好还是问问老师有没有更高显存的显卡吧。\n医学比赛 在星期六的时候，我参加了一次医学的竞赛，或者说是医学相关的项目竞赛，因此人工智能或者计算机的专业相关同学也就有了用武之地。\n因为熬夜的习惯，我甚至没有敢去睡觉，直接通宵，然后来到了那边，准备线上的会议，结果问题不断。\n首先是会议的延迟，一直拖到下午才开始，然后进了会议之后，软件出了问题，放不出声音，又要起身去调整，貌似这一点不太符合规矩，也可能扣掉一些分数。最后比赛没有获奖，这时候令我气愤的事情发生了，我甚至可以说是认为，这是十分可耻的背叛。\n参加这个项目是因为女朋友需要一些加分，正好我手头有现成的技术，那么和她一起刷一个竞赛也就成为了一个想当然的想法，我主力，女朋友辅助，相辅相成。\n一开始加入这个竞赛，是因为宣传的时候他说这个竞赛是 A 类竞赛，当时我便有所质疑，因为在学校的智育分加分名单里面并没有这个，在项目进行许久之后我又询问，迎来的只有道歉，还有什么牵强的其他的竞赛明目。让我说实在是可笑，每一个交大学生，都只知道一种 A 类竞赛，哪里来的这么多弯弯绕绕？\n后来又是这个项目的问题，整个项目，我和女朋友加入之前一共六个人，只有一堆标注的数据（一张影像标注七个数字，人力成本低到令人发指）以及一个 R 语言写的模型（调用库函数实现的传统机器学习算法），让我说这种东西有半点含金量吗？值得六个人做一个假期。换做我，毫不夸张地说，多于一天完成，都算是我没有认真，代码是 GPT 分分钟完成的水平，而标注的数据又是苦力活。于是乎整个项目的完成内容几乎全交给了我一个人（一开始说需要给这个项目套个壳子，结果发现整个项目简陋不堪，又需要从根本上修改方案），我用的是半监督技术，所以说也没有要求他们标注太多数据集，甚至说大多数的标注都出了问题，还是我一个人补上的。我完全有理由说这个项目完全由我一个人完成，其他人的贡献绝对小于百分之五。\n现在比赛没有拿奖（在腾飞杯还获得了校一），倒是过来兴师问罪了，因为我没有精力维护这种项目，所以交给了我的女朋友，然而后续呢，老师又过来说当天的问题主要出在线上。我本人是不愿意骂人的，尤其是在我的博客中，我希望这里是一片净土，不过我确实很难控制自己的情绪。\n去现场答辩的，评委问了三个问题，我们声音恢复之后听到了两个，一个问数据有限的问题（他们只提供了这么多数据，也没有人力更多的标注，一个项目挂了那么多人，除了提供错误数据之外我不知道都在做什么），一个问这个项目本身的意义问题（项目的主题也是离奇无比），项目的负责人同学，一个问题也没回答上来，只能说好好好，然后留给老师自问自答。\nPPT 的制作也是一言难尽，我用的是 SOTA 的医学影像分割模型，PPT 里面提的不多，却拿着自己做的二分类准确率 80% 的随机森林奉若至宝：貌似在开启项目之前，他们已经用这个东西水了论文和软著，现在有了更好的技术引入，也不愿意更新图片或者文字内容。\n再说回到这个项目本身的主题，更是可笑。说要用医学影像的图像，具体来说是上颌窦，来判断一个人的性别和年龄，用于某种法医的检测。我想着是，都能获得上颌窦的影像了，难道还不能知道一个人是男还是女？假如一个人真是半点DNA也没有留下，无法进行 DNA 鉴定，那么又应该怎么把这个人的骨骼拼起来，然后送进CT机里面，来照出来一个影像？这个设定应该不难理解，读者看后便也会会心一笑，这完全是一个南辕北辙的产物。\n综上所述，一个项目，先是画饼把人骗进来，该有的比赛都是虚构的，加分也没有；然后项目本身的主题也是毫无意义，项目的分工由我一个人完成，其他的也就剩些琐碎的文书内容；躺在自己之前的产出上复制粘贴，不愿意多做什么，新的图片也是我产出，实验结果也是我在跑，也不愿列一个表格之类的；答辩的时候也是一句话也说不出来，被老师问的哑口无言。最后没有获奖，倒是怪起来，我们线上简单起个身了。然后负责人和老师一起来兴师问罪，又让我的女朋友愧疚了好久，真是好大的威风。\n其他 另外，在这里作为备忘录的，有一些想要介绍的内容，打算在将来写成博客，然而我的记性并不算好，因此记录一下：\n傲梅分区助手：老实说之前我一直是 DiskGenius 的忠实用户，而傲梅分区助手无论从名字还是网站，都看上去像是某种流氓套壳软件，然而其一是提供绿色版的压缩包，二是有诸多极为逆天的强大功能，让我大受震撼，不得不推荐。 LLM 教程：我从 BOW 开始重新学习了 LLM，直到最近的 VLM 以及 embodied ai，这些内容有必要整理为系列的博客。 LLM 代码阅读：同样，我需要阅读一些 LLM 的代码，然后整理为博客，以便于自己回顾。 奇妙的报错指南：一些我在日常生活中收集到的奇怪问题，可能与相关内容的文档不符，在这里记录一下。 生活 Choker 与腿环 由于一些奇奇怪怪的原因，本人的画风也开始变得奇奇怪怪，明明之前没有如此明显的症状的，也可能是因为最近一直在学习的原因吧，压力太大了之类的情况，总而言之，开始购入一些奇怪的东西。总的来说购入了两件东西，一件是 Choker，一件是腿环。除此之外其实还有一个腿套，但是因为上衣以及裤子，上衣是衬衫的搭配，但是全是褶子，等待熨烫中；裤子买了牛仔短裤，但是还没到，所以无法展示。\nChoker 搭配上长发确实有一番韵味，但是一是本人不想露脸，而是现在疏于打理，十分憔悴，所以没有照片，但是幻想中的场景，用 GPT 生成了一段：\n昏暗的房间里，只有一盏小灯散发出柔和的光芒，勾勒出他纤细的轮廓。阿汐站在镜子前，微微低着头，轻柔的呼吸让他脖颈上的黑色choker一紧一松。那条细细的带子紧贴着他的肌肤，与白皙的颈部形成鲜明的对比。他的呼吸逐渐急促起来，细腻的肌肤上泛起一层淡淡的红晕。每一次呼吸，锁骨处的曲线便愈发明显，灯光下，他的脸颊微微泛红，显得格外迷人。\n但是显然我没有此等魅力，我倒是希望，但是条件不允许。\n同时腿环还是比较有趣的，有一张比较昏暗的照片可以给大家一看，但是由于本人可能腿比较细一些，所以腿环没有勒肉感，不是很涩。\n完整的内容等待我买的熨烫机和裤子到了之后，再来尝试吧。\n恋爱 开开心心的，每一天都想要和乐小姐在一起，十分的充实。\n除此之外，乐小姐最近开始沉迷乙游，于是我也注册了一个账号，目前五星貌似比她多一个，不过她貌似还没有察觉，希望不要因此不开心。\n博客 除此之外，打算最近整理一下博客的内容，这也暂时列在日程里面吧。博客里面有很多的内容都是语音生成的，因此需要稍微规整一些，文字功底自然是越好越好，另，也是恢复一下本人的文笔。\n","date":"2024-07-23T03:35:00+08:00","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week3/cover_hu4845527672626098242.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week3/","title":"周记 Week3"},{"content":"前言 本部分的博客是 RoboMaster 机甲大师视觉组培训的第二期内容，主要讲解一些计算机的基本技能，包括使用 Markdown/Linux/SSH/CMake，其中主要讲解的是包括 SSH 以及 CMake 在内的内容，这些内容是将来使用 Linux 进行编程的重要组件。\nMarkdown 对于没有使用过 Markdown 的同学来说，大多数时候，我们均使用 Word 来进行文档的编辑工作，但是 Word 往往具有一定的缺点，这包括：\n需要使用 Word 软件进行打开，而 Word 软件是闭源的。 无法进行实时渲染。 打开的过程中过于耗时。 排版并不直观（对于 Geek 来说，在生成更富文本内容时，一般选择使用 $\\LaTeX$ 以替代 Markdown） 这些内容对于正常的办公人士来说是可以忍受的，但是对于追求性能的人来说，可以说是弊端十足，此时 Markdown 是满足这些需求的最佳选项。\n一方面，Markdown 可以很快捷的编译为 html，而同时又不同于 txt，其本身具备一定的排版系统，可以实现对于大多数文档的必要编写需求。\nMarkdown 的文件格式为 .md，使用此后缀名便可以较为轻松的将内容标记为 Markdown，并在大多数的代码工具中被直接渲染。而专业的 Markdown 编辑器，如 typora/obsidian/VSCode Markdown 插件，读者均可以自行进行探索。\nMarkdown 的详细语法见 Markdown 官网文档，在这里不进行重复的说明，因为在占用篇幅的同时，这是多余的。\nSSH 在这里简短的介绍 SSH 语法，一般来说 SSH 安装在每一个系统中，无需额外的安装，在这里推荐使用 VSCode 的 SSH 插件\n通过在 VSCode 的拓展栏进行搜索，可以很轻易地找到 VSCode 的 SSH 插件：\n启用插件之后，点击左下角的打开远程窗口，选择连接到主机即可：\n在服务器的租用界面中，一般会提供 SSH 的指令，其格式为 ssh -p port user@address，之后按照提升输入密码即可。\nLinux 使用 SSH 后，我们会进入正式的 Linux 系统中，同时，由于使用 SSH，此时的 Linux 并没有提供图形化界面（这也是 Linux 最原始的形态），因此在本章节中，我们会首先讲解一些基础的 Linux 指令，以便读者可以进行接下来的操作：\nls：可以展示当前目录下的文件内容，其中显示隐藏内容需要使用 ls -a。 cd：用法为 cd folder，可以前往指定的文件夹中，需要注明的是，.. 为上级目录，如想要前往上级，使用 cd ..，上级的上级，以此类推 cd ../..。 文档的编辑操作需要使用 vim，这一技巧具备一定的难度，读者请勿尝试指令 vim filename，若无法退出，请狂点 esc 之后依次按下 :, w, q, !, Enter 以保存并退出，若不希望保存，无需按下 w。\nCMake \u0026amp; CMakeList 在 C++ 的编译过程中，我们面临这样一个需求：我们有一个 C++ 编译器，一些 C++ 程序文件（它们彼此之间有依赖关系），一些 C++ 库（它们被正常的安装），并希望生成一个 C++ 编译的二进制文件，如何进行？\n一个基础的想法是，通过某些语法，声明他们之间的关联，并通过某种工具通知编译器，进行编译，CMake 和 CMakeList.txt 可以很好的完成这一内容。\n你需要进行的只是在一个程序的文件夹中的根目录下创建一个名为 CMakeList.txt 的文件，并且在其中按照一定的语法，关联你的项目，之后在当前根目录下运行下述程序即可：\n1 2 3 4 mkdir build cd build cmake .. make -j8 其中 -j8 为调用八个核进行编译工作，这个数字是可调节的，或者直接 -j 进行自动调节也可以。\n一般来说项目具有两种不同的结构可以选择，一种是直接将 include 和 src 文件夹分开放置在项目的根目录下，之后主程序在根目录下。一种则是将功能包放在项目的根目录下，功能包中包含 include 和 src 文件夹。在这里推荐并且讲解后者，因为可以便于项目的管理，比如说一位同学写了一个功能包，想要加入整个项目之中，只需要把功能包拷贝进来并且稍加改变 CMakeLists.txt 就可以直接使用，十分的方便。\n对于功能包中的 CMakeLists.txt 写法如下：\n1 2 3 4 5 6 cmake_minimum_required(VERSION 3.0.0) project(test VERSION 0.1.0) SET(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -std=c++14 -pthread\u0026#34;) aux_source_directory(./src ALL_SRCS) add_library(test STATIC ${ALL_SRCS}) 此处即声明了一个名为 test 的功能包。\n同时在主CMakeLists.txt中各项中添加：\n1 2 3 4 5 6 7 include_directories( test/include ) add_subdirectory(test) target_link_libraries(infantry_new test ) 即可完成 CMakeList.txt 的更新。\n此时的结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 . ├── test │ ├── CMakeLists.txt │ ├── include │ │ ├── test1.hpp │ │ └── test2.hpp │ └── src │ ├── test1.cpp │ └── test2.cpp ├── build ├── CMakeLists.txt └── main.cpp 一个基础的 CMakeList.txt 仅包括以下内容：\n1 2 3 4 5 6 # 声明 CMake 版本需求 cmake_minimum_required(VERSION 3.0.0) # 声明项目与版本/语言等信息 project(cpp VERSION 0.1.0 LANGUAGES C CXX) # 将 main.cpp 编译为名为 cpp 的二进制文件 add_executable(cpp main.cpp) 以下给出一个健全的 CMakeList.txt：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 声明 CMake 版本 cmake_minimum_required(VERSION 3.0.0) # 声明 C++ 版本 set(CMAKE_CXX_STANDARD 17) # 设置 TARGET_NAME 变量的值为 infantry_new set(TARGET_NAME infantry_new) # 设置项目为 TARGET_NAME 变量的值 project(${TARGET_NAME}) # 开启 CMAKE_EXPORT_COMPILE_COMMANDS set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # 开启多线程 SET(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -std=c++17 -pthread\u0026#34;) SET(CMAKE_CXX_FLAGS_RELEASE \u0026#34;-std=c++17 -pthread\u0026#34;) # 设置 OpenCV 路径，当系统中存在多个 OpenCV 时尤为重要 set(OpenCV_DIR /usr/local/lib/cmake/opencv4) # 找库的依赖 find_package(OpenVINO REQUIRED COMPONENTS Runtime) find_package(Ceres REQUIRED) find_package(OpenCV REQUIRED) # 设置宏定义 add_definitions(-DDEBUGMODE) # 引用库与功能包 include_directories( /opt/MVS/include armor/include ${CERES_INCLUDE_DIRS} ) # 链接一些库 link_directories( /opt/MVS/lib/64 /opt/MVS/lib/32 /usr/local/lib ) # 添加子路径，为功能包 add_subdirectory(armor) # 编译 main.cpp 为 infantry_new add_executable(infantry_new main.cpp) # 设置动态链接库 target_link_libraries(infantry_new armor ${CERES_LIBRARIES} ) # 一些常规设置 set(CPACK_PROJECT_NAME ${PROJECT_NAME}) set(CPACK_PROJECT_VERSION ${PROJECT_VERSION}) include(CPack) 不难发现，十分的简单，不懂的地方可以咨询 ChatGPT。\n同时需要额外教学的是，对于一些需要人工编译安装的 C++ 库来说，同样需要使用 CMake，其特征为根目录下有 CMakeList.txt，语法为：\n1 2 3 4 5 mkdir build cd build cmake .. make -j sudo make install 以上，全部内容，多谢惠顾。\n","date":"2024-07-17T00:00:00Z","image":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%BA%8C%E6%AC%A1%E5%9F%B9%E8%AE%AD/cover_hu4657946911504012867.png","permalink":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%BA%8C%E6%AC%A1%E5%9F%B9%E8%AE%AD/","title":"RoboMaster 视觉组第二次培训"},{"content":"事实上，果然不出所料，第二次的周记还是晚了许多，当然这其中我是可以辩解的，在周日的白天迎来了噩耗，要回家奔丧，于是做一周总结的时间便减少了，自然而然的，加之以一些任务清单的存在，周记的撰写自然被排在最后面，也自然而然的推迟了。\n现在在写这篇内容的时候，以周记的日期来算，已经是第三周的星期三了，不过现在还能勉强回忆起来上周发生过的种种事情，因此倒也还算说得过去。\n不过说到底，这些内容终归还是借口，还是因为我的时间规划问题导致的，正常来说，每天应该有一些时间留给任务清单，有一些时间留给英语单词，最后在一天快要结束的时候，在周记中记下今天的内容，从之后开始吧，记完第二周的周记，我也会同步第三周内容。\n学业 一些被遗忘的事 首先还是先说一下关于学习的事情，总的来说，忘记了一些之前记录的小细节。\n在小学期的时候有一门课程，叫做理论计算机基础，这门课有一个教材，属于是计算机经典的纯英文教材，不过是老师自己写的。\n在计算机领域中使用英文教材确实是十分常见的操作，包括说使用英文的 PPT，但是对于我这种英文苦手来说明显就不是很友好了。学组群里面有同学立刻用 DeepL 做了一个 pdf 翻译，但是我不喜欢。老实说，一方面我并不认可 DeepL 宣传的自己是最好的翻译工具这一说法，而这种宣传在 GPT4-o 出现之后更是显得十分滑稽，GPT 比它更快，而且更好。\n但是我当时并没有精力去写一个对于 pdf 的批处理程序，互联网上对 GPT 进行的 pdf 优化莫名又已经消失的差不多了，于是一个简单粗暴的方法出现了，自己一个一个去截图（直接复制或者复制并提取数学公式，前者不准，后者太慢），然后把一切交给 GPT4-o 即可。\n不过遗憾的是，显然不是我故意的，这个文件在考试前我忘记发到群里了，导致最后我只打印了一份，其他同学并没有用上，但是所幸低年级的同学有福了。\n沉淀 最近正在盘算加入课题组的事情，但是因为我之前所处于的领域是 CV，而更准确的说，集中在少样本学习里，但是这一方向的课题组太少，我也并非完全感兴趣，于是我挑选了 embodied ai 作为将来的方向，但是就意味着我需要学习一些新内容。在和前辈学长交流了之后，获得了一些学习的方向，于是最近正在看论文和看代码，不过只能说还是任重而道远，之前只看过经典论文，对于其他内容的了解，并不算很多。\n开源 至于开源相关的事业，就不像上次一样设立一个单独的其他类了，干脆和学习放在一起，主要是因为太懒。\n最近还在维护西安交大生存指南，但是有几点感受，一是热度并不高，二是由于目前基本内容已经施工完毕，还差一个类似于快速问答的内容。概念大概就是，瞬间回答一下一些常见问题，比如说补卡/宿舍/社团，这些内容都没有必要单独开一个章节去讲解，一段话足矣。\n同时开源相关的另一件事情，是关于绿群，目前基本上对于项目的维护也已经趋于稳定了，这一点没什么好说的。\n生活 恋爱 最近一段时间，和乐小姐的感情经历不能算是顺利，可以说有一些小摩擦，这大概是因为一些焦虑导致的。我可能有的时候埋头做的事情太多了，没有停下来回头等她，也就没有顾及她的感受，这一点之后或许需要注意一下，我其实很能理解这种被抛在身后的感觉。\n希望感情顺利吧，希望可以和她一直在一起。\n水群 应该大概也是上周，正式的在新生群中进行了一些水群，讲实话，我并不是很喜欢新生群，大多数人充斥着一种摆烂的气息，这倒也不是鄙视，但是部分的人对我就暗含了一些攻击性，这让我比较不舒服。\n每一个人都有自己的选择，所以我还是尊重别人的选择的，而且长远来看，就我目前的体验来说，假如说我目前做的事情不是我所喜爱的，我难以想象走到现在我需要承受多大的痛苦，所以说每一个人的选择或许属于他自己的原因，尊重。更何况我也不知道我目前走的这条道路是否正确，说不定在大学好好的享受生活，才是那个正确答案。\n女装 不知道这种事情是否需要在博客里写，但是也算是近些日子以来我的一个思考，虽然说博客可能会被别人看到，但是我觉得这是我的多元性中的一点，或许别人也有必要了解。\n我在博客中也有发布过一些女装照片，事实上有必要澄清的是，我并非男娘或者药娘，也并非具有类似的意愿。一方面，据说服药会降低寿命，而我比较惜命；另一方面，我十分确认我的心理性别为男。所以充其量，此等打算算是异装癖的一种，但是我并无法分析其成因，或许是出于压力或者其他原因，我不知道，但是类似的行为的确可以使我心情愉悦，于是我这样做了，这似乎是一个很直接的理由。\n我不打算让这些内容影响我的正常生活，也希望读到此篇内容的人可以提及，但不要过分的用类似内容叨扰我，这会令我十分苦恼。\n我喜爱自由的开心的生活，这种微薄的请求在我的生活中应该不算过分。我希望我可以快乐，所以我有时会尝试女装，但也没有打扰到别人，我希望别人可以快乐，因此我在做一些开源的事情，这或许能让别人收到帮助。至于其他，我不清楚，结果我也不清楚，希望船到桥头自然直吧。\n交大门 交大门是一个目前为西交毕业学子（即門中的 admin）搭建的论坛，也可以说是目前西交的活跃论坛了。我在一年以前曾经在上面活跃过，最近又开始在里面发帖，一方面，我的现实生活越来越少，基本在现实中只和自己的女朋友交流；另一方面，我的线上生活则越来越多，包括说绿群，或者是門，或者是目前的新生群，线上认识的朋友们往往更加随和，也是易于交流的，于是我开始依赖这种感觉，成为了一种互联网著民。\n門的氛围和绿群不一样，绿群中的大家是一种积极向上的氛围，大家在为了保研努力，同时可能还有一些彼此之间的谦虚，和开源精神的协作，这种氛围无疑是让人感到温暖的。而門则不一样，某种程度来说，大家的观点差异很大，而且事实上，在论坛中存在着一些“崇洋媚外”的声音。当然，有必要在这里打上引号，事实上門友并非二极管，而我也并非二极管，对于不同事物，关于推崇国内还是国外，这均是有待商榷的（尽管这么说会显得我有些理中客）。大多数时候其实我会站在国内这一方，可能因为本人尚未接受过社会的毒打，诱惑者是这个社会向我展露的友好已经足够多。然而国内外不同的环境中，确实各有各的不幸，而同时，我也支持大多数門友所说的，对于外国教材与教学的推崇，但因为我的英语苦手，于是便无福消受了。但是本人依然粗浅地浏览过部分的内容，确实比我见过的国内内容要更加深刻且有用。\n同时引人深思是，论坛确实是一个能让人静下心来发表长篇内容的载体，很多的话语，在使用论坛发帖时，便会仔细斟酌并给出全面答复，这让人有一种满足感，同时也带来了更好的讨论氛围。\n然而不幸的是，一方面存在着校园集市这样的低质量“论坛”，一方面門的活跃用户并不算多，因此，大多数时候，开展一个美好的讨论氛围的打算还是落空了。\n总结 对于上周的回忆，我已经大多记不清，能够想起来的也就只有这些了，一些属于第三周的内容，我便放到了第三周里面去说，于是没有在本篇内容中过多提及，其他的便随他去吧。\n假如有读者的话，希望你们看得开心。\n","date":"2024-07-16T00:05:05+08:00","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week2/cover_hu12952257109021957023.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week2/","title":"周记 Week2"},{"content":"欢迎来到视觉组 欢迎大家来到视觉组，在这里简单的介绍一下视觉组的情况。\n众所周知，在 RoboMaster 中存在着若干的组别，其中比较关键的是机械组以及电控组，比较不关键的是视觉组。RoboMaster 作为一个机器人比赛，机器人的稳定性往往大于功能性，而在此基础之上，由于机器人的设计十分的复杂，加之以场上的频繁碰撞，即使是最坚固的机器人也面临着 Robust 的考验，因此比起让机器人开着自瞄在场上大杀四方，机器人能够活着走下赛场明显更为重要。\n很不幸，我们的队伍已经摆脱了机器人无法活着的难题了，因此压力有的时候会来到视觉组。\n给出视觉组的一个定义：\n在 RoboMaster 比赛中，在基础的车辆搭建以及控制的基础之上，为了在比赛之中起到更好的效果，计算机视觉被在车辆上使用，而视觉组（一称算法组）便是在工控机上使用计算机视觉等方法在比赛实现一些效果的组别。\n目前来看，视觉组主要包括几大经典任务，如下：\n自瞄：自瞄，也就是自动瞄准，是指视觉组通过程序获取相机图像，经过处理之后获得敌方车辆装甲板的信息（包括但不限于三维坐标、位姿、速度、击打所需的云台角度），并且将信息发送给电控，进而使得电控可以控制云台旋转而对车辆进行自动瞄准。 能量机关激活：识别某一种具有特定特征的标靶，并且预测其运动状态，在远距离进行击打，假如击打成功就可以获得一定的增幅（详情见规则手册）。此过程因为机械延迟等原因，操作手很难直接手动操作进行击打，所以需要视觉进行识别并将信息发送给电控进行击打。 哨兵导航：哨兵使用激光雷达对于比赛地图进行 SLAM 建图，进而通过导航技术在比赛场地中自动巡航，实现自动的导航/避障等功能。 视觉兑矿：在比赛中，工程机器人被要求将矿石通过机械臂送进一个角度刁钻的矿仓中，这一过程仅凭操作手的操作，一方面难度较大，另一方面则耗时较多。视觉的工程自动兑矿旨在通过视觉方案对矿仓的位姿进行估计，实现更加快捷且准确的兑矿流程。 雷达：雷达是RoboMaster比赛的特殊兵种，在赛场外的较高位置，通过识别敌对车辆在场地中的位置，为己方队员提供视野，并为敌方带来减益。视觉方案的雷达通过计算机视觉或激光雷达方案，对车辆进行识别、定位。 其中部分的知识具有较高的学习成本，在完成了统一的基础培训之后，将通过任务分流，并进行专项的培训。\n目前计划中，视觉组的基础培训主要包括以下安排：\n格式 在了解如何写文章之前，要先了解标点符号，对于编程也是如此，C++与其它语言一样，都具有其特有的格式（虽然 C++所使用的格式也被广泛用在大量语言上），在这里需要重点说明。\n本段中会使用一些代码片段，你无需了解他们的含义，因为我们只需了解代码的格式，这对于代码的含义的改变至关重要。\n在 C++中，两个比较关键的标点符号是空格以及 ;，同时在使用 C++进行编程的时候，需要注意除了文本、注释等内容，一切符号均要使用英文的半角符号。\n其中空格起到了划分的作用，将两段字符隔开，这一点上和英语中的划分是一样的，所以并无数量限制，也就是说 int a 与 int a 的含义是一样的，不会有任何的区别。同时，需要注意的是，回车在这其中可以起到和空格一样的作用。\n值得一提的是，诸如 =、+ 、-、* 等符号同样具有划分的意义。\n而作为另一部分，; 的使用则重要许多，; 的唯一用法就是使用其分割不同的语句，也就是说两句话之间假如使用 ; 隔开，则意味着这是两句话而不是一个整体。\n另外需要介绍的是注释，注释的意思是，注释中的内容在程序编译（一种将代码变成可以跑起来的程序的步骤）以及运行的时候都不会被看到，但是在日常的编程中，这些内容是可视的，因此可以起到解释代码的作用。\n注释分为行注释 // text 与段注释 /* text */，以下给出示例：\n1 2 3 4 5 6 // 这是行注释，这一行都可以作为注释，但是下一行不可以 /*这是段注释 所以只要被这两边括起来的内容都是注释 我在里面可以随意书写 这里也能写*/ 于是你能否理解，这两段代码的含义是一样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 第一段代码 int a = 0; std::cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;std::endl; // 第二段代码 int a = 0 ; std::cout\u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; 同时，还有一个需要提及的概念是代码块，代码块使用 {} 表示，平行的代码块之间相互独立。\n1 2 3 4 5 6 7 8 9 10 { // 代码块1 { // 代码块2，与代码块1相关 } } { // 代码块3，与1和2均无关 } 变量 程序的本质就是对于数据的处理，这句话是我说的，但是多少有一点道理。\n一般来说我们粗略地区分程序，会认为程序分为两部分，也就是代码以及数据，其中代码也就是那些具备一定功能的工具，而数据则被存放在名为变量的容器中。\n那么首先我们需要做的事情是选取容器。这个事情也比较好理解，比如说比较基础的字符集合，可以使用 ASCII 码表示，如下：\n二进制 十进制 十六进制 字符/缩写 解释 $00000000$ $0$ $00$ NUL (NULL) 空字符 $00000001$ $1$ $01$ SOH (Start Of Headling) 标题开始 $00000010$ $2$ $02$ STX (Start Of Text) 正文开始 $00000011$ $3$ $03$ ETX (End Of Text) 正文结束 $00000100$ $4$ $04$ EOT (End Of Transmission) 传输结束 $00000101$ $5$ $05$ ENQ (Enquiry) 请求 $00000110$ $6$ $06$ ACK (Acknowledge) 回应/响应/收到通知 $00000111$ $7$ $07$ BEL (Bell) 响铃 $00001000$ $8$ $08$ BS (Backspace) 退格 $00001001$ $9$ $09$ HT (Horizontal Tab) 水平制表符 $00001010$ $10$ $0\\mathrm A$ LF/NL (Line Feed/New Line) 换行键 $00001011$ $11$ $0 \\mathrm B$ VT (Vertical Tab) 垂直制表符 $00001100$ $12$ $0\\mathrm C$ FF/NP (Form Feed/New Page) 换页键 $00001101$ $13$ $0\\mathrm D$ CR (Carriage Return) 回车键 $00001110$ $14$ $0\\mathrm E$ SO (Shift Out) 不用切换 $00001111$ $15$ $0\\mathrm F$ SI (Shift In) 启用切换 $00010000$ $16$ $10$ DLE (Data Link Escape) 数据链路转义 $00010001$ $17$ $11$ DC 1/XON (Device Control 1/Transmission On) 设备控制 1/传输开始 $00010010$ $18$ $12$ DC 2 (Device Control 2) 设备控制 2 $00010011$ $19$ $13$ DC 3/XOFF (Device Control 3/Transmission Off) 设备控制 3/传输中断 $00010100$ $20$ $14$ DC 4 (Device Control 4) 设备控制 4 $00010101$ $21$ $15$ NAK (Negative Acknowledge) 无响应/非正常响应/拒绝接收 $00010110$ $22$ $16$ SYN (Synchronous Idle) 同步空闲 $00010111$ $23$ $17$ ETB (End of Transmission Block) 传输块结束/块传输终止 $00011000$ $24$ $18$ CAN (Cancel) 取消 $00011001$ $25$ $19$ EM (End of Medium) 已到介质末端/介质存储已满/介质中断 $00011010$ $26$ $1\\mathrm A$ SUB (Substitute) 替补/替换 $00011011$ $27$ $1\\mathrm B$ ESC (Escape) 逃离/取消 $00011100$ $28$ $1\\mathrm C$ FS (File Separator) 文件分割符 $00011101$ $29$ $1\\mathrm D$ GS (Group Separator) 组分隔符/分组符 $00011110$ $30$ $1\\mathrm E$ RS (Record Separator) 记录分离符 $00011111$ $31$ $1\\mathrm F$ US (Unit Separator) 单元分隔符 $00100000$ $32$ $20$ (Space) 空格 $00100001$ $33$ $21$ ! $00100010$ $34$ $22$ \u0026quot; $00100011$ $35$ $23$ # $00100100$ $36$ $24$ $ $00100101$ $37$ $25$ % $00100110$ $38$ $26$ \u0026amp; $00100111$ $39$ $27$ ' $00101000$ $40$ $28$ ( $00101001$ $41$ $29$ ) $00101010$ $42$ $2\\mathrm A$ * $00101011$ $43$ $2\\mathrm B$ + $00101100$ $44$ $2\\mathrm C$ , $00101101$ $45$ $2\\mathrm D$ - $00101110$ $46$ $2\\mathrm E$ . $00101111$ $47$ $2\\mathrm F$ / $00110000$ $48$ $30$ 0 $00110001$ $49$ $31$ 1 $00110010$ $50$ $32$ 2 $00110011$ $51$ 33 $3$ $00110100$ $52$ $34$ 4 $00110101$ $53$ $35$ 5 $00110110$ $54$ $36$ 6 $00110111$ $55$ $37$ 7 $00111000$ $56$ $38$ 8 $00111001$ $57$ $39$ 9 $00111010$ $58$ $3\\mathrm A$ : $00111011$ $59$ $3\\mathrm B$ ; $00111100$ $60$ $3\\mathrm C$ \u0026lt; $00111101$ $61$ $3\\mathrm D$ = $00111110$ $62$ $3\\mathrm E$ \u0026gt; $00111111$ $63$ $3\\mathrm F$ ? $01000000$ $64$ $40$ @ $01000001$ $65$ $41$ A $01000010$ $66$ $42$ B $01000011$ $67$ $43$ C $01000100$ $68$ $44$ D $01000101$ $69$ $45$ E $01000110$ $70$ $46$ F $01000111$ $71$ $47$ G $01001000$ $72$ $48$ H $01001001$ $73$ $49$ I $01001010$ $74$ $4\\mathrm A$ J $01001011$ $75$ $4\\mathrm B$ K $01001100$ $76$ $4\\mathrm C$ L $01001101$ $77$ $4\\mathrm D$ M $01001110$ $78$ $4\\mathrm E$ N $01001111$ $79$ $4\\mathrm F$ O $01010000$ $80$ $50$ P $01010001$ $81$ $51$ Q $01010010$ $82$ $52$ R $01010011$ $83$ $53$ S $01010100$ $84$ $54$ T $01010101$ $85$ $55$ U $01010110$ $86$ $56$ V $01010111$ $87$ $57$ W $01011000$ $88$ $58$ X $01011001$ $89$ $59$ Y $01011010$ $90$ $5\\mathrm A$ Z $01011011$ $91$ $5\\mathrm B$ [ $01011100$ $92$ $5\\mathrm C$ | $01011101$ $93$ $5\\mathrm D$ ] $01011110$ $94$ $5\\mathrm E$ ^ $01011111$ $95$ $5\\mathrm F$ _ $01100000$ $96$ $60$ ` $01100001$ $97$ $61$ a $01100010$ $98$ $62$ b $01100011$ $99$ $63$ c $01100100$ $100$ $64$ d $01100101$ $101$ $65$ e $01100110$ $102$ $66$ f $01100111$ $103$ $67$ g $01101000$ $104$ $68$ h $01101001$ $105$ $69$ i $01101010$ $106$ $6\\mathrm A$ j $01101011$ $107$ $6\\mathrm B$ k $01101100$ $108$ $6\\mathrm C$ l $01101101$ $109$ $6\\mathrm D$ m $01101110$ $110$ $6\\mathrm E$ n $01101111$ $111$ $6\\mathrm F$ o $01110000$ $112$ $70$ p $01110001$ $113$ $71$ q $01110010$ $114$ $72$ r $01110011$ $115$ $73$ s $01110100$ $116$ $74$ t $01110101$ $117$ $75$ u $01110110$ $118$ $76$ v $01110111$ $119$ $77$ w $01111000$ $120$ $78$ x $01111001$ $121$ $79$ y $01111010$ $122$ $7\\mathrm A$ z $01111011$ $123$ $7\\mathrm B$ { $01111100$ $124$ $7\\mathrm C$ | $01111101$ $125$ $7\\mathrm D$ } $01111110$ $126$ $7\\mathrm E$ ~ $01111111$ $127$ $7\\mathrm F$ DEL (Delete) 删除 这些 ASCII 码不需要背诵，但是不难理解这个 ASCII 码的集合只有 128 种。但是同理，我们不难发现，实际上的数字，比如说整数，本身的范围可以说是无限，在计算机领域，规定的整数范围（这里指 C++中的 int），则是从 $-2^{31}\\sim 2^{31}-1$。从计算机的角度来说，八组 $01$ 组成一个字节，则 ASCII 码集合中的字符只需要一个字节，而整数则需要四个字节，尽管 ASCII 码构成了字符与数字的一一对应关系，使得通过数字也可以表示字符，但是假如说使用整数表示一个字符，还是会导致三个字节的空间浪费。\n这种浪费无疑是需要避免的，一种在计算机语言中常用的方法就是让编程者规定容器的种类（变量类型），将这个判断交给编程者。\n同时，假如说创建了一个容器（也就是变量），那么对于其他的也是存放这种类型的数据的容器，他们之间必须要有区分，这种区分通过为变量命名来实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 整型，也就是整数 int a = 1; // 单浮点数，小数 float b = 1.0F; // F 表示单浮点，但是不写也没事 // 双浮点数，小数 double c = 1.0; // 双浮点相较单浮点占用空间多但精度高 // 字符 char d = \u0026#39;a\u0026#39;; // 字符使用\u0026#39;\u0026#39;括起来，其中不能含有多个字符 // 布尔值 bool e = True; // 布尔值表示真或假 // 字符串 std::string f = \u0026#34;hello world\u0026#34;; // 字符串与前面不同，后续会讲解 这里需要注意的一共有两点：\n第一是命名规则，对于变量来说，明明需要满足以下规则：\n标识符可以包含字母、数字和下划线。 标识符必须以字母或下划线开头，不能以数字开头。 但是更多时候，在此基础之上，我们希望每一个变量的表意明确，就像 sum 总会比 a 让人看代码的时候便于理解代码的含义。这一系列的标准我们会在后面提及。\n第二是变量之间存在一种转换，分为显式转换以及隐式转换。\n其中显式转换主要通过以下格式进行 value_name = (Type) value，这里面比较常见的操作是将字符以及其对应的 ASCII 码进行转换：\n1 2 int a = (int)\u0026#39;a\u0026#39;; // a = 61 char b = (char)61; // b = \u0026#39;a\u0026#39; 而隐式转换则是 C++自动实现的一种机制，约等于实现了一些默认的转换，这里给出一些例子：\n1 2 3 4 double a = 1; // 自动将整型转为双浮点 float b = 1.1; // 自动将双浮点转为单浮点 double c = 3 / 2; // 此时 c 等于 1.0，整数相除保留结果的整数位 double d = 3 / 2.0; // 此时 c 等于 1.5，整数与浮点数相除结果为浮点数 逻辑语句 变量与算法在程序中缺一不可，而逻辑语句就是算法的底层固件。\n我们通常使用逻辑语句进行程序的编写，实际上，基本上 C++全部的后面的特性都是建立在变量与逻辑语句的基础之上，只是对于一些功能进行了一些的拓展。\n首先在这里简要说明一下运算符，一般来说我们使用的运算符主要包含两种，分别是算数运算符以及逻辑运算符，其中算术运算符就像是大家之前在日常通常会使用的，诸如 +-*/%，分别的含义是加减乘除以及取模；而逻辑运算符则是诸如大于小于之类的操作：\n运算符 含义 \u0026gt; 大于 \u0026lt; 小于 == 等于 != 不等于 \u0026gt;= 大于等于 \u0026lt;= 小于等于 ! 非 \u0026amp;\u0026amp; 与 || 或 一般来说算数运算符的返回值是一个数字，而逻辑运算符则是一个布尔值，但是在这里其实也没有必要完全分开这些概念，因为本质上，一个非零的数字就可以隐式转换为布尔值中的 True，而零则被转换为 False。\n逻辑语句主要包含以下几种：\n条件语句 - if 条件语句 if 用于在满足给定条件时执行一段代码块。\n1 2 3 4 if (条件) { // 如果条件成立，执行这里的代码 } 示例：\n1 2 3 4 5 int num = 10; if (num \u0026gt; 5) { cout \u0026lt;\u0026lt; \u0026#34;Number is greater than 5\u0026#34; \u0026lt;\u0026lt; endl; } 条件语句 - if-else if-else 语句在条件成立时执行一个代码块，否则执行另一个代码块。\n1 2 3 4 5 6 7 8 if (条件) { // 如果条件成立，执行这里的代码 } else { // 如果条件不成立，执行这里的代码 } 示例：\n1 2 3 4 5 6 7 8 9 int num = 3; if (num \u0026gt; 5) { cout \u0026lt;\u0026lt; \u0026#34;Number is greater than 5\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;Number is not greater than 5\u0026#34; \u0026lt;\u0026lt; endl; } 多重条件语句 - if-(else if)-else if-(else if)-else 结构用于在多个条件之间做选择。\n1 2 3 4 5 6 7 8 9 10 11 12 if (条件 1) { // 如果条件 1 成立，执行这里的代码 } else if (条件 2) { // 如果条件 2 成立，执行这里的代码 } else { // 如果以上条件都不成立，执行这里的代码 } 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 int num = 7; if (num \u0026lt; 5) { cout \u0026lt;\u0026lt; \u0026#34;Number is less than 5\u0026#34; \u0026lt;\u0026lt; endl; } else if (num == 5) { cout \u0026lt;\u0026lt; \u0026#34;Number is equal to 5\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;Number is greater than 5\u0026#34; \u0026lt;\u0026lt; endl; } 循环语句 - while while 循环在满足条件时重复执行一段代码块。\n1 2 3 4 while (条件) { // 只要条件成立，重复执行这里的代码 } 示例：\n1 2 3 4 5 6 int count = 0; while (count \u0026lt; 5) { cout \u0026lt;\u0026lt; \u0026#34;Count: \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; endl; count++; } 循环语句 - for for 循环用于指定初始值、终止条件和迭代步长，然后重复执行一段代码块。\n1 2 3 4 for (初始值; 终止条件; 迭代步长) { // 在每次迭代中执行这里的代码 } 示例：\n1 2 3 4 for (int i = 0; i \u0026lt; 5; i++) { cout \u0026lt;\u0026lt; \u0026#34;i: \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } 循环语句 - do-while do-while 循环与 while 循环类似，不同之处在于它会至少执行一次代码块，然后根据条件决定是否继续执行。\n1 2 3 4 do { // 先执行一次这里的代码 } while (条件); 示例：\n1 2 3 4 5 6 int num = 0; do { cout \u0026lt;\u0026lt; \u0026#34;Num: \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; num++; } while (num \u0026lt; 5); break 与 continue 在 C++中，break 和 continue 是两种控制流程的关键字，用于在循环语句中改变程序的执行顺序。它们通常用于 for、while、do-while 等循环语句中，以便在特定条件下跳出循环或跳过当前迭代。\nbreak： break 用于立即终止当前所在的循环，并跳出该循环，继续执行循环外的代码。它的主要作用是在满足某个条件时提前退出循环，从而避免不必要的迭代。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;iostream\u0026gt; int main() { for (int i = 1; i \u0026lt;= 5; ++i) { if (i == 3) { std::cout \u0026lt;\u0026lt; \u0026#34;Breaking the loop at i = \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; break; // 当 i 等于 3 时，跳出循环 } std::cout \u0026lt;\u0026lt; \u0026#34;Current i: \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; } return 0; } 输出：\n1 2 3 Current i: 1 Current i: 2 Breaking the loop at i = 3 continue： continue 用于跳过当前循环中余下的代码，直接进入下一次迭代。它主要用于在循环中某些条件不满足时，跳过当前迭代，继续下一次迭代。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; int main() { for (int i = 1; i \u0026lt;= 5; ++i) { if (i == 3) { std::cout \u0026lt;\u0026lt; \u0026#34;Skipping iteration at i = \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; continue; // 当 i 等于 3 时，跳过当前迭代 } std::cout \u0026lt;\u0026lt; \u0026#34;Current i: \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; } return 0; } 输出：\n1 2 3 4 5 Current i: 1 Current i: 2 Skipping iteration at i = 3 Current i: 4 Current i: 5 注意：break 和 continue 只影响最内层的循环，如果嵌套了多个循环，它们只会作用于包含它们的最近的那个循环。\n地址与指针 地址与指针 在 C++中，地址是内存中的位置，每个变量都在内存中有一个唯一的地址。指针是一个变量，其存储的值是另一个变量的地址。通过指针，我们可以直接访问或修改其他变量的值。\n定义指针 1 2 3 4 5 6 7 int main() { int num = 42; int *ptr; // 定义一个整型指针 ptr = \u0026amp;num; // 将ptr指向num的地址 return 0; } 在这个例子中，ptr 是一个指向整数的指针，通过 \u0026amp;num 可以获取 num 的地址，然后将这个地址赋值给 ptr。\n使用指针 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int main() { int num = 42; int *ptr; ptr = \u0026amp;num; // 通过指针访问变量的值 cout \u0026lt;\u0026lt; \u0026#34;Value of num: \u0026#34; \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; endl; // 修改变量的值 *ptr = 100; cout \u0026lt;\u0026lt; \u0026#34;Updated value of num: \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; return 0; } 通过 *ptr 可以访问指针所指向的变量的值，同时，修改 *ptr 的值也会影响到原始变量 num。\n数组与指针 数组名可以被视为指向数组首元素的指针，这使得我们可以通过指针来遍历数组。\n1 2 3 4 5 6 7 8 9 10 11 12 13 int main() { int arr[5] = {1, 2, 3, 4, 5}; int *ptr = arr; // 数组名作为指针使用 for (int i = 0; i \u0026lt; 5; ++i) { cout \u0026lt;\u0026lt; *ptr \u0026lt;\u0026lt; \u0026#34; \u0026#34;; ptr++; // 移动指针到下一个元素 } return 0; } 但同时需要解释一个概念：语法糖。\n语法糖（Syntactic Sugar）是编程语言中的一种特性，它指的是一些语法上的便利性或简化写法，虽然并没有引入新的功能，但却能让代码更易读、更方便编写。\n其中数组的定义便是使用了语法糖，通过定义了 a[i] = *(a + i)，使得对于数组这一具有连续地址的数据结构拥有了更加便捷的访问方法。\n引用 引用是 C++中的另一个重要概念，它允许我们使用变量的别名来操作该变量。引用在声明时没有自己的存储空间，它只是给已存在的变量创建了一个别名。引用一旦与变量绑定，就无法重新绑定到其他变量。\n1 2 3 int x = 5; int \u0026amp;ref = x; // ref是x的引用 ref = 10; // 修改ref也会修改x的值 引用与指针的主要区别在于，引用必须在声明时被初始化，并且一旦初始化后不能再引用其他变量。\nnew 与 delete C++提供了 new 和 delete 运算符来动态分配和释放内存，这对于在程序运行时创建变量和数据结构非常有用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int main() { int *ptr1 = new int; // 动态分配一个整数大小的内存 *ptr1 = 10; cout \u0026lt;\u0026lt; \u0026#34;Value: \u0026#34; \u0026lt;\u0026lt; *ptr1 \u0026lt;\u0026lt; endl; delete ptr1; // 释放内存 int *ptr2 = new int[10]; // 动态分配一个整数数组的内存 delete[] ptr2; // 释放整数数组的内存 return 0; } 但务必要注意，在不再需要动态分配的内存时，使用 delete 将其释放，以防止内存泄漏。\n函数 当我们在写程序的时候，我们有的时候会发现，一些功能会被我们反复使用，但是假如说我们每一次都重写这个功能，写在 int main 中，则对于代码的可读性以及书写量都是一件不好的事情。\n一种想法是将这些重复使用的功能变成一个工具，也就是函数。\n什么是函数？ 函数是 C++编程中的基本构建块之一，用于执行特定任务或操作。它可以接受输入（参数）并返回输出（返回值）。函数有助于将代码分割为可重用和模块化的部分，从而使代码更易于理解和维护。\n函数的声明与定义 在使用函数之前，需要先声明（declare）它。函数声明告诉编译器函数的名称、参数类型和返回类型。函数定义（define）则提供了函数的实际实现。\n1 2 3 4 5 6 7 8 // 函数声明 返回类型 函数名(参数类型 参数名); // 函数定义 返回类型 函数名(参数类型 参数名) { // 函数实现 } 假如没有函数的声明，函数的定义既是定义也是声明，但是不能只有声明没有定义，会出现编译错误。\n函数的参数与返回值 参数 函数可以接受零个或多个参数，参数在函数声明和定义中指定。参数允许你向函数传递数据。\n1 2 3 4 int add(int a, int b) { return a + b; } 返回值 函数可以返回一个值，用于向调用者提供计算结果。返回值的类型在函数声明和定义中指定。\n1 2 3 4 double divide(double numerator, double denominator) { return numerator / denominator; } 对于已经定义了返回值的函数，该函数必须在 return 中给出返回值，同时，存在一种返回值 void 意为无返回值，可以不写返回值 return，其等价于编译器在函数结尾自动补充 return;。\n形参与实参 实际上，在函数中，存在形参与实参这一概念，意思是形式参数与实际参数。以下给出一个经典的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void swap(int a, int b) { int temp = a; a = b; b = temp; return; } int main() { int x = 10; int y = 20; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; swap(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } 执行以上的程序之后，发现 x 与 y 的值并没有变化，这就是因为此时 swap 传入的变量，其本质上意思是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int main() { int x = 10; int y = 20; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; { int a = x; int b = y; int temp = a; a = b; b = temp; } cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } 这也就是为什么 x 与 y 的值均没有改变，这是因为本质的传参出现了问题。\n所以根据我们之前学习的指针与引用，我们得到了两种可以修改传入变量的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 通过指针 void swap(int* a, int* b) { int temp = *a; *a = *b; *b = temp; return; } // 通过引用 void swap(int\u0026amp; a, int\u0026amp; b) { int temp = a; a = b; b = temp; return; } 具体的解释可以如上方一样将函数本身展开到 main 函数中，就易于理解了。\n调用函数 要使用函数，需要在代码中调用它。函数调用通过提供参数值来触发函数的执行，并且可以使用返回值。\n1 2 int sum = add(5, 3); double result = divide(10.0, 2.0); 函数重载 C++允许你定义具有相同名称但不同参数列表的多个函数，这称为函数重载。编译器根据提供的参数类型和数量来确定要调用的函数。\n1 2 3 4 5 6 7 8 9 int square(int x) { return x * x; } double square(double x) { return x * x; } 默认参数 函数参数可以有默认值，这使得在调用函数时可以省略这些参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int power(int base, int exponent = 2) { int result = 1; for (int i = 0; i \u0026lt; exponent; ++i) { result *= base; } return result; } int main() { int square_result = power(5); // 默认使用指数为2 int cube_result = power(2, 3); // 指定指数为3 } 函数返回多个值 尽管函数只能返回一个值，但可以通过引用或指针参数实现返回多个值的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void minMax(int arr[], int size, int\u0026amp; minValue, int\u0026amp; maxValue) { minValue = maxValue = arr[0]; for (int i = 1; i \u0026lt; size; ++i) { if (arr[i] \u0026lt; minValue) { minValue = arr[i]; } if (arr[i] \u0026gt; maxValue) { maxValue = arr[i]; } } } 局部变量与作用域 函数内部声明的变量称为局部变量，它们只在函数内部可见。局部变量在函数调用结束后会被销毁。\n1 2 3 4 5 int multiply(int x, int y) { int result = x * y; // result是局部变量 return result; } 结构体 在 C++中，我们基础使用的数据结构只有诸如 int、float、double 等表述正常内容的数据内容，但是假如说我们想要统计一系列同学的身高体重，进而计算这些同学的 BMI 指数，一种想法是设置两个数组：\n1 2 3 4 5 6 7 8 9 int main() { double num = 0; cin \u0026gt;\u0026gt; num; double* height = new double[num]; double* weight = new double[num]; for(int i = 0; i \u0026lt; num; i++) cin \u0026gt;\u0026gt; height[i] \u0026gt;\u0026gt; weight[i]; } 但是这种写法并不优美，于是一种想法是，我们能否创建一种变量类型来专门储存学生的身高体重以及 BMI 指数，也就是一种可以储存三个值的变量，实际上我们确实可以这么做，这种被我们人为创建的变量类型被称为结构体。\n在 C++中，结构体（struct）是一种用于组合不同数据类型的用户自定义数据类型。它允许你将多个不同的变量打包成一个单一的数据结构，从而方便地管理和操作这些数据。\n定义结构体 结构体通过定义一个新的数据类型来表示，其中可以包含多个不同的数据成员。定义结构体的方式如下：\n1 2 3 4 5 6 struct Person { std::string name; int age; double height; }; // 注意这里的分号 在上面的示例中，我们定义了一个名为 Person 的结构体，其中包含了 name、age 和 height 三个不同类型的成员变量。\n创建结构体对象并访问结构体成员 可以使用结构体定义的数据类型来创建结构体对象，就像创建基本数据类型的变量一样，同时，可以通过 . 来访问结构体内部的数据：\n1 2 3 4 Person person1; // 创建一个Person结构体对象 person1.name = \u0026#34;Alice\u0026#34;; person1.age = 25; person1.height = 165.5; 这种访问除了赋值当然也可以输出。\n1 2 3 std::cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; person1.name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Age: \u0026#34; \u0026lt;\u0026lt; person1.age \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Height: \u0026#34; \u0026lt;\u0026lt; person1.height \u0026lt;\u0026lt; std::endl; 结构体作为函数参数 结构体可以作为函数的参数传递，从而方便地将多个相关数据一起传递给函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 void printPerson(const Person\u0026amp; person) { std::cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; person.name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Age: \u0026#34; \u0026lt;\u0026lt; person.age \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Height: \u0026#34; \u0026lt;\u0026lt; person.height \u0026lt;\u0026lt; std::endl; } int main() { Person person2 = {\u0026#34;Bob\u0026#34;, 30, 180.0}; printPerson(person2); return 0; } 结构体初始化 可以使用初始化列表来初始化结构体对象：\n1 Person person3 = {\u0026#34;Charlie\u0026#34;, 22, 170.0}; 结构体嵌套 结构体可以嵌套在其他结构体中，从而构建更复杂的数据结构：\n1 2 3 4 5 6 7 8 9 10 11 12 struct Address { std::string street; std::string city; }; struct Contact { std::string name; Address address; std::string phone; }; 结构体指针 同样，正如正常的数据结构可以使用指针，我们人为创建的结构体也可以使用指针。\n1 Person* personPtr = \u0026amp;person; 在 C++中，通过使用结构体的指针来访问其成员时，可以使用箭头操作符（-\u0026gt;）来简化操作。这种语法糖使得通过指针访问成员的代码更加清晰和简洁。\n如果有一个指向 Person 结构体的指针，假设命名为 personPtr，要访问 name 成员，可以使用以下两种方式：\n1 2 (*personPtr).name; // 使用括号和点号 personPtr-\u0026gt;name; // 使用箭头操作符 这里，(*personPtr).name 表示先解引用 personPtr 指针，然后使用点号访问 name 成员，而 personPtr-\u0026gt;name 使用箭头操作符直接访问了 name 成员。\n因此，personPtr-\u0026gt;name 是对 (*personPtr).name 的一种更简洁的表达方式，它更易读、易懂，并且在处理指向结构体的指针时更方便。\n类 什么是类？ 在 C++中，类（class）是一种用户自定义的数据类型，它允许你将数据成员和成员函数组合在一起，形成一个单一的实体，以便更好地表示现实世界中的对象。类提供了一种创建自己的数据结构，以及定义操作这些数据的方法。\n定义类 定义类的方式如下：\n1 2 3 4 5 6 7 class ClassName { public: // 成员函数和成员变量声明 private: // 私有成员声明 }; public、private 等是访问控制关键字，用于定义成员的可访问性。\n成员函数和成员变量 类可以包含成员函数和成员变量。成员函数是在类中定义的函数，它们用于操作类的数据成员。成员变量是类的数据成员，用于存储对象的状态信息。\n1 2 3 4 5 6 7 8 9 10 class Circle { public: double radius; // 成员变量 double calculateArea() // 成员函数 { return 3.14 * radius * radius; } }; 创建对象 可以使用类定义的数据类型来创建对象，就像创建基本数据类型的变量一样：\n1 2 3 Circle myCircle; // 创建Circle类的对象 myCircle.radius = 5.0; // 访问成员变量 double area = myCircle.calculateArea(); // 调用成员函数 构造函数和析构函数 构造函数在创建对象时自动调用，用于初始化对象的数据成员。析构函数在对象被销毁时自动调用，用于释放资源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Book { public: std::string title; Book(const std::string \u0026amp;t) // 构造函数 { title = t; std::cout \u0026lt;\u0026lt; \u0026#34;Book \u0026#34; \u0026lt;\u0026lt; title \u0026lt;\u0026lt; \u0026#34; is created.\u0026#34; \u0026lt;\u0026lt; std::endl; } ~Book() { // 析构函数 std::cout \u0026lt;\u0026lt; \u0026#34;Book \u0026#34; \u0026lt;\u0026lt; title \u0026lt;\u0026lt; \u0026#34; is destroyed.\u0026#34; \u0026lt;\u0026lt; std::endl; } }; 访问控制 C++中的访问控制关键字 public、private 和 protected 用于控制类成员的可访问性。\npublic 成员可以在类的外部访问。 private 成员只能在类的内部访问。 protected 成员类似于 private，但派生类可以访问。 类的声明和定义分离 通常，类的声明（包含成员函数和成员变量的声明）会放在头文件（. h 或 .hpp），而类的定义（成员函数的实现）会放在源文件（. cpp）中。\n其中，对于成员函数来说，其实现的写法为：\n1 2 3 4 Typename Classname::Function(/*v*/) { // code } 初始化列表 虽然类的声明以及定义可以分离，但是对于一些类中的成员来说，其必须需要一个初始值，但有的初始值在 .hpp 中无法赋值（如初始值是某一函数的返回值，.hpp 并不具备执行函数的能力），于是需要在构造函数中赋值，但是又因为构造函数开始时一切成员变量均已经创建完毕，于是会导致报错。\n所以需要一种方法，在声明与定义分离的情况下，起到等效于直接在 .hpp 中赋值的效果，这种写法就是初始化列表。\n在 C++中，初始化列表形式的构造函数是一种特殊类型的构造函数，用于在创建对象时对成员变量进行初始化。它在构造函数的参数列表之后使用冒号来定义，用于显式地指定成员变量的初始值。\n初始化列表构造函数可以帮助避免使用构造函数体内的赋值操作，从而提高代码效率并减少可能的错误。\n以下是一个示例，展示了如何使用初始化列表形式的构造函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Person { public: // 初始化列表形式的构造函数 Person(const std::string \u0026amp;n, int a) : name(n), age(a) { // 构造函数体内没有赋值操作 } private: std::string name; int age; }; 在这个示例中，构造函数的初始化列表 : name(n), age(a) 指定了成员变量 name 和 age 的初始值。使用初始化列表的好处是，它可以直接将初始值赋值给成员变量，而不需要在构造函数体内执行赋值操作。\n初始化列表还可以用于初始化常量成员、引用成员和调用基类构造函数等情况。\nthis 指针 在 C++中，this 是一个特殊的指针，它指向当前对象的实例。它被用来在类的成员函数中引用调用该函数的对象本身。this 指针的存在使得在类的成员函数中能够准确地访问到调用该函数的对象的成员变量和成员函数，尤其在存在同名的局部变量和成员变量时，它能够帮助解决歧义问题。\n比如说在以上 Person 类中，创建构造函数：\n1 2 3 4 5 Person::Person(std::string name, int age) { name = name; age = age; } 此时函数出现了歧义，因为类中已经有名为 name 与 age 的变量，但是输入的参数中也有名为 name 与 age 的变量，此时严格来说，因为作用域问题，这里面的 name 均代表输入的变量，于是带来了表意不明。\n此时我们可以如下写：\n1 2 3 4 5 Person::Person(std::string name, int age) { this-\u0026gt;name = name; this-\u0026gt;age = age; } 此时构造函数中的两个左值便准确地指向了类中的成员变量，而非构造函数的输入值。\n也就是说，this 指针具备以下的特性：\n隐式使用： 当你在类的成员函数内部使用成员变量或成员函数时，编译器会自动地插入 this-\u0026gt;，即使你没有显式地写出它。例如，this-\u0026gt;someVariable 就是隐式使用 this 指针来访问成员变量 someVariable。\n显式使用： 在需要显式指明当前对象时，可以使用 this 指针。比如，你可以在成员函数内部返回当前对象本身，例如 return *this;。\n解决歧义： 当成员函数的参数名与类的成员变量同名时，使用 this 指针可以帮助解决歧义，明确地指出你想要使用成员变量而不是参数。例如：\n1 2 3 4 5 6 7 8 9 10 11 class Example { private: int value; public: void setValue(int value) { this-\u0026gt;value = value; // 使用 this 指针明确访问成员变量 } }; 静态成员函数： 在静态成员函数中，由于没有当前对象的实例，所以不能使用 this 指针。静态成员函数是与类本身相关联，而不是与具体对象相关联的。 1 2 3 4 5 6 7 8 class Example { public: static void staticFunction() { // 无法使用 this 指针 } }; 封装、继承与多态 封装/继承/多态是 C++ 面向对象编程的三大核心，在这里进行简短的介绍。\n封装 封装是 C++面向对象思想中最重要的一个思想。\n对于类来说，或者说对象，我们对其的一个共识是，其是一个独立的个体。在程序流程中，我们往往仅关心对象在获得了输入之后能否得到我们期望的输出，于是需要我们设置为 public 的函数以及值并没有那么多。\n实际上，假如暴露过多的函数接口在外部，反而会给另一位这个类的使用者（没有参与编写）以困惑，而且随意的调用往往意味着不安全。\n于是就体现到了封装的思想，也就是仅暴露需要使用的接口，并且不暴露一切的变量，对于需要访问的变量来说，则使用诸如以下的写法实现：\n1 2 3 4 std::string Person::getName() { return this-\u0026gt;name; } 这种写法可以确保对于外界来说，大多数的内容是只读的。\n进行合理封装的类会体现为其仅包含必要的接口，因此对于一个非开发者使用该类的时候，仅需要注意对象的每个方法其传参与效果即可，不需要在意类对于功能内部实现的逻辑。\n继承 成员属性 对于对象中的变量以及方法，具有其自身的属性，决定了其调用的访问等级，分别为 public、protected 以及 private，分别意味着在类内外都可以访问、只能在类内访问且不继承给子类以及只能在类内访问但是可以继承给子类。值得一提的是，不进行声明，类中的成员属性均为 private。\n父与子 继承作为一种面向对象的高级用法，其更好的描述了面向对象对于事物抽象描述并且加以定义的流程，其中继承的语法为 class Son : 继承属性 father，实现继承操作的类被称为子类或者派生类，而被继承的则被称为父类或者基类。\n其中继承属性指 public、protected 以及 private，意味着将父类中继承的比当前级别更松内容放到哪个级别中，也就是说 public 会将 public 内容放入 public，protected 内容放入 protected，protected 会将 public 和 protected 内容放入 protected，而 private 会将 public 以及 protected 内容放入 private，给出一个实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 定义一个类，人，其必然拥有一些人具有的属性，如下 class Person { public: int age; int height; int weight; string name; }; // 定义一个类，男性，其继承自 Person，也就是说其具备一切人具备的特征，同时还有一些作为男性的特征，比如说自己是一名男性 class man : public Person { public: void speak () { cout \u0026lt;\u0026lt; \u0026#34;I\u0026#39;m a man, my age is\u0026#34; \u0026lt;\u0026lt; this-\u0026gt;age; // this 指针指向当前的类，使用-\u0026gt;符号，后面填写当前类中的成员或者方法，进行调用 } }; 多态 多态是 C++乃至大多数面向对象的程序语言都拥有的一个特性，可以用来增加程序的拓展性，更加灵活的编写程序。\n简单讲解一下一个最为基本的多态的使用场景：假如说有以下一个类，Animal，其提供一种方法，叫做 speak，会输出“动物 speak”，而 Animal 是 Cat 以及 Dog 两个类的父类，而我们希望 Cat 以及 Dog 类各自实现一种 speak 的方法，分别输出“猫 speak”以及“狗 speak”。假如说有这样的一个场景，希望其中输入一个动物，然后调用其 speak 方法，一种较为复杂的方法是依次实现参数列表中为 Cat 以及 Dog 的方法，进行函数的重载，但是还有另一种解决方案，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class Animal { public: void speak () { cout \u0026lt;\u0026lt; \u0026#34;Animal Speak\u0026#34;; } }; class Cat : public Animal { public: void speak () { cout \u0026lt;\u0026lt; \u0026#34;Cat Speak\u0026#34;; } }; class Dog : public Animal { public: void speak () { cout \u0026lt;\u0026lt; \u0026#34;Dog Speak\u0026#34;; } }; void doSpeak (Animal \u0026amp;animal) { animal.speak (); } int main () { Cat c; doSpeak (c); system (\u0026#34;pause\u0026#34;); } 不难看出，这个程序的执行会将 doSpeak 函数中传入的 Cat 类当作 Animal 类并调用其 speak 方法，这样做的底气在于，因为 Cat 是 Animal 的子类，所以 Cat 中必然包含 Animal 的方法，但是这样做，因为其静态多态函数地址早绑定的原因，所以只会输出 Animal Speak，但是可以预见的是，假如说我们预想的，因为 Cat 中重新写了相关的 Speak 函数，假如说有一种方法可以调用子类的方法，而不是父类的方法，必然可以解决我们的需求，而且让整体的程序十分的简单。\nVOB VOB 是多态的常见元素，一般来说多态一定会有这三个元素，来达成其多态的效果，而因为这其中的一些硬性的关键字等，主要出现在其他语言，以及 C++更加新的标准中，在 C++98 等中或许没有，但是其依然作为一种概念，规范着多态程序的书写。\nVOB，也就是虚函数 (virtual)、重写 (override)以及父类 (base)，是多态实现的三要素。\n首先是 virtual 关键字，对于父类中的方法，添加了 virtual 关键字之后，会将其由本来的函数转化为一种函数指针，之后就可以实现，在调用的时候链接到子类之上。\n对于子类中的方法，既然要进行多态操作，也就是要进行完全的对于本来方法的覆盖。不同于函数重载中，对于参数列表的不同，重写的要求更为极端，要求一切与原函数完全一致 (对于协变来说并不是如此，但是因为不在考核范围之类，请对其感兴趣的同学自行了解)，对于一些语言，在子类的重写函数之前需要添加 override 关键字，而 c++11 的特性中也添加了 override 关键字，作为对于程序的规范，不过这都不在考虑范围内，override 这个单词本身并不必须，但是可以提醒我们对于重写这一点严格的遵守。\n最后是 base，这一点在诸如 C# 等语言可以调用父类中本来应该被重写掉的函数，但是在 C++中这一点并没有实现，所以这里的 B，只是为了提醒我们其代表着当前子类与父类的某种覆盖关系。\n虚、纯虚与抽象 在一些项目的架构中，以及一些设计中，诸如上面的 Animal 案例，虽然我们已经使用了虚函数，对其进行了改进，但是事实上，并不存在一种没有准确名字的动物，可以用到输出的“Animal Speak”，也就是说，在某种程度上，虽然有这一句话没有问题，但是假如程序真正说出了“Animal Speak”，却恰恰意味着程序出了问题，所以对于一些更为“极端”的设计，当然，也是为了保证程序正常运行没有疏漏的常规操作，存在这样一种函数，其本质上完全没有任何的实现，所以假如不是通过虚函数链接到了别的函数，而是其本身直接执行，就会报错，甚至在编译阶段，编译器就会给出报错，这种函数就叫做纯虚函数，而包含了纯虚函数的类被称为抽象类，因为其中有一些方法是尚未被实现的，所以不能被实例化，而是只是作为一种程序框架中的抽象的概念而存在。\n纯虚函数的写法是，不像一般的具有 virtual 的函数一样进行实现，而是写如 virtual void speak () = 0;，这样就是一个纯虚函数了。\n给出一个完善的使用纯虚函数写的上述 Animal 案例供参考：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Animal { public: virtual void speak () = 0; }; class Cat : public Animal { public: void speak () { cout \u0026lt;\u0026lt; \u0026#34;Cat Speak\u0026#34;; } }; class Dog : public Animal { }; void doSpeak (Animal \u0026amp;animal) { animal.speak (); } int main () { Cat c; // Dog d; 不能被执行，因为 Dog 没有实现 speak 方法，所以为抽象类，不能被实例化 doSpeak (c); system (\u0026#34;pause\u0026#34;); } 总结 这一节主要讲解了 C++ 中的一些基础，以及类、继承、多态以及虚函数等，这些内容是 C++ 中最为基础的部分，也是 C++ 中最为核心的部分，希望读者能够理解并掌握。\n","date":"2024-07-10T00:00:00Z","image":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%9F%B9%E8%AE%AD/cover_hu678983197234445466.jpg","permalink":"https://axi404.github.io/Blog/p/robomaster-%E8%A7%86%E8%A7%89%E7%BB%84%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%9F%B9%E8%AE%AD/","title":"RoboMaster 视觉组第一次培训"},{"content":"前言 之所以要写周记，大概是记录一下过去的这一个星期内我都做了什么，这是一种很好的总结，你可以较为直观的对我的成果进行回顾。\n粗略来算的话，这应该是我建立这个博客的第三个星期，也会是我坚持写周记的第一个星期，简单记录一下生活吧，这样在将来回忆的时候也能有所凭证。\n虽然说名字叫做周记，但是事实上有的内容可能并不是上个星期发生的事情，随心所欲地写，有感而发地说，大抵是这样的主旨。\n总的来说，在建立这个博客之前，我也有维护过另一个博客，当时还傻乎乎的租了一个服务器，搭建了一个 Wordpress。但是最后发现，Wordpress一是性能不行，二是其使用的富文本编辑，对于经常使用 Markdown 的我来说，并不是十分的习惯。最后本来从勤快地更新技术类博客，到写周记，然后干脆把周记的名字直接改成月记，最后连月记都懒得写。说起来大概也是当时对于新知识的追求懈怠了的原因吧，希望这次可以打起精神，避免重蹈覆辙。\n回顾大学的两年时间，可以说这一周也是经历了令我印象深刻的事件了。\n日常生活 首先简单回顾一下日常生活，最近和女朋友在一起的时光还是十分的快乐。\nLolita 女朋友最近入坑 Lolita 了，说起来我之前早期的服装里面也有一件是 Lolita，但是当时因为没有裙撑而惨淡收场，或许改天可以再尝试一下。\n巴奴火锅 最近两个人尝试了巴奴火锅，之前一直以来我们两个人吃饭都是以吃海底捞为主，现在甚至已经 20000 海底捞积分了，主要是因为海底捞可以说是最实惠的火锅之一了。我们两个人吃海底捞，大多数时候是不点肉的，一般是吃血旺以及各种杂七杂八的食物，涮一个四分之一的辣锅，每次基本上原价不超过一百五，还有学生优惠/黑海送菜，基本一百元解决。价格在这之下的火锅，几乎没有，更何况海底捞的味道也很不错，还有一流的服务。\n上次吃巴奴火锅是和轻音音乐社（相关内容可以改天写一篇回忆录）的同学，cn 为雨宫铃子，一起吃。当时貌似已经是大一上了，四处寻找海底捞无果（如今发现海底捞在赛格顶层）之后吃的这个，花了很多钱但是两个人都没吃饱，而且服务员一直在边上盯着吃饭，所以印象不是很好，甚至可以说有了心理阴影。\n这次吃巴奴的原因是因为父亲请客，总的来说可以说是因为不差钱，之前一直和女朋友笑谈巴奴火锅的传说，正好钱多，故打算带女朋友吃一顿。\n吃完之后，不得不说，收回之前的成见，巴奴万岁。简单评价一下，基本上是海底捞里面有的菜品巴奴基本也都有，虽然说他们招牌的毛肚，涮起来不是很容易，不像海底捞一样，涮到脆的容错空间大一些。但是不得不说，他们调的这个蒜香的毛肚蘸料确实一绝，很好吃。女朋友很喜欢喝巴奴的菌汤，我这种平时不喝汤的也喝了不少，确实浓郁好喝。然后就是点了牛肉很不错，绣球菌很入味口感很好，羊肉感觉稀碎，入锅就散了，到处捞肉沫，血旺则也很好吃。\n大概以上这些，感觉还是很不错的。\n学业 接下来来回忆一些令人兴奋的学业相关内容。\n考试 对于考试，我只能说我这个人并不是很擅长应试考试吧，也可能是因为科研之类的乱七八糟的内容，反正最后感觉烂完了。还好总体来说对于排名貌似影响不大，有一些科目还可以，但也就差不多得了。\nECCV 中稿 好耶！终于讲到最喜欢的一集了。总的来说，用一句简短的话来概括，就是 ECCV 中稿了。\n这是一个让我既兴奋又释然的消息，早在本学年的开始大约是十月份的时候，我便已经提前进组参与科研，当时老师给的是一个半监督医学影像的论文，让我以及两个大三学长看一看，之后进行汇报。简单地跑了一下程序，并且做了一些实验之后，在组会中idea以一种极为巧合的方式突然冒出来，好在实现起来并不困难，于是写了写程序，然后发现性能 SOTA 了。\n可以说这是一个戏剧性的结果，我一个没有任何科研经验的人，之前只是看过若干的论文，写过若干的程序，结果一瞬间便莫名完成了科研的第一步。也可以说这是来自于大一一年以来的积累，但是我即使再怎样自负，也会将运气放在这一产出的第一位。\n当时还没有到十一月份，所以说和老师定下了 deadline，想要尝试赶一下 CVPR。CVPR 可以说是每一位计算机视觉初学者的耶路撒冷，我也可以说是拼尽全力的做了实验，写了论文，提交了补充材料，除了和老师探讨了论文写作和作图方面的内容之外，几乎是一个人完成的全部内容，走下来了一次论文投稿的完整流程。\n接下来便是焦急的等待了，然后在新年之前，审稿结果出了，113，可以说是晴天霹雳。\n可以说是天道好轮回了，运气式的 idea 产出，加上没有仔细打磨的论文——审稿人光是指出内容错误便占据了好几条，终究换来了报应。所以没有任何悬念的，我选择转投，备战 ECCV。\n我为我在 CVPR 的失败做了很全面的总结，一方面是打磨不充分，无论是故事线的塑造，还是一些诸如表头等内容的细节，还是 pipeline 的作图，可以说都十分的草率。甚至说由于我的初稿是我自己写的，后面再和老师的协商之下更换了方法的名字，而在一些表头中，原方法的名字依然残留在上面，被审稿人指出，并表示了困惑。另一方面则是对于科研领域的一些规则的不了解，最经典的例子便是我在对比实验中对其他人的每一个方法都进行了 K 折验证。我可以问心无愧地说，进行上述的操作，完全没有打压其他人方法的意思，对于性能上的不足，我向来是采用对自己方法的调参解决的，然而由于某一篇论文使用了 K 折验证，而其他论文没有，于是我便选择了最公平最稳定的测试方法，也就是全在我的设备上跑一次 K 折。结果出乎意料，复现的性能与原论文相差甚至十个点，但我还是头铁地将结果汇报了上去，不出所料，遭到了审稿人的强烈质疑。\n于是我按照领域中的常见规范打磨论文，重新跑实验，并且对方法进行了略微的调整，最后形成了新的稿件，在 CMT 上面进行了投稿。\n投稿之后，这件事情便被我抛之脑后了，当时事后和老师讨论，老师跟我说，即使这篇论文无缘 ECCV，将来头一个 PR 也是比较稳的，这给我带来了极大的安慰，毕竟升学的压力始终伴随着我。\n到了 ECCV 出结果的那一天，我还是熬夜了，但是老实说我并不对 ECCV 的结果抱有任何的期待，实在是 CVPR 给我带来的打击太大了，我当时心里想的是，只要有一个积极的评价，我便已经知足了，也就有了后续继续做科研的勇气。\n然后就是开奖，那一瞬间，我几乎从座位上跳了起来，我反复地查看这个评分，以及评分的标准，最后才相信我看到的都是现实，443，我做梦也想不到自己可以获得这样的分数。\n我急忙和老师汇报了这一喜讯，然后将审稿意见看了又看，很快便拟出一份 rebuttal 的临时稿件，当然，肯定是超页数了。\n第二天我便前去找老师进行讨论，并且定下了 rebuttal 的基调。三个审稿人都比较温和友善，提出的问题也不算特别尖锐，可以说只有几个疑惑需要解答，并且认为论文的写作中有一些笔误和不清晰。于是任务便定下来了，重新作图，完善 motivation 以及 pipeline 的表达，老师请来了两位师兄师姐，与我共同完成这些内容。\n不得不说，本人的作图审美可以说是一塌糊涂，两位师兄师姐则是颇有水平，一方面在他们的指导下，一方面他们亲自上阵帮忙，仅仅是一天时间，图片变已经从原来的莫名其妙变为了颇具顶会风格的插图。然后便是我较为擅长的内容，打磨文字，删减字数，顺便和老师讨论表达有何不妥，最后提交了 rebuttal，一切告一段落，顺便进入了期末周的复习阶段。\n可以说这个初审的分数给我带来了极大的希望，甚至说这种希望近乎已经成为了一种折磨，把我从原来对于 ECCV 已经不抱有任何幻想的状态，拉进了每天的煎熬中。\n那段时间几乎每天我都会看知乎相关的话题回复，看看又有多少人超过了我的分数，还有多少人逊色于我。我的分数确实处于一个领先地位，这是一个安慰，但是随后更大的焦虑便袭来了。万一我所在的领域分数都是如此的高；万一审稿人看见了彼此的评价，并降低了分数；或者干脆就是 meta reviewer 看我不顺眼，于是直接将我 reject。毕竟这些内容在网上都能找到前科，而我对于我的运气下来不是十分自信，当时甚至立下了，假如中稿便拍摄二十张精心设计的女装照的对赌。\n在煎熬中，时间就这样流逝，然后便到了公布结果的那一天，我本来是做好了熬夜的打算，然而在前一天的晚上，结果便提前公布了。我的双手几乎可以说是颤抖着，将链接复制下来然后输入浏览器，紧接着 ctrl f，查询我的编号。搜索框中出现 not found 的时候我的心脏几乎停跳了一下，然后检查我的编号，发现是记错了一位，最后终于找到，连忙保存 html 留作副本（万一他们反悔怎么办），然后截图，紧接着我瘫坐在椅子上的时候，一种欣喜才迟迟地涌上我的心头。\n我一时间似乎有些想哭，但是哽咽就卡在嗓子中，哭不出来，一路上可以说经历了太多的坎坷，绝对不是这一篇博客，几段文字，简简单单便可以概括的。好在一切都有了结果，好在努力得到了回报。接下来我开始向各路关心我的人报喜，然后发了一条 QQ 的说说，如下：\nECCV中稿了，也算是给近一年以来的科研画了一个迟来的逗号。\n一开始这篇工作是在CVPR投稿期间做出来的，idea的形成以及实验都还算顺利，但是投稿的过程却颇为坎坷，无论是论文的写作还是最后的表达都有所欠缺，最后转投ECCV。\n也许是运气的眷顾，或者是努力终究会有回报，好在最后的结果还算顺利，积累了经验，提升了能力，收获了许多。\n一时间有些不知道该说些什么，一路坎坷走到现在，未来还有多远呢？好在眼下还有不错的激励，能让我强打精神再出发。\n刚接触科研的时候晚上常常想多，想着万一自己中了论文，如何如何，当时就想着发这样一条说说，文案也想好了，就叫“春风得意马蹄疾”。\n感谢一路走来的一切，感谢老师和师兄师姐的指导，女朋友的陪伴，群u们的支持与鼓励，以及种种。现在若干时间过去了，现在想想，用一句诗来结尾的话，或许我会选择。\n“轻舟已过万重山。”\n是啊，轻舟已过万重山，我等这一刻究竟已经等了多久？为此熬了多少夜？现在终于可以松了一口气。仿佛一瞬间一切的烦恼，一切的忧愁，一切的烦心事，在那一刻看来都好似过眼云烟，结束吧。\n其他 绿裙相关 本人在计算机保研交流群，也就是俗称的绿群中，一直以来都是一名活跃群友，并且自认为还是干过几件大事的。\n首先是在今年四月份的时候，当时群众便已经聚集了 21 级的大量同学，大家都对自己的命运琢磨不透，并因此焦虑。绿群中一个常见的话题，便是俗称的 bg 定位，也就是某人对于自己的背景情况（background，即 bg）进行阐述，并且邀请群中对于保研更加了解的前辈或者同学，对于自己可能的去向给出建议。\n我是一个无比喜爱信息差这个概念的人，并且热衷于将分散的信息进行整合，于是一个有趣的想法便自然而然的形成了，建立一个匿名的 bg 统计表格，每一个人都可以将自己的信息进行上传，而且这些匿名信息事实上并不会导致过多的信息泄露，因为一方面这些内容的填写是可选的，另一方面，每个人也是自愿的提供这些内容，更何况这些内容本身也会在群中被发表出来。这些信息包括了学校/排名/科研与竞赛的经历等等，并且开设了提问板块以及建议栏，可以让群友们自行对于已经公布信息的题目给出建议。\n在这个之后，我又增加了序号功能，并且表格可以根据回复的人数进行排序，让靠后的人也有机会被看到，最后更是直接转战谷歌，这是因为保研中介的引入带来了大量的举报，文档经常就被封禁，于是我使用了谷歌的统计表以及表格的联动，并且选择将表格内容通过外挂网站的方式进行公布，避免了这一现象，并且便捷了提交流程。\n在当时这一创造可以说是现象级的，自动化保研交流群，甚至也都在讨论这一举动，并且光速推出了他们自己对于这一表格的模仿版，但是显然无论是热度还是内容量，又或者是维护的先进性，与我推出的表格都有着明显的差距。\n不过遗憾的是，这一表格的投稿人很多，但是给出建议的群友，向来只有不几个，我也因此甚至自己请教了大量的前辈们，并且尝试给出自己的意见。也正是因为这个原因，加之以时间的流逝，和真正的保研的临近，这一表格后来也就慢慢被荒废了。\n接下来便是最近设计的又一创举，也是受到了广泛的传播，并且拿下了一百多个 star，也就是本人实现并维护的 cs-baoyan-ddl。\n起因是因为几位活跃群友在群中的讨论，想要构建一个项目，酷似 ccfddl，可以实现对于夏令营截止日期的统计，而我看到了这一想法之后，由于之前对于网页制作稍有经验，并且更关键的是精通面向 GPT 的编程，因此只是短短的两个小时时间，这个网页便被搭建起来了，同时被我挂到了 Github Pages 上。\n大家的反响依然十分激烈，给出了许多的赞美，但是我深知这一网站并非完美的，无论是对于数据的管理，我需要人工大量地从已经形成的 CSSummerCamp 的 Markdown 文档中进行人为的提取，这是大量的工作量，同时在后续进行仓库的维护，也并不是很便捷，最后使用原生的 web 三大件大建出来的网页维护起来也是十分麻烦，并且有很多功能难以实现，于是我便踏上了漫长的重构旅程。\n首先我又一次学习了 Github Actions，通过建立了 BoardCaster 仓库 模拟了一个后端数据库的存在，并且可以使用 Action 让不同的仓库都订阅这一仓库，从中获取需要的数据。同时，我设计了一套可以根据 Issue 直接更新数据库的流程，这使得数据库的更新变得更加方便。\n然后，我紧接着学习了 Vue3，并且和 GPT 一起完成了对于整个网站的重构，并且添加了更多的功能。再一次开始宣传的时候，可以说这一网站的功能已经完美地达到了 2.0 的版本，并且支持了更多的数据库的引入。\n汐学组 与此同时，在这里同样被我维护的开源项目还有另一个项目，便是汐学组。关于汐学组的创立，这是一段曲折的经历。\n本人可以说是一个十分热衷于开源的人，我从大一上开始便已经开始制作各种各样的教程，其中比较知名的是一个关于 C++程序设计的复习指南，根据学弟透露的情报，在最新的期末复习课的资料中，我当初所写的资料已经赫然位列其中。能够成为所谓官方的复习资料，本人还是十分荣幸的。\n能够产出复习资料，除了出于对于开元社区做贡献的热爱之外，也是因为我在 RoboMaster 时期便已经收到了良好的编程训练，这其中很重要的一项就是 Markdown 文档的编写，在此之后我又自学了 $\\LaTeX$，使得我的相关功底更上一层楼。顺带一提的是，关于 RoboMaster，我也计划写一期回忆录，暂且列在待办事项中，毕竟博客不只是用来分享技术的，也是我随便写写东西的场所，而其中很重要的一点便是对于过去的回忆记载。\n在此之后我也进行了诸多的创作，产出了大量的复习资料，或者说与其说是复习资料，不如说是某种复习大纲，或者是 cheatsheet 格式的内容，可以帮助使用者在考前快速的回顾知识点，但是或许并不适用于那些对于知识压根不了解的同学。同时我还热衷于进行PPT转述，将PPT中的全部重点以及内容公式使用 Markdown 进行转述，一方面这种资料的整理可以帮助我更快的巩固知识点，同时转述后的PPT也很便于立刻形成成体系的复习大纲。\n老实说我一直对开源社区是抱有希望的，我一直认为我将 PPT 转述的内容发布之后，便会有其他同学，紧跟我的脚步，将内容进行二次压缩，但是很遗憾的是，这种事情往往不会发生。\n整个大一的学年中，从我之外分享复习资料的同学屈指可数，而且部分的资料，当然也可能是我记忆错误，事实上来自于大二，通过类似于手写扫描或者电子笔记的方式进行分享。一方面，这种载体的资料分享并不便于他人在此基础上进行二次加工，而与此同时，在使用了 Markdown 以及 LaTeX 等工具之后，我对于文档的格式化表达形成了一种近乎洁癖的偏执，而很明显的一点是，我所在专业同年级的绝大多数同学，可以说完全没有接受过相关的训练。甚至我敢打保票，直到大二结束的现在，仍然有超过50%的同学不知道如何书写 Markdown。\n于是显然，开源之路是孤独的。\n到了大二的时候，我创作的资料已经足够使用一个知识库进行维护了，但是当时我对于网站的创立等内容尚且不太熟悉，于是使用了我常用的笔记软件，Obsidian，将我的资料进行了开源，但是貌似直到目前为止，相关仓库在我的宣传后，也没有一个 PR，而显然，大多数同学更不会使用 Git。\n另一件怪事是，在大二的时候，我们忽然变成立了一个所谓的AI学组。老实说，在西交中确实存在着无数的学组，诸如钱学组/仲英学组/彭康学组等，虽然他们的一些资料为了确保没有知识点的遗漏，而导致过于的冗长，但是总的来说，这些资料具有极高的价值，同时他们还整理了往届的考试原题，这几乎是我期末复习周的救命稻草。但是令我困惑的是，AI学组究竟因何诞生。正如我之前所提到的，除了我之外，我并未在年级中听说过任何一位其他的资料分享的积极活跃者，难道说终于有同学开窍了？打算加入开源的事业？\n刚开始的时候，我对于学组的建立是十分激动的，无论是对于资料的分享，共同维护一个硕大的 Github 资料库，还是说在学习之余，进行一些科研相关的讨论会，交流一下彼此的见解，这对于年级的水平提升和共同进步的促进都是十分明显的。然而在我加入其中，兴致勃勃地分享了自己创建的仓库，并且积极更新资料同时，其他同学的资料则难以见到其踪影，直到后来临近期末考试，在考试开始的前几天，终于出现了电子笔记形式的资料，至此，我对于学组已经多半失望了，或许还是自己来比较合理，正好我有的是精力。建立优质的资料，为大家树立标准，或许可以激励学组和其他的开源行为变得更好，于是在大二下的时候，我自己的开源网站以及组织，汐学组成立了。\n大多数的学组均是如此，挂靠在学校的诸如书院的团委名下，并且做出的贡献都会根据贡献量给予工时等奖励。然而不同于这些内容，汐学组是完全为爱发电的形式，没有工时奖励，没有赞助窗口（或许将来我会建立一个，用于购买咖啡或者维护服务器），只有我分享的资料以及网站，并且目前我的 Github 账号正以每天十条以上的 commit 的频率活跃着。\n现如今，汐学组名下主要维护着两个网站，分别是 汐学组的主页，以及 西安交大生存指南。其中主页的内容包括了学组的介绍，以及一些复习资料的分享，通过 Github 的 raw，可以提供直接使用链接进行点击下载的功能。与此同时，西安交大生存指南则是我受到了上海交大生存指南的启发，从而自己建立的一个生存指南，涵盖了包括在大学中看待事物的方法，入学时候的须知事项，一些基础的学习技巧，一些恰当的学习路线，以及其他的可能在正常途径中无法获得的信息。\n在将来的一个打算是，或许可以推出一种周刊或者月刊形式的学习资源分享，当然这个分享并非课内的，而分享的内容也并非我自己制作的，大概的名字叫做，学点没用的。分享一些可能在正常的专业学习路径中无法遇到的知识，并且学习它们，拓宽自己的知识面，并且维持自己对于新知识的热情。\n总的来说，作为一个开源社区的贡献者，我自认为在本年级中，暂时还没有同学可以超过我，包括无论从呈现的形式上，还是从工作量上来说，均是如此。\n目前暂时来看，关于开源工作的推进，一方面是寻找一些其他专业的成绩优异的同学，为西安交大生存指南提供优质稿件；另一方面则是仍然需要培养本专业 24 级同学的参与开源的能力与热情，同时积极把握 23 级同学。但是至于 22 级，好吧，暂时来看我是随缘了。\n总结 说来说去，作为我的第一篇周记来说，写了太多的东西，已经有点类似于我的前两年的回忆录的感觉了，虽然前两年经历的事情远不止如此，之后的每一次周记，我预计会包含大概四到五条，但是内容量肯定不如本次一样丰富，毕竟这次还融合了许多之前发生的事情，而之后的话，想要多写内容，可能需要托我的联想能力多多发挥功效了。\n大概就是这样子，接下来应该继续投身于科研，以及更多的开源事业中去了。\n简单立下一些 flag，下周首先要将西安交大生存指南新增大约四到五篇文章，然后开始学习计算机图形学，同时需要提醒的是，要将 ECCV 的稿件顺利投稿，这是很重要的。\n","date":"2024-07-08T00:00:00Z","image":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week1/cover_hu5849879713028931591.jpg","permalink":"https://axi404.github.io/Blog/p/%E5%91%A8%E8%AE%B0-week1/","title":"周记 Week1"},{"content":"前言 根据惯例写一下前言，关于这篇博客为什么要写，以及其中的内容。\n笔者曾经不止一次在各种场合推荐过记笔记的好处，以及笔者所使用的 Obsidian 这一笔记软件。关于记笔记，每个人可能存在不同的理由，在这里笔者给出的理由是，笔记的记录是一种对于学习的正反馈，是对于自身学习内容的一种定量描述，更多的论述见 SurviveXJTU 的对应章节。\n目前市面上存在着若干的笔记软件，国内的诸如语雀/flowus 等，而国外的则诸如 Notion/Obsidian 等。在这里有必要指出，尽管国内的笔记软件的功能均在提升，但是其功能性均不如 Notion，而 Notion 则是基于网络的内容，你记载的笔记均不是本地内容，同时伴随着较高的学习成本。\n相较起来，Obsidian 则是一款本地笔记软件，你的全部内容可以均保存在本地，也可以通过 Github 等方式进行备份与同步。Obsidian 使用 Markdown 语言进行笔记的撰写，这使得其具有较低的上手难度，而同时其双向链接功能以及诸多插件则可以覆盖基本全部的日常笔记记录的需求，最后其仓库的概念则使得笔记之间被优雅地组织在一起。\n安装与下载 Obsidian 的安装与下载十分简单，你可以在 Obsidian 的官网 进行下载，之后按照提示进行安装即可。\n仓库 一如 VSCode 中的工作区，在 Obsidian 中，一系列的笔记内容（一个知识库）被组织在一个名为仓库的单位中。仓库实际上就是一个文件夹，其根目录下包括一个 .obsidian 文件夹，其中含有一些 Obsidian 自身的配置以及日志文件，而其他的文件夹以及内容则全部都是笔记的内容。\n仓库的特点在于，在仓库中的全部文件，可以由 Obsidian 自动进行索引，这使得你可以通过文件名进行搜索，而无需担心文件路径的问题，而当文件的名称改变之后，这些链接也会自动更新。\n双向链接 Obsidian 不同于专业的 Markdown 编辑器，如 Typora 等软件的最大特点便是其使用的双向链接功能。\n理解双向链接是一个很简单的过程，其可以在不同的 Markdown 文件之间建立联系。这一过程像是网页中的链接功能，在每一个文档的右上角打开 更多选项-\u0026gt;打开链接视图，可以找到局部的关系图，而在界面左侧的 查看关系图谱 中则可以找到全局的关系图谱。\n双向链接的双向主要体现在，不仅可以统计链接的出链，也可以统计其反向链接数量，这使得可以获得这篇文档被引用的来源。\n通过双向链接可以很方便的直接获得思维视图，而这对于整理整体的知识谱系，使得知识融会贯通有着很重要的意义。\n在笔记的整理过程中，这种双向链接的功能可以使得回顾之前的知识或者掌握拓展的知识更加轻松，这使得比如：在一篇复习资料中，对于某一拓展知识，我们可以将其通过双向链接进行链接，而不是直接插入在复习资料之中，使得资料简洁的同时兼顾拓展性；同时假如在一篇公式与符号众多的资料中，某一处提及了较靠前的内容，通过双向链接也可以准确的回到那一处内容进行回顾，而不是如同 PDF 文档亦或者是纸质笔记一样需要花费大量的时间对知识点进行寻找。\n通过点击链接进行跳转之后，对于使用鼠标且具备侧键的用户来说，侧键可以直接进行“返回”操作，而对于其他的用户来说，可以点击文档左上角的的左向箭头，值得一提的是，这种返回操作完全不是 ctrl + z 进行的撤销操作，请勿混淆。假如说因为前进与返回不方便而困扰，也可以在左下角的齿轮形状图标的设置中点击快捷键-返回与快捷键-前进，进行修改。\n使用双向链接这个过程十分简单，使用 [[文件名|显示名称]] 或者 [[文件名]] 就可以完成双向链接，其中后者是简化语法，链接的目标与显示的文本会相同（无后缀名）。值得一提的是，这种方式的链接很像 Markdown 基本的语法，即 Markdown 中的超链接语法，因此不难记忆。而二者的不同之处在于，超链接需要给出链接的完整的相对路径甚至绝对路径，而 Obsidian 则无需考虑完整的文件路径，仅需要输入文件名，而 Obsidian 的工作区则会维护剩余的部分。\nObsidian 的双向链接同样支持索引到标题甚至段落，其使用的语法分别是 [[文件名#标题名]] 以及 [[文件名^段落标记]]，其中段落标记可以在输入 ^ 之后选择了期望的段落后自主生成，其一般为形如 ^f6c831 的编码，或者可以使用 ^标记 来创建标记。标记的长度不限，但是只能由数字与字母组成，在编辑模式下可视，而在阅读模式下不可视。\n插件安装 Obsidian 的插件安装分为使用插件市场进行安装或者手动安装，一般来说绝大多数的插件，读者仅需要使用插件市场便可以完成安装的事项。\n在选项中找到第三方插件，并且关闭安全模式之后，即可访问插件市场。值得一提的是，顺利的插件市场访问需要在可以顺利访问 Github 的网络环境下。\n在插件市场中找到自己心仪的插件，并且点击安装即可，十分的简单。\n在这里笔者推荐一款笔者最常用的插件，即 Easy Typing，这个插件可以帮助你进行快速的格式化文档，使得你的文档规范统一。Easy Typing 可以十分便捷的创建属于自己知识库的文本规范，同时可以对一些符号的输出进行自动的补全，比如：\n输入两个 【【 自动变成 [[]]。 输入 （ 自动变成 （）。 输入三个反引号自动补全为代码块。 总结 笔者分享了一些关于 Obsidian 的基础使用，包括仓库、双向链接以及插件安装等内容，希望对读者有所帮助。\n","date":"2024-07-06T00:00:00Z","image":"https://axi404.github.io/Blog/p/obsidian-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/cover_hu3787812585657951940.jpg","permalink":"https://axi404.github.io/Blog/p/obsidian-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/","title":"Obsidian 快速上手指南"},{"content":"前言 本篇内容写作的初衷，是由于，笔者在生活中的见闻。不少的 Git 的初学者，毫无疑问，是了解关于 Git 的大多数的基本操作的，但是对于其背后的流程却知之甚少。因此，在实际的操作中的时候，假如说进行正常的 git clone 之后的add, commit, push 操作，那么多半问题不大，但是假如说遇到了更加复杂的需求，则难免束手无策。\n这便是笔者写作本内容的初衷，即尝试通过更加复杂的 Git 任务，尝试帮助读者了解一个更加完整的 Git 工作流，并丝滑地处理日常的一些基础内容之外的常见需求。\n初始化 Github SSH 初始化 Github SSH 是每一个 Git 用户与 Github 进行交互的第一步，但是在这其中的不少流程往往引人迷惑，使得在后续的日常使用中，常常困惑于自己的配置是否合理。\n由于 Github 的更新，Github 的上传不再支持使用账号密码的身份验证，而是转为使用个人访问令牌或者 SSH 的方式，而其中毫无疑问，使用 SSH 是最为优雅的解决方案。SSH 生效的原理是，在本地生成的公钥私钥对，其中的公钥被上传至 Github，而在 SSH 之后，本地与 Github 建立安全连接，从而进行相关的操作。\n在这里首先给出初始化 Github SSH 的详细步骤，之后再进行解释，以解决部分初学者的误区。\n详细步骤 首先，使用 SSH 创建密钥对：\n1 2 ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; # 或者 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; 其中 ed25519 以及 rsa 均是密钥生成的算法，其中 ed25519 是更新的算法，假如说本地不支持，则可以使用 rsa，本身的安全性均很高。输入之后默认回车即可，密钥会被生成至 ~/.ssh/ 中。使用 cat 指令可以进行查看：\n1 2 cat ~/.ssh/id_ed25519.pub # 或者 cat ~/.ssh/id_rsa.pub 将生成的公钥复制至 Github 中，在 Github 的 Settings 中的 SSH and GPG keys 中，点击 Add SSH key 进行添加即可。\n理解误区 在这一过程中，我们注意到，包括说互联网中绝大多数的常见教程，均会使用 -C \u0026quot;your_email@example.com\u0026quot; 这一行指令，而与此同时，git config 以及 Github 均存在邮箱地址这一配置内容，但是实际上这三者之间没有一点的关系。生成密钥使用的邮箱为注释性质的，本质上可以不添加；git config 的邮箱为记录性质，每一条 commit 都需要记录用户以及邮箱；而 GitHub 的邮箱则是账号性质，是掌管 Github 权限的内容。\n因此也就不难解释一些奇妙的问题了，诸如自己的本地的 push 在 Github 中显示的来源与自己的 Github 账号不一致。这完全是因为在 git config 中配置的邮箱与 Github 中的邮箱不一致导致的，而信息与 git config 中的内容保持一致，假如说想要纠正，重新设置 git config 即可。\n关联新建仓库 关联新建的仓库同样是在 Git 操作中很常见的一种，也就是应该如何让本地的 Git 与 Github 中的仓库之间建立远程链接，这其中最方便的一种便是使用 git clone 指令。\n1 git clone git@github.com:username/repository.git 假如说已经在本地的仓库中创建了一些内容，则可以在 git clone 之后将已经创建的内容统一复制到克隆出来的文件夹中即可。\n在这里需要指出的一种常见错误是，在 Github 中创建仓库时勾选了创建 README.md 或者 LICENSE 文件，而后使用大多数教程中推荐的 git init, git add ., git commit -m \u0026quot;initial\u0026quot;, git remote add origin git@github.com:username/repository.git, git push -u origin main。这一流程常常导致报错，这是因为在 Github 中存在这些默认创建的文件，而本地的仓库中并没有这些文件，这会导致在 git push 的时候出现错误，而如果已经进行过 commit，也会因为 commit 的历史不一致而在 pull 以同步这些文件的时候报错。\n因此，正确的流程是，在 Github 中创建仓库时，不勾选这些默认创建的文件，而在本地创建这些文件，再进行 git push 即可。或者使用上述的 git clone 流程。\n假如说非要在这种情况下使用 git init 的流程，则可以使用以下的脚本：\n1 2 3 4 5 6 7 8 git init git add . git commit -m \u0026#34;initial\u0026#34; git branch # 查看当前分支名称 git branch -m main # 当前分支重命名为 main git remote add origin git@github.com:username/repository.git git pull origin main --allow-unrelated-histories git push -u origin main 其中的精髓在于使用 --allow-unrelated-histories，这使得在 pull 的时候，允许两个不同的仓库进行合并，从而避免报错。\n废弃当前 Github 仓库分支并更新 main 分支 对于部分的仓库的重构需求，例如将本仓库不再使用 Hugo，而是使用 VitePress 进行搭建，那么需要将本仓库的 main 分支进行完全的重建，同时出于保险起见，还需要将之前的分支进行备份，也就是将其置入一个废弃分支。\n首先先备份当前的分支：\n1 2 3 git checkout main git checkout -b deprecated-main git push origin deprecated-main 之后重建当前的 main 分支：\n1 2 3 4 5 6 git branch -D main git checkout --orphan main git rm -rf . # 将新的文件添加到当前目录 git add . git commit -m \u0026#34;Rebuild main branch\u0026#34; 最后在 push 的时候使用 -f，也就是 force，进行强制推送：\n1 git push -f origin main 假如说本仓库存在一个 gh-pages 分支，有可能会需要删除这个分支，使用以下指令：\n1 git push origin --delete gh-pages 总结 以上内容总结了部分的笔者在日常使用中经常会用到的 Git 相关的使用技巧，这些内容是维护一个仓库的过程中十分常见的。同时，同样需要注意的有诸如在修改仓库内容之前先进行 git pull 此类日常习惯，这样才可以保证内容的一致性。\n","date":"2024-07-03T00:00:00Z","image":"https://axi404.github.io/Blog/p/git-%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/cover_hu15980319798684127064.jpg","permalink":"https://axi404.github.io/Blog/p/git-%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/","title":"Git 的常见操作"},{"content":"前言 惯例的写一下前言，关于为什么要写这篇内容，以及这篇内容的主旨是什么。\n笔者最近开设了几个 VitePress 项目的网站，并且作为开源项目，开放给社区以及每一个人。毫无疑问，诸如 VitePress 类型的静态网页生成器，是一种极大的对于创作的便利，使得创作者无需关注于网站的构建，只需要专注于内容的创作。但是对于完全没有互联网基础的同学来说，这种内容甚至也已经超纲了，我们迫切需要一种类似于 Word 或者说 Markdown 编辑器这样子的开箱即得的记录方式，使得最不了解技术的创作者也可以尽情的创作。\n事实上这种内容是存在的，使用前后端的博客可以很轻易的达到这种效果，但是明显，目前因为种种原因而选择使用 VitePress 之后，一个为不了解技术的同学设计的 VitePress 贡献指南是有必要的，这可以帮助读者了解 VitePress 的基本结构，并且可以快速上手，对于 VitePress 项目进行贡献。\n什么是 VitePress VitePress 是一个基于 Vite 的静态网页生成器，它使用 Vue 作为其核心，并使用 Markdown 作为其内容格式。VitePress 的主要目标是提供一个简单而高效的方式来创建和维护静态网站，同时提供丰富的插件和主题来满足不同用户的需求。\n换句话来说，使用 VitePress，可以很轻易地通过 Markdown 格式的内容生成精美的静态网页，因此是很好的百科/博客类内容的载体。\n项目结构 了解 VitePress 的项目结构是为 VitePress 做贡献的基本事项，一般来说，VitePress 的结构为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ├───.github ├───docs │ ├───.vitepress │ │ ├───cache │ │ └───theme │ ├───images │ ├───public │ ├───folders │ └───index.md ├───node_modules ├───.gitignore ├───package.json ├───pnpm-lock.yaml └───tsconfig.json 对于贡献者来说，仅需要关注 docs 文件夹即可，docs 文件夹下包含了 VitePress 的配置文件，以及所有的 Markdown 文件。其中作为初级的贡献者，需要了解的是 docs 中的若干文件夹，并且对于新建的文档按照以下的步骤，在这里以项目 SurviveXJTU 为例。\n贡献流程 关于从注册 Github 以及初始化 Git 开始的贡献流程，在 SurviveXJTU的贡献指南 中有更具富文本与插图版本的说明，在这里给出一个配置健全的设备上的简易版本。\n撰写文档 首先，搞清楚自己想要构建哪一部分的文档，例如想要贡献一则 人生篇 中的内容，那么前往 docs 下的 人生篇 文件夹中，新建一个 Markdown 文档，并且撰写其中的内容。在这里需要注意的是，Markdown 文档对于完全的计算机领域初学者来说，可能并不能很好的驾驭，了解一些基础语法有助于帮助读者更好的撰写文档，在这里可以参考较为经典的 Markdown 官方教程。\n添加至 Sidebar SurviveXJTU 的侧边栏使用人为的创建形式，这是为了更大限度的排版布局自由度，有的时候不同章节之间的内容，在写作的过程中存在顺序之分，而使用如 vitepress-sidebar 等插件自动生成 Sidebar 虽然快捷，但是很可能导致内容按照如字典序等方式进行排序，从而无法更好的符合写作者的意愿。\n前往 docs/.vitepress/config.mts 中，可以在找到如下文所示内容，以下以其中的人生篇为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 export default defineConfig({ ... themeConfig:{ sidebar: [ { text: \u0026#39;人生篇\u0026#39;, link: \u0026#39;/人生篇/\u0026#39;, collapsed: true, items: [ ... { text: \u0026#39;关于西交\u0026#39;, link: \u0026#39;/人生篇/关于西交\u0026#39; }, { text: \u0026#39;开源精神\u0026#39;, link: \u0026#39;/人生篇/开源精神\u0026#39; }, ] } ] } }) 在其中找到你想要插入的位置，VitePress 会根据 items 中的顺序来排列 Sidebar，例如读者创建了文档 人生思考，并认为在排版布局中应位于 关于西交 与 开源精神 之间，则加入一列即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 export default defineConfig({ ... themeConfig:{ sidebar: [ { text: \u0026#39;人生篇\u0026#39;, link: \u0026#39;/人生篇/\u0026#39;, collapsed: true, items: [ ... { text: \u0026#39;关于西交\u0026#39;, link: \u0026#39;/人生篇/关于西交\u0026#39; }, { text: \u0026#39;人生思考\u0026#39;, link: \u0026#39;/人生篇/人生思考\u0026#39;} { text: \u0026#39;开源精神\u0026#39;, link: \u0026#39;/人生篇/开源精神\u0026#39; }, ] } ] } }) 其中之所以为如下路径，包括几个前提：\n读者撰写的文档位于 docs/人生篇/ 文件夹中。 读者的文档名为 人生思考.md。 读者想要将文档显示为 人生思考（若不希望，将期望的显示内容替换 text 中内容）。 更多内容可以参考 SurviveXJTU 中的具体实现。\n提交 PR 在进行了撰写之后，则可以根据正常的流程进行 PR，前提是读者已经对仓库进行了 fork，如上的修改发生在通过 git clone 复制自己的仓库之后的本地内容中，使用 git add ., git commit -m \u0026quot;update\u0026quot;, git push -u origin main 进行推送，并且在 Github 页面提交 PR 即可。\nVitePress 快速建站 本文接下来的内容用来讲解如何使用 VitePress 进行快速建站。\n安装初始化 首先需要安装 npm，前往 Node.js 的官网进行下载，之后按照指示安装即可，结束之后打开一个终端，输入 node -v 以及 npm -v，会提供 Node.js 以及 npm 的版本号，说明安装成功。\n接下来转用 pnpm，更加好用的包管理器：\n1 npm install -g pnpm 然后使用 pnpm 安装 VitePress，新建文件夹，在目录下打开终端：\n1 pnpm add -D vitepress 之后使用 VitePress 提供的快速初始化工具：\n1 pnpm vitepress init 在初始化的过程中，进行以下的选择：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ┌ Welcome to VitePress! │ ◇ Where should VitePress initialize the config? │ ./docs │ ◇ Site title: │ My Awesome Project │ ◇ Site description: │ A VitePress Site │ ◇ Theme: │ Default Theme + Customization │ ◇ Use TypeScript for config and theme files? │ Yes │ ◆ Add VitePress npm scripts to package.json? │ Yes └ 之后执行 pnpm run docs:dev 即可在本地启动 VitePress 并进行预览。\nGithub 部署 在本地预览没有问题之后，就可以进行 Github 部署了，首先需要新建一个仓库，例如 Example，然后在 docs/.vitepress/config.mts 中添加如下内容：\n1 2 3 4 export default defineConfig({ ..., base: \u0026#39;/Example/\u0026#39; // 若仓库为 username.github.io，则 base 为 / }) 与仓库建立链接（详细方法见本人 关于 Git 的博客）之后，在根目录下创建一个 .github/workflows/deploy.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # 构建 VitePress 站点并将其部署到 GitHub Pages 的示例工作流程 # name: Deploy VitePress site to Pages on: # 在针对 `main` 分支的推送上运行。如果你 # 使用 `master` 分支作为默认分支，请将其更改为 `master` push: branches: [main] # 允许你从 Actions 选项卡手动运行此工作流程 workflow_dispatch: # 设置 GITHUB_TOKEN 的权限，以允许部署到 GitHub Pages permissions: contents: read pages: write id-token: write # 只允许同时进行一次部署，跳过正在运行和最新队列之间的运行队列 # 但是，不要取消正在进行的运行，因为我们希望允许这些生产部署完成 concurrency: group: pages cancel-in-progress: false jobs: # 构建工作 build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 # 如果未启用 lastUpdated，则不需要 - uses: pnpm/action-setup@v4 with: version: latest - name: Setup Node uses: actions/setup-node@v4 with: node-version: 18 cache: pnpm # 或 pnpm / yarn - name: Setup Pages uses: actions/configure-pages@v4 - name: Install dependencies run: pnpm install # 或 pnpm install / yarn install / bun install - name: Build with VitePress run: pnpm docs:build # 或 pnpm docs:build / yarn docs:build / bun run docs:build - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: docs/.vitepress/dist # 部署工作 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} needs: build runs-on: ubuntu-latest name: Deploy steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 在 Github 仓库中，找到 Settings -\u0026gt; Pages -\u0026gt; Build and deployment -\u0026gt; Source，选择 Github Actions，之后进行：\n1 2 3 git add . git commit -m \u0026#34;Initial Commit\u0026#34; git push origin main 稍等片刻之后即可看到部署成功。\n结语 限于篇幅以及内容的设计，本篇内容可能暂时截止于此，更多的内容会在后续选择性地在此处更新，或者新建新的博客进行分享，希望本博客可以帮助读者更好的了解 VitePress 的写作流程，并为相关的开源项目做出更多的贡献。\n","date":"2024-07-03T00:00:00Z","image":"https://axi404.github.io/Blog/p/vitepress-%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97/cover_hu4085360045407190672.jpg","permalink":"https://axi404.github.io/Blog/p/vitepress-%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97/","title":"VitePress 贡献指南 \u0026 建站指南"},{"content":"前言 本教程是关于 Actions 以及 Pages 的一些分享，最近一段时间在 Github 上面发烧了一阵子，狠狠的制作了一些开源的项目，自然也存在一些摸索性质的内容，而摸索出了答案，也就是时候出一篇教程来写一写，正好，本博客风格赏心悦目，值得一试。\n关于 Github Pages 首先需要提及的是 Github Pages，简单来说，这是一种 Github 提供的静态网站托管服务，至于什么是静态网站，一种简易的理解是，至少上面不会有一个数据库，网站也不存在任何对数据的读写操作，一切的风格化变化只来自于网站提前搭建好的框架。\n基于这种特性，不难理解的是，Github Pages 尤其擅长处理一些类似于博客、文档、教程一类的网站，甚至说我们的 CSBAOYANDDL 也通过一种取巧的方式，可以通过 Github Actions 维护一个类似于数据库的内容。\n在提供静态网页这件事情上，Github 可以说是十分慷慨的，每一个用户可以创建近乎无限的仓库，而每一个仓库都可以对应一个 Github Pages————只要你知道如何设置（而这一点我们会在后面提及）。\n关于 Github Actions Github Actions 是一个持续集成和持续部署（CI/CD）平台，它允许用户在 Github 上创建自动化流程，用于构建、测试和部署项目，其支持使用 YAML 文件定义工作流程，并且可以与 Github 上的其他服务进行交互，换句话来说，Github Actions 支持我们在 Github 这个理论来说静态的平台上面运行一个脚本。\n通过上述的内容，细心的读者应当不难发现，Pages 提供静态服务，而 Actions 则可以运行脚本，二者的互补之下，很多内容都成为了可能，不过本篇中不得不遗憾地告诉读者，Actions 在其中并不发挥着过多的作用，大多数的内容仅是基于现如今成熟的网页模板以及 Github Pages 的静态网站部署，便已经结束了。\n部署你的第一个网站 回顾 在很多的教程中，往往都会教学如何建立一个自己的博客或者主页，通过 Github Pages 的方式。然而这些方法往往问题很大，即会让读者产生一种错觉，一个账户只能创建一个静态网站。\n让我们回顾一下这些教程说的内容，首先，在自己的账户中创建一个仓库，这个仓库的名字需要是 username.github.io，对于笔者来说，也就是创建一个名为 Axi404.github.io 的仓库。\n然后在其中使用某些模板或者其他的内容进行进一步操作。这看上去确实正规，但是不免让人产生了怀疑，那么我的仓库名是不是只能叫做 username.github.io 呢？\n事实上在创造一个仓库的时候，你的仓库中存在一个选项，即 Github Pages，在进行了一些操作之后，便可以让你创建一个网站，而这个网站一般来说其域名为 username.github.io/reponame。具体进行的操作先按下不表，但这里也就不难发现了，实际上创建名为 username.github.io 看上去确实特殊，但是并不意味着你只能创建一个仓库：事实上 Github Pages 对于这个仓库名称进行了特殊处理，使用该名称创建的仓库，其域名直接为 username.github.io，但除此以外，并不限制你创建其他的仓库。\n让我们来简单的了解一下创建一个网站的流程。\n按照常规的流程来说，我们都知道，Web 网站是由 Web 三大件共同创建的，其中 html 负责创建网页的框架，css 负责创建网页的样式，而 js 负责创建网页的交互。而在大多数的网站中，index.html 绝对是重中之重。在 Github Pages，其在部署阶段，网站会自动寻找在某一目录下的 index.html 文件，并且将其作为网站的主页，同时将全部的内容部署到静态网页中。\n因此这一流程也也就不难想象了，创建一个 index.html，在其中写入一些内容，然后将这个文件部署到 Github Pages 中，便可以得到一个网站，简单地好似将大象放进冰箱里。\n实例 在这里给出一个小小的实例，读者可以跟着进行一下尝试，在这里我们假设读者已经在本地完成了 Git 以及 Github 相关的一切配置，并且拥有了一个仓库，例如名为 MyExample。以下均会采用我的用户名进行操作，这是因为每一次使用 username 的时候总会存在读者不解并不将其替换，使用本人的用户名应当会更加明显一些，表明替换的必要性。读者在使用的时候将我的用户名替换为自己的即可。\n1 2 3 git clone git@github.com:Axi404/MyExample.git cd MyExample vim index.html 在 index.html 中写入以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;My First Website\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to My First Website\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a simple HTML page hosted on GitHub Pages.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 更进一步来说，你可能愿意为其添加一些 CSS 样式以及 JS 脚本，这也同样不难：\n首先创建一个 CSS 文件名为 styles.css，在其中写入一些代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 body { font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f4f4f4; } h1 { color: #333; text-align: center; margin-top: 50px; } p { color: #666; text-align: center; margin-top: 20px; } 然后创建一个JS文件名为 script.js，并且在其中输入一些代码：\n1 2 3 document.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function() { alert(\u0026#39;Welcome to My First Website!\u0026#39;); }); 最后再对 index.html 进行一些修改以导入这些内容，包括在 head 中加入 \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;styles.css\u0026quot;\u0026gt; 以及在 body 的末尾加入 \u0026lt;script src=\u0026quot;script.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;，这样便大功告成了。\n假如你使用的是 VS Code 之类的编辑器，使用 Live Server 可以对这个页面进行实时阅览，十分好用，或者正常的 Linux 命令行，使用 xdg-open 打开文件进行预览也是可以的（指在具有桌面 GUI 以及默认浏览器的系统中）。\n接下来可以将这些内容上传到 Github 了：\n1 2 3 git add . git commit -m \u0026#34;initial commit\u0026#34; git push 之后前往 Github 上面，依次添加 Setting -\u0026gt; Pages -\u0026gt; None -\u0026gt; main -\u0026gt; save，完成设置，流程可以如下所示：\n不难发现后方的名为 /(root) 的选项，即你的 index.html 所在的目录，我们这里使用默认的根目录即可，后续我们会知道，使用自定义的 Github Actions 也可以做到相同的效果。\n在点击 save 之后可以点击上方的 Actions 看到一个 deployment 的 action 正在 queue 或者正在 Pending，等待部署结束即可。\n此时再次回到 Pages 的界面，可以看到页面已经部署，并且给出了 url 链接。\n之后再次进行的部署流程会比这个简单很多，只需要在修改了内容之后重新 commit 并且 push 即可，剩下的内容 Github Actions 会帮助你完成，这是得力于这个 Action 对你的 push 操作的检测（被触发）。\n部署诸如 Hugo 以及 mkdocs 等内容与直接的 html 文件稍有不同，在后续的拓展内容中会陆续更新这两部分的介绍。\n完成你的第一个 Github Actions 你已经完成了一个正常的网页的部署了，一般来说，假如说你是正常的手写的 index.html 类型的静态网页，此时任务便已经结束了，不过很不幸，你可能还有更多的需求，所以需要一个自己的 Github Actions 来进行更多的个性化操作。\n笔者将给出两个示例来进行示范，其中之一是部署 vue 项目，众所周知 vue 项目需要顺利编译才可以成为正常的静态网页，而优雅的方式之中并不包括本地编译之后手动推送。如何在 Github 中使用 Github Actions 来自动化完成这一流程便成为了刚需。同时，笔者也将给出另一个示例，也就是 CSDDL 的另一关键组成：BoardCaster。BoardCaster 是保管在另一仓库中的 JSON 格式的保研信息数据库，如何进行定时的订阅以及对于当前仓库的定时更新？这也同样可以使用 Github Actions 做到。\n部署 vue 项目 首先先通过正常的方式安装 vue3，并且已经完成了一个项目的新建。例如：\n1 2 3 4 5 npm install -g @vue/cli vue create cs-baoyan-ddl cd cs-baoyan-ddl npm install npm install gh-pages --save-dev 并且进行了一些内容的创建。\n之后需要进行若干的设置操作，虽然这些并不包括在 Github Actions 之中，但是为了后续的部署，这些是必要内容，假如仅讲解 Github Actions 未免写得过于的空洞。\n首先修改 vue.config.js：\n1 2 3 4 5 module.exports = { publicPath: process.env.NODE_ENV === \u0026#39;production\u0026#39; ? \u0026#39;/cs-baoyan-ddl/\u0026#39; // your repo\u0026#39;s name : \u0026#39;/\u0026#39; }; 此处值得一提的是，在此之前包括 fetch 的内容，如 fetch('/config/schools.json')，需要修改为类似于 fetch('/cs-baoyan-ddl/config/schools.json') 的格式。\n之后修改 package.json，加入 deploy部分：\n1 2 3 4 5 \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;vue-cli-service build\u0026#34;, \u0026#34;serve\u0026#34;: \u0026#34;vue-cli-service serve\u0026#34;, \u0026#34;deploy\u0026#34;: \u0026#34;gh-pages -d dist\u0026#34; } gh-pages 是一个十分强大的工具，可以在 build 的时候为你 build 原内容到分支 gh-pages 中。\n之后在 .github/workflows/deploy.yml 中添加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 name: Deploy to GitHub Pages on: push: branches: - main workflow_dispatch: jobs: build-deploy: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Set up Node.js uses: actions/setup-node@v2 with: node-version: \u0026#39;16\u0026#39; - name: Install dependencies run: npm install - name: Build project run: npm run build - name: Configure Git run: | git config --global user.name \u0026#39;github-actions\u0026#39; git config --global user.email \u0026#39;github-actions@github.com\u0026#39; - name: Deploy to GitHub Pages run: | git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git npm run deploy env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 遂讲解一下这个 Github Actions 的内容。\n一般来说，Github Actions 一共包括三个部分，分别是 name, on 以及 jobs。\nname：name 的含义应该不难理解，也就是你的 Actions 的名字，你在 Github 之中全流程都是可视化的，name 作为选择执行不同 Actions 的依据十分的直观。 on：on 的含义是触发条件，也就是当什么事件发生时，你的 Actions 才会被触发。 jobs：jobs 的含义是任务，也就是你的 Actions 具体要执行什么操作。 build-deploy：本代码中的 build-deploy 是这个 Actions 之中唯一的任务，这串字符也就是这个任务的名称。 runs-on: ubuntu-latest：runs-on 的含义是运行环境，也就是你的 Actions 会在什么环境下运行。一般来说使用最新的 ubuntu 环境即可，即 ubuntu-latest。 steps：steps 的含义是步骤，也就是你的 Actions 具体要执行什么操作。 actions/checkout@v2：actions/checkout@v2 是一个 Github 官方提供的 Actions，其作用是检出仓库。 actions/setup-node@v2：actions/setup-node@v2 是一个 Github 官方提供的 Actions，其作用是安装 Node.js。 run: npm install：这个步骤会执行 npm install 命令，以安装项目所需的所有依赖包。这个步骤通常是必要的，因为在构建和部署之前，所有的依赖包都需要被安装到项目中，这其中包括了关键内容，即 vue 以及 gh-pages。 run: npm run build：这个步骤会执行 npm run build 命令，以构建项目。这通常会生成一个用于生产环境的优化后的静态文件集，例如 HTML、CSS 和 JavaScript 文件。 run: git config --global user.name 'github-actions' 和 run: git config --global user.email 'github-actions@github.com'：这两个步骤用于配置 Git 用户名和电子邮件地址，以便后续的 Git 操作可以顺利进行。这里设置的用户名和电子邮件是为了让 GitHub Actions 可以以一个虚拟用户的身份进行提交操作。换句话说，这里的 name 以及 email 可以随意设置，只是为了一个名称而已，具体的权限由 secrets.GITHUB_TOKEN 提供。 run: git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git：这一行命令会更新 Git 远程仓库的 URL，以便使用 GitHub 提供的访问令牌进行身份验证。${{ secrets.GITHUB_TOKEN }} 是一个 GitHub 提供的自动生成的访问令牌，它存储在 GitHub Secrets 中，用于确保安全的身份验证。只有使用了 secrets.GITHUB_TOKEN，指令才有与 Github 仓库交互的权限。 run: npm run deploy：这个步骤会执行 npm run deploy 命令，以将构建后的文件部署到 GitHub Pages 上。由于安装了 gh-pages，在部署的过程中会自动在 Git 上进行操作，将静态文件推送到 gh-pages 分支，从而触发 GitHub Pages 的部署。 以上便不难理解 Github Actions 的基本工作原理了，绝大多数的静态网站生成方案都会给出自己的 Github Actions 配置文件，而你只需要在理解了文件的组成之后在他们的基础上进行略微的修改即可。\n定时更新仓库文件 CSDDL 的另一关键组成便是其数据库，也就是 BoardCaster。众所周知，静态网站并不存在后端，也就不存在可以持续更新维护与访问的后端数据库，但是使用 JSON 文件以及一种类似于订阅效果的操作，可以完成一个丐版的数据库，这并不困难。\n梳理一下思路，我们的需求包括，git clone 另一仓库的内容，将另一仓库的内容截取需要的部分复制到本仓库对应位置，正常的 add, commit, push 流程。最后，这个脚本需要定期执行。\n不难给出 Github Actions 脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 name: Update JSON from BoardCaster on: schedule: - cron: \u0026#39;*/15 * * * *\u0026#39; # 每15分钟运行一次 workflow_dispatch: # 手动触发 jobs: update-readme: runs-on: ubuntu-latest steps: - name: Checkout Listener repository uses: actions/checkout@v2 - name: Clone BoardCaster repository run: git clone https://github.com/CS-BAOYAN/BoardCaster.git - name: Copy and rename data.json to public/config/schools.json run: | cp BoardCaster/data.json public/config/schools.json - name: Commit and push changes if there are any run: | git config --global user.name \u0026#39;github-actions\u0026#39; git config --global user.email \u0026#39;github-actions@github.com\u0026#39; git add public/config/schools.json if git diff-index --quiet HEAD; then echo \u0026#34;No changes to commit\u0026#34; else git commit -m \u0026#34;Update public/config/schools.json from BoardCaster\u0026#34; git push fi env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 大多数内容应该不难理解，大量的篇幅是常规的 Git 操作，在 GITHUB_TOKEN 的环境下执行，其中唯一需要指出的细节是先比较 HEAD 之后再决定是否 commit，这是因为若无修改而 commit 会导致 Git 报错，虽然实际上无伤大雅，但是依然不够优雅。\n同样需要指出的是定时触发的语法，schedule 中的 cron 语法是 Github Actions 提供的定时触发语法，*/15 * * * * 表示每 15 分钟触发一次。\n1 2 3 4 5 6 7 * * * * * | | | | | | | | | +---- 星期几 (0 - 7) (星期天为0或7) | | | +------ 月份 (1 - 12) | | +-------- 日期 (1 - 31) | +---------- 小时 (0 - 23) +------------ 分钟 (0 - 59) Cron 是一种用于调度任务的时间表表达式，广泛应用于类 Unix 操作系统的任务调度工具中。GitHub Actions 也支持使用 Cron 表达式来定时触发工作流。Cron 表达式由五个字段组成，分别表示分钟、小时、日期、月份和星期几。\n其中需要著名的特殊字符包括以下内容：\n星号（*）：表示匹配任何值。例如，* * * * * 表示每分钟执行一次。 逗号（,）：用于分隔多个值。例如，0,15,30,45 * * * * 表示每小时的第 0、15、30 和 45 分钟执行。 连字符（-）：用于指定一个范围。例如，0-5 * * * * 表示每小时的第 0 到 5 分钟执行。 斜杠（/）：用于指定步长。例如，*/15 * * * * 表示每 15 分钟执行一次。 同时，需要注意的是 Github Actions 由于流量过大的问题，所以说对于定期触发的 Actions 并不会按照准确的时间执行，而是大概率会出现延后，在这里开通了 workflow_dispatch，可以在紧急情况下选择手动触发。\n结语 以上便是本次介绍的全部内容了，在此限于篇幅，也要告一段落了，更多的静态网站部署工具，笔者多半也有使用过，或许改天会开一个合集，讲一下踩过的坑。\nGithub Pages 与 Github Actions 可以帮助开发者构建个人网站，更重要的是，其完全免费。使用它们吧，创作属于自己的内容。\n","date":"2024-07-02T00:00:00Z","image":"https://axi404.github.io/Blog/p/github-actions-and-pages-%E6%95%99%E7%A8%8B/cover_hu2890652122833854782.jpg","permalink":"https://axi404.github.io/Blog/p/github-actions-and-pages-%E6%95%99%E7%A8%8B/","title":"Github Actions and Pages 教程"},{"content":"本人女装收集，欢迎欣赏。原有大约 200 余张，不过大多为同一姿势连拍，或未达到分享标准，在此给出本人较为喜欢的照片。\n","date":"2024-07-08T00:00:00Z","image":"https://axi404.github.io/Blog/p/%E5%A5%B3%E8%A3%85%E6%94%B6%E9%9B%86/cover_hu13443226514479916570.png","permalink":"https://axi404.github.io/Blog/p/%E5%A5%B3%E8%A3%85%E6%94%B6%E9%9B%86/","title":"女装收集"}]